{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "John R. Ladd, Jessica Otis, Christopher N. Warren, and Scott Weingart, \"Exploring and Analyzing Network Data with Python,\" The Programming Historian 6 (2017), https://doi.org/10.46430/phen0064.\n",
    "\n",
    "https://programminghistorian.org/en/lessons/exploring-and-analyzing-network-data-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import functools\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build User Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connections(tweets):\n",
    "    \"\"\"Generate three sets of connections ((user1, user2), tweetid):\n",
    "        1. Retweeted: ((['userid'], ['retweet_userid'])['tweetid'])\n",
    "        2. Replied: ((['userid'], ['in_reply_to_userid']), ['tweetid'])\n",
    "        3. Mentioned: ((['userid'], ['mentioned_userid']), ['tweetid'])\n",
    "    \"\"\"\n",
    "    rt = tweets[['userid', 'retweet_userid']].dropna().reset_index()\n",
    "    re = tweets[['userid', 'in_reply_to_userid']].dropna().reset_index()\n",
    "    \n",
    "    mentions = (tweets['user_mentions']\n",
    "                # replace empty braces with NaN and drop\n",
    "                .replace('[]', np.nan)\n",
    "                .dropna()\n",
    "                # expand usernames into columns\n",
    "                .str.replace(r\"[\\[\\]\\']\", \"\", regex=True)\n",
    "                .str.split(',', expand=True)\n",
    "                # melt wide table into duplicated tweets\n",
    "                .reset_index()\n",
    "                .melt(id_vars=['tweetid'],\n",
    "                      value_name='mentioned_userid')\n",
    "                # clean up\n",
    "                .astype({'mentioned_userid':'string'})\n",
    "                .drop(columns=['variable'])\n",
    "                .join(tweets['userid'], on='tweetid')\n",
    "                .dropna()\n",
    "               )\n",
    "    \n",
    "    rt_graph = nx.from_pandas_edgelist(rt, \n",
    "                                       source='userid', \n",
    "                                       target='retweet_userid', \n",
    "                                       edge_attr='tweetid',\n",
    "                                       create_using=nx.DiGraph(),\n",
    "                                      )\n",
    "    re_graph = nx.from_pandas_edgelist(re, \n",
    "                                       source='userid', \n",
    "                                       target='in_reply_to_userid', \n",
    "                                       edge_attr='tweetid',\n",
    "                                       create_using=nx.DiGraph(),\n",
    "                                      )\n",
    "    mention_graph = nx.from_pandas_edgelist(mentions, \n",
    "                                           source='userid', \n",
    "                                           target='mentioned_userid', \n",
    "                                           edge_attr='tweetid',\n",
    "                                           create_using=nx.DiGraph(),\n",
    "                                           )\n",
    "    return rt_graph, re_graph, mention_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality\n",
    "\n",
    "Capture the importance of a node's position in the network considering: \n",
    "- degree, on the assumption that an important node will have many connections,\n",
    "- closeness, on the assumption that important nodes are close to other nodes, and\n",
    "- betweenness, on the assumption that important nodes are well situated and connect other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_attributes(G):\n",
    "    \"\"\"Compute various graph metrics and add to node attributes.\n",
    "    \"\"\"\n",
    "    # degree\n",
    "    nx.set_node_attributes(G,\n",
    "                           dict(G.out_degree(G.nodes())), \n",
    "                           'out_degree')\n",
    "    nx.set_node_attributes(G,\n",
    "                           dict(G.in_degree(G.nodes())), \n",
    "                           'in_degree')\n",
    "    \n",
    "    # eigenvector centrality\n",
    "    nx.set_node_attributes(G, \n",
    "                           nx.eigenvector_centrality(G),\n",
    "                           'eigenvector')\n",
    "    \n",
    "    # betweenness centrality\n",
    "    nx.set_node_attributes(G,\n",
    "                           nx.betweenness_centrality(G), \n",
    "                           'betweenness')\n",
    "    \n",
    "    # degree centrality\n",
    "    nx.set_node_attributes(G,\n",
    "                           nx.degree_centrality(re),\n",
    "                           'degree_centrality')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def top_nodes(data_dict, limit=20, show=False):\n",
    "    \"\"\"Return and optionally print the top n nodes in an attribute\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    nodes = sorted(data_dict.items(), \n",
    "                   key=itemgetter(1), \n",
    "                   reverse=True)[:limit]\n",
    "    if show:\n",
    "        print(\"Top {} nodes:\".format(limit))\n",
    "        for d in nodes:\n",
    "            print(d)\n",
    "        \n",
    "    return nodes\n",
    "        \n",
    "def highest_value(attribute_dict):     \n",
    "    \"\"\"Find the node with largest value in an attribute dictionary.\n",
    "    \n",
    "    Return: \n",
    "        tuple(node, value)\n",
    "        \n",
    "    \"\"\"     \n",
    "        # Ordered tuple  \n",
    "        attr_items = [(b,a) for (a,b) in attribute_dict.iteritems()]    \n",
    "        # Sort in descending order     \n",
    "        attr_items.sort()     \n",
    "        attr_items.reverse()     \n",
    "    return tuple(reversed(attr_items[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and transitivity\n",
    "\n",
    "Measuring the tendency for nodes to cluster together or for edges to form triangles: this corresponds to measures of the extent to which the users interacting with one particular user tend to interact with each other as well. Transitivity weights nodes with a large degree higher.\n",
    "\n",
    "The clustering coefficient is calculated as the number of triangles connected to node $i$ divided by the number of sets of two edges connected to node $i$ (node triples). \n",
    "\n",
    "The transitivity coefficient is calculated as 3 times the number of triangles in the network, divided by the number of connected triples of nodes in the network.\n",
    "\n",
    "- insight into how users tend to create groups characterized by dense connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_directed_attributes(G):\n",
    "    # ratio of number of graph edges to number of edges if fully connected\n",
    "    G.graph['density'] = nx.density(G)\n",
    "    \n",
    "    # diameter = maximum distance between any pair of nodes\n",
    "    G.graph['diameter'] = nx.diameter(G)\n",
    "\n",
    "    \n",
    "def add_undirected_attributes(G):\n",
    "    graph = graph.to_undirected()\n",
    "    \n",
    "    G.graph['connected_components'] = nx.number_connected_components(graph)\n",
    "    #G.graph['largest_subgraph'] = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "    \n",
    "    clustering_coeffs = nx.clustering(graph)\n",
    "    G.graph['avg_clust'] = (sum(clustering_coeffs.values()) \n",
    "                             / len(clustering_coeffs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(G):\n",
    "    \"\"\"Export graph to Pandas dataframe with attributes as columns.\"\"\"\n",
    "\n",
    "    return pd.DataFrame(dict(G.nodes(data=True))).T\n",
    "    \n",
    "def to_file(G, file):\n",
    "    \"\"\"Export graph to .gexf file.\"\"\"\n",
    "    nx.write_gexf(G, file)\n",
    "    \n",
    "def to_txt(G, file):\n",
    "    \"\"\"Export node attributes to .txt file.\"\"\"\n",
    "    results = [(k, bet_cen[k], clo_cen[k], eig_cen[k]) for k in range(len(nodes))]\n",
    "    \n",
    "    f = open(file,'w')\n",
    "    for item in results:     \n",
    "        f.write(','.join(map(str,item)))     \n",
    "        f.write('\\n')f.close()\n",
    "\n",
    "def get_matrix(G):\n",
    "    return nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(G, format_dict=None):\n",
    "    if format_dict == None:\n",
    "        format_dict = {'font_size':16,\n",
    "                       'width':3,\n",
    "                       'edge_color':'grey',\n",
    "                       'node_color':'purple',\n",
    "                       'with_labels':False,\n",
    "                      }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pos = nx.spring_layout(G, k=2)\n",
    "\n",
    "    nx.draw_networkx(G, \n",
    "                     pos,\n",
    "                     ax=ax,\n",
    "                     kwargs=format_dict,\n",
    "                    )\n",
    "    # Offset labels\n",
    "    for key, value in pos.items():\n",
    "        x, y = value[0]+.135, value[1]+.045\n",
    "        ax.text(x, y,\n",
    "                s=key,\n",
    "                bbox=dict(facecolor='red', alpha=0.25),\n",
    "                horizontalalignment='center', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iran 12/2020 Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = UsersData('../data/users')\n",
    "tweets = TweetsData('../data/tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets.df.loc[:][:]\n",
    "tweets_df = df[df['campaign'] == 'iran202012']\n",
    "rt, re, mentions = get_connections(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 92\n",
      "Edges: 243\n",
      "Maximum degree: 19\n",
      "Minimum degree: 1\n",
      "Average degree: 5.3\n",
      "Mode: 2\n"
     ]
    }
   ],
   "source": [
    "out = \"Nodes: {}\".format(graph.number_of_nodes())\n",
    "print(out)\n",
    "out = \"Edges: {}\".format(graph.number_of_edges())\n",
    "print(out)\n",
    "\n",
    "degrees = [val for (node, val) in graph.degree()]\n",
    "\n",
    "out = \"Maximum degree: {}\".format(np.max(degrees))\n",
    "print(out)\n",
    "out = \"Minimum degree: {}\".format(np.min(degrees))\n",
    "print(out)\n",
    "out = \"Average degree: {:.1f}\".format(np.mean(degrees))\n",
    "print(out)\n",
    "out = \"Mode: {}\".format(stats.mode(degrees)[0][0])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average clustering coefficient: 0.3277545397909848\n",
      "Transitivity: 0.676875\n"
     ]
    }
   ],
   "source": [
    "out = \"Average clustering coefficient: {}\".format(nx.average_clustering(graph))\n",
    "print(out)\n",
    "out = \"Transitivity: {}\".format(nx.transitivity(graph))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max degree centrality: 0.21, for node v6groR3jb3Pkm5X9ccSwgoPnmlZzKEkx5bsc1XQHb0=\n",
      "Max closeness centrality: 0.22, for node y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=\n",
      "Max betweenness centrality: 0.16, for node y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=\n"
     ]
    }
   ],
   "source": [
    "graph_centrality = nx.degree_centrality(graph)\n",
    "max_de = max(graph_centrality.items(), key=itemgetter(1))\n",
    "graph_closeness = nx.closeness_centrality(graph)\n",
    "max_clo = max(graph_closeness.items(), key=itemgetter(1))\n",
    "graph_betweenness = nx.betweenness_centrality(graph, normalized=True, endpoints=False)\n",
    "max_bet = max(graph_betweenness.items(), key=itemgetter(1))\n",
    "\n",
    "out = \"Max degree centrality: {:.2f}, for node {}\".format(max_de[1], max_de[0])\n",
    "print(out)\n",
    "out = \"Max closeness centrality: {:.2f}, for node {}\".format(max_clo[1], max_clo[0])\n",
    "print(out)\n",
    "out = \"Max betweenness centrality: {:.2f}, for node {}\".format(max_bet[1], max_bet[0])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_dict_scatter(dict1,\n",
    "                      dict2,\n",
    "                      path=\"\",\n",
    "                      ylabel=\"\",\n",
    "                      xlabel=\"\",\n",
    "                      title=\"\",\n",
    "                      line=False):\n",
    "    \n",
    "    fig = plt.figure(figsize=(7,7))    \n",
    "    ax = fig.add_subplot(111)    \n",
    "      \n",
    "    items1 = sorted(dict1.items())    \n",
    "    items2 = sorted(dict2.items())    \n",
    "    xdata = [b for a,b in items1]    \n",
    "    ydata = [b for a,b in items2]     \n",
    "    \n",
    "    for p in range(len(items1)):        \n",
    "        ax.text(x=xdata[p], \n",
    "                y=ydata[p],\n",
    "                s=str(items1[p][0]), \n",
    "                color=\"b\")\n",
    "        \n",
    "    if line:         \n",
    "        # use NumPy to calculate the best fit        \n",
    "        slope, yint = plt.polyfit(xdata,ydata,1)        \n",
    "        xline = plt.xticks()[0]         \n",
    "        yline = map(lambda x: slope*x+yint,xline)        \n",
    "        ax.plot(xline, yline, ls='--',color='b')\n",
    "        \n",
    "        # Set new x- and y-axis limits    \n",
    "        plt.xlim((0.0, max(xdata)+(.15*max(xdata))))    \n",
    "        plt.ylim((0.0, max(ydata)+(.15*max(ydata))))\n",
    "        \n",
    "        # Add labels and save    \n",
    "        ax.set_title(title)    \n",
    "        ax.set_xlabel(xlab)     \n",
    "        ax.set_ylabel(ylab)     \n",
    "        plt.savefig(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict1 = dict(graph.in_degree(graph.nodes()))\n",
    "dict2 = dict(graph.out_degree(graph.nodes()))\n",
    "\n",
    "#node_dict_scatter(dict1, dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
