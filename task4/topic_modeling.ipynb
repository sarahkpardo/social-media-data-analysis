{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from topic_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(string):\n",
    "    \"\"\"Remove symbols; replace urls, hashtags, and user \n",
    "       mentions with a placeholder token.\n",
    "    \"\"\"\n",
    "    # \"rt\" (\"retweet\") \n",
    "    string = re.sub('rt', '', string.lower())\n",
    "    \n",
    "    # @-mentions\n",
    "    string = re.sub(r'@\\w+', '<-@->', string)\n",
    "    \n",
    "    # hyperlinks\n",
    "    string = re.sub(r'http\\S+', '<-URL->', string)\n",
    "    string = re.sub(r'www.[^ ]+', '<-URL->', string)\n",
    "    \n",
    "    # hashtags\n",
    "    string = re.sub(r'#\\w+', '<-#->', string)\n",
    "    \n",
    "    # digits\n",
    "    string = re.sub(r'[0-9]+', '', string)\n",
    "    \n",
    "    # symbols\n",
    "    string = re.sub(r'[!\"$%&()*+,./:;=?[\\]^_`{|}~]', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_string(string):\n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(string))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on dataframes\n",
    "For use with ```.pipe()``` and ```.apply()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(df):\n",
    "    \"\"\"Remove symbols; replace urls, hashtags, and user \n",
    "       mentions with a placeholder token.\n",
    "    \"\"\"\n",
    "    # \"rt\" (\"retweet\") \n",
    "    df = df.str.lower().replace('rt', '')\n",
    "    \n",
    "    # @-mentions\n",
    "    df = df.str.replace(r'@\\w+', '<-@->')\n",
    "    \n",
    "    # hyperlinks\n",
    "    df = df.str.replace('http\\S+', '<-URL->')\n",
    "    df = df.str.replace('www.[^ ]+', '<-URL->')\n",
    "    \n",
    "    # hashtags\n",
    "    df = df.str.replace(r'#\\w+', '<-#->')\n",
    "    \n",
    "    # digits\n",
    "    df = df.str.replace(r'[0-9]+', '')\n",
    "    \n",
    "    # symbols\n",
    "    df = df.str.replace(r'[!\"$%&()*+,./:;=?[\\]^_`{|}~]', '')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenize(df):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    df = df.map(tokenizer.tokenize)\n",
    "    return df\n",
    "\n",
    "def tokenize(df):\n",
    "    \"\"\"Apply nltk tokenizing function to a dataframe,\n",
    "       removing single-character tokens.\n",
    "    \"\"\"\n",
    "    df = df.map(word_tokenize)\n",
    "    df = df.apply(lambda x: [x for token in x if len(token)>2])\n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    \"\"\"Remove stop words, based on nltk list.\"\"\"\n",
    "    \n",
    "    cache = set(stopwords.words())\n",
    "    df = df.apply(lambda x: [word for word in x \n",
    "                                    if word.lower() not in cache])\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    \"\"\"Lemmatize using nltk WordNet method.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df = df.apply(lambda x: [lemmatizer.lemmatize(word)\n",
    "                                  for word in x\n",
    "                                  if len(lemmatizer.lemmatize(w))>3])\n",
    "    return df\n",
    "\n",
    "def preprocess_words(df, tweet_tokenizer=True, lemmatize=False):\n",
    "    \"\"\"Apply word-level preprocessing.\"\"\"\n",
    "    \n",
    "    if tweet_tokenizer:\n",
    "        token_fn = tweet_tokenize\n",
    "    else: token_fn = tokenize\n",
    "        \n",
    "    if lemmatize:\n",
    "        df = df.pipe(token_fn).pipe(remove_stopwords).pipe(lemmatize)\n",
    "        return df\n",
    "    \n",
    "    df = df.pipe(token_fn).pipe(remove_stopwords)\n",
    "    return df\n",
    "\n",
    "def preprocess_text(self, tweet_tokenize, lemmatize):\n",
    "    \"\"\"Pre-process text in a dataframe column.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        df['processed_text'] = preprocess_data(df['not_processed_text'])\n",
    "\n",
    "    \"\"\"\n",
    "    return df.pipe(preprocess_string).pipe(preprocess_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_text(list_of_strings):\n",
    "    \"\"\"\n",
    "    Concatenate a list of strings into a single string.\n",
    "    \"\"\"\n",
    "    return ' '.join([string for string in list_of_strings])\n",
    "\n",
    "def all_tokens(list_of_lists):\n",
    "    \"\"\"\n",
    "    Concatenate items from multiple lists into a single list.\n",
    "    \"\"\"\n",
    "    return list(itertools.chain(*list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_iter(df_of_lists):\n",
    "    \"\"\"\n",
    "    Usage: df.pipe(tokenize_df)\n",
    "    \"\"\"\n",
    "    # Concatenate into a long string to be tokenized\n",
    "    long_string = all_text(all_tokens(df_of_lists))\n",
    "    preprocessed = preprocess_tweet(long_string)\n",
    "    \n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(preprocessed))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(list_of_strings):\n",
    "    \"\"\"\n",
    "    Usage: df.map(tokenize_list)\n",
    "    \"\"\"\n",
    "    long_string = all_text(list_of_strings)\n",
    "    preprocessed = preprocess_tweet(long_string)\n",
    "    \n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(preprocessed))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid\n",
       "1331706590525874184    Правительство Франции заявляет, что не признае...\n",
       "1100358276435398656    Interview w/ Ayaz Mutalibov, first President o...\n",
       "1100389340914569216    Dana Mazalova, Czech Journalist, is the author...\n",
       "724982683118358528     Baku Declaration of the 7th UNAOC Global Forum...\n",
       "728142042765742080     FM Mammadyarov: #Azerbaijan is &amp; will rema...\n",
       "727245477867974656     Azerbaijani army is and will defend its citize...\n",
       "728581480545325057     Terter'de Ermenilerin sivilleri hedef alması s...\n",
       "650550450320601088     newsazerbaijan.ru У берегов Испании спасены ок...\n",
       "661914640331333632     newsazerbaijan.ru РФ подтвердила защиту взаимн...\n",
       "535744142437933056     newsazerbaijan.ru В 2014 году в Азербайджане з...\n",
       "Name: tweet_text, dtype: string"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = df.loc[:]['tweet_text'].head(50)\n",
    "text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['правительство',\n",
       " 'франции',\n",
       " 'заявляет',\n",
       " 'что',\n",
       " 'не',\n",
       " 'признает',\n",
       " 'карабах',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'interview',\n",
       " 'w',\n",
       " 'ayaz',\n",
       " 'mutalibov',\n",
       " 'first',\n",
       " 'president',\n",
       " 'of',\n",
       " '<-#->',\n",
       " '“',\n",
       " 'the',\n",
       " 'corridor',\n",
       " 'by',\n",
       " 'which',\n",
       " 'people',\n",
       " 'could',\n",
       " 'escape',\n",
       " 'had',\n",
       " 'nonetheless',\n",
       " 'been',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'armenians',\n",
       " 'so',\n",
       " 'why',\n",
       " 'would',\n",
       " 'they',\n",
       " 'fire',\n",
       " '”',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'dana',\n",
       " 'mazalova',\n",
       " 'czech',\n",
       " 'journalist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'author',\n",
       " 'of',\n",
       " 'the',\n",
       " 'famous',\n",
       " 'interview',\n",
       " 'with',\n",
       " 'ayaz',\n",
       " 'mutalibov',\n",
       " 'published',\n",
       " 'in',\n",
       " '“',\n",
       " 'nezavisimaya',\n",
       " 'gazeta',\n",
       " '”',\n",
       " 'where',\n",
       " 'mutalibov',\n",
       " 'acknowledges',\n",
       " 'the',\n",
       " 'existence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'humanitarian',\n",
       " 'corridor',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'armenian',\n",
       " 'side',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'baku',\n",
       " 'declaration',\n",
       " 'of',\n",
       " 'the',\n",
       " 'th',\n",
       " 'unaoc',\n",
       " 'global',\n",
       " 'forum',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'fm',\n",
       " 'mammadyarov',\n",
       " '<-#->',\n",
       " 'is',\n",
       " 'amp',\n",
       " 'will',\n",
       " 'remain',\n",
       " 'a',\n",
       " 'committed',\n",
       " 'paner',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'joint',\n",
       " 'strategic',\n",
       " 'interests',\n",
       " 'in',\n",
       " 'field',\n",
       " 'o',\n",
       " '<-url->',\n",
       " 'azerbaijani',\n",
       " 'army',\n",
       " 'is',\n",
       " 'and',\n",
       " 'will',\n",
       " 'defend',\n",
       " 'its',\n",
       " 'citizens',\n",
       " 'and',\n",
       " 'will',\n",
       " 'give',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'response',\n",
       " 'to',\n",
       " 'every',\n",
       " 'armed',\n",
       " 'provocation',\n",
       " 'a',\n",
       " '<-url->',\n",
       " \"teer'de\",\n",
       " 'ermenilerin',\n",
       " 'sivilleri',\n",
       " 'hedef',\n",
       " 'alması',\n",
       " 'sonucu',\n",
       " 'zarar',\n",
       " 'gören',\n",
       " 'bir',\n",
       " 'evde',\n",
       " 'türk',\n",
       " 'milli',\n",
       " 'takımının',\n",
       " 'posteri',\n",
       " 'görülüy',\n",
       " '<-url->',\n",
       " 'newsazerbaijanru',\n",
       " 'у',\n",
       " 'берегов',\n",
       " 'испании',\n",
       " 'спасены',\n",
       " 'около',\n",
       " 'иммигрантов',\n",
       " 'спасенные',\n",
       " 'мигранты',\n",
       " 'в',\n",
       " 'ближайшее',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'рф',\n",
       " 'подтвердила',\n",
       " 'защиту',\n",
       " 'взаимных',\n",
       " 'инвестиций',\n",
       " 'с',\n",
       " 'азербайджаном',\n",
       " 'на',\n",
       " 'сегодняшний',\n",
       " 'день',\n",
       " 'р',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'в',\n",
       " 'году',\n",
       " 'в',\n",
       " 'азербайджане',\n",
       " 'зарегистрировано',\n",
       " 'преступлений',\n",
       " 'совершенных',\n",
       " 'детьми',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'эксперт',\n",
       " 'истинными',\n",
       " 'контрагентами',\n",
       " 'даиш',\n",
       " 'являются',\n",
       " 'отнюдь',\n",
       " 'не',\n",
       " 'власти',\n",
       " 'турции',\n",
       " 'санкции',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'ужесточается',\n",
       " 'наказание',\n",
       " 'за',\n",
       " 'нарушение',\n",
       " 'требований',\n",
       " 'закона',\n",
       " 'ар',\n",
       " '«',\n",
       " 'о',\n",
       " 'телерадиовещании',\n",
       " '»',\n",
       " 'с',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'глава',\n",
       " 'мид',\n",
       " 'азербайджана',\n",
       " 'отправился',\n",
       " 'в',\n",
       " 'париж',\n",
       " 'на',\n",
       " 'встречу',\n",
       " 'с',\n",
       " 'мг',\n",
       " 'обсе',\n",
       " 'министр',\n",
       " 'иностран',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'кроме',\n",
       " 'объединения',\n",
       " 'другого',\n",
       " 'пути',\n",
       " 'развития',\n",
       " 'сельского',\n",
       " 'хозяйства',\n",
       " 'нет',\n",
       " 'особое',\n",
       " 'внимани',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'live',\n",
       " 'полуфинал',\n",
       " 'международного',\n",
       " 'конкурса',\n",
       " 'по',\n",
       " 'танковому',\n",
       " 'биатлону',\n",
       " 'в',\n",
       " 'алабино',\n",
       " 'в',\n",
       " 'полуф',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'в',\n",
       " 'габале',\n",
       " 'завершился',\n",
       " 'кубок',\n",
       " 'мира',\n",
       " 'по',\n",
       " 'олимпийским',\n",
       " 'видам',\n",
       " 'стрельбы',\n",
       " 'данные',\n",
       " 'соревновани',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'вр',\n",
       " 'может',\n",
       " 'заморозить',\n",
       " 'реализацию',\n",
       " 'ряда',\n",
       " 'проектов',\n",
       " 'из-за',\n",
       " 'низкой',\n",
       " 'цены',\n",
       " 'на',\n",
       " 'нефть',\n",
       " 'кроме',\n",
       " 'т',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'полиция',\n",
       " 'задержала',\n",
       " 'нескольких',\n",
       " 'активистов',\n",
       " 'у',\n",
       " 'базы',\n",
       " 'ядерных',\n",
       " 'подлодок',\n",
       " 'в',\n",
       " 'шотландии',\n",
       " 'пол',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'прожиточный',\n",
       " 'минимум',\n",
       " 'в',\n",
       " 'ар',\n",
       " 'может',\n",
       " 'быть',\n",
       " 'увеличен',\n",
       " 'до',\n",
       " 'манатов',\n",
       " 'прожиточный',\n",
       " 'минимум',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'ответ',\n",
       " 'вс',\n",
       " 'азербайджана',\n",
       " 'за',\n",
       " 'погибших',\n",
       " 'солдат',\n",
       " 'будет',\n",
       " 'сокрушительным',\n",
       " '–',\n",
       " 'минобороны',\n",
       " 'ар',\n",
       " 'в',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'курс',\n",
       " 'доллара',\n",
       " 'незначительно',\n",
       " 'колеблется',\n",
       " 'к',\n",
       " 'мировым',\n",
       " 'валютам',\n",
       " 'по',\n",
       " 'состоянию',\n",
       " 'на',\n",
       " 'м',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'кровавый',\n",
       " 'список',\n",
       " 'дтп',\n",
       " 'в',\n",
       " 'азербайджане',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'экс-директор',\n",
       " 'мвф',\n",
       " 'приговорен',\n",
       " 'к',\n",
       " 'штрафу',\n",
       " 'за',\n",
       " 'махинации',\n",
       " 'судья',\n",
       " 'национальной',\n",
       " 'судебной',\n",
       " 'к',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'самой',\n",
       " 'высокой',\n",
       " 'пирамиде',\n",
       " 'из',\n",
       " 'монет',\n",
       " 'исполняется',\n",
       " 'года',\n",
       " 'алекс',\n",
       " 'червинский',\n",
       " 'попал',\n",
       " 'в',\n",
       " 'кн',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'вероятность',\n",
       " 'полномасштабной',\n",
       " 'войны',\n",
       " 'в',\n",
       " 'европе',\n",
       " 'не',\n",
       " 'очень',\n",
       " 'убедительна',\n",
       " '–',\n",
       " 'политолог',\n",
       " 'во',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'врачи',\n",
       " 'научили',\n",
       " 'компьютеры',\n",
       " 'обрабатывать',\n",
       " 'жалобы',\n",
       " 'пациентов',\n",
       " 'исследователи',\n",
       " 'создали',\n",
       " 'ко',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'страны',\n",
       " 'восточной',\n",
       " 'европы',\n",
       " 'хотят',\n",
       " 'вступить',\n",
       " 'в',\n",
       " 'нато',\n",
       " 'а',\n",
       " 'не',\n",
       " 'альянс',\n",
       " 'движется',\n",
       " 'на',\n",
       " 'восток',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'суббота',\n",
       " 'в',\n",
       " 'городе',\n",
       " 'выставки',\n",
       " 'отдыхая',\n",
       " 'от',\n",
       " 'трудов',\n",
       " 'праведных',\n",
       " 'имеет',\n",
       " 'смысл',\n",
       " 'побаловать',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'вашингтон',\n",
       " 'прикладывает',\n",
       " 'все',\n",
       " 'усилия',\n",
       " 'чтобы',\n",
       " 'еаэс',\n",
       " 'приказал',\n",
       " 'долго',\n",
       " 'жить',\n",
       " 'виталий',\n",
       " 'арьк',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'задержаны',\n",
       " 'человек',\n",
       " 'в',\n",
       " 'связи',\n",
       " 'с',\n",
       " 'терактом',\n",
       " 'в',\n",
       " 'анкаре',\n",
       " 'по',\n",
       " 'словам',\n",
       " 'премьер-министра',\n",
       " 'тур',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'позиция',\n",
       " 'греции',\n",
       " 'снижает',\n",
       " 'интерес',\n",
       " 'азербайджана',\n",
       " 'к',\n",
       " 'тар',\n",
       " '–',\n",
       " 'депутат',\n",
       " 'мм',\n",
       " '«',\n",
       " 'правительство',\n",
       " 'с',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'ford',\n",
       " 'первым',\n",
       " 'в',\n",
       " 'мире',\n",
       " 'применит',\n",
       " 'пластичный',\n",
       " 'алюминий',\n",
       " 'новый',\n",
       " 'сплав',\n",
       " 'изготовлен',\n",
       " 'по',\n",
       " 'тех',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'баку',\n",
       " 'сарсангское',\n",
       " 'водохранилище',\n",
       " 'превращено',\n",
       " 'ереваном',\n",
       " 'в',\n",
       " 'инструмент',\n",
       " 'угроз',\n",
       " 'на',\n",
       " 'встре',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'wsj',\n",
       " 'сильный',\n",
       " 'доллар',\n",
       " 'навредит',\n",
       " 'многим',\n",
       " 'американским',\n",
       " 'компаниям',\n",
       " 'негативный',\n",
       " 'эффект',\n",
       " 'в',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'турецкий',\n",
       " 'поток',\n",
       " 'будет',\n",
       " 'рассмотрен',\n",
       " 'еврокомиссией',\n",
       " 'проект',\n",
       " 'турецкий',\n",
       " 'поток',\n",
       " 'будет',\n",
       " 'р',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'найдено',\n",
       " 'тело',\n",
       " 'еще',\n",
       " 'одного',\n",
       " 'пропавшего',\n",
       " 'азербайджанского',\n",
       " 'нефтяника',\n",
       " 'тело',\n",
       " 'одного',\n",
       " 'из',\n",
       " 'пр',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'рубль',\n",
       " 'открыл',\n",
       " 'последнюю',\n",
       " 'торговую',\n",
       " 'неделю',\n",
       " 'года',\n",
       " 'резким',\n",
       " 'снижением',\n",
       " 'но',\n",
       " 'в',\n",
       " 'начале',\n",
       " 'г',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'в',\n",
       " 'грузии',\n",
       " 'по',\n",
       " 'делу',\n",
       " 'о',\n",
       " 'гибели',\n",
       " 'жвания',\n",
       " 'предъявлено',\n",
       " 'обвинение',\n",
       " 'экс-прокурору',\n",
       " 'страны',\n",
       " 'гру',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'президент',\n",
       " 'ильхам',\n",
       " 'алиев',\n",
       " 'поздравил',\n",
       " 'народ',\n",
       " 'с',\n",
       " 'гурбан',\n",
       " 'байрамы',\n",
       " 'президент',\n",
       " 'азербайджана',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'в',\n",
       " 'азербайджане',\n",
       " 'отмечается',\n",
       " 'день',\n",
       " 'национальной',\n",
       " 'музыки',\n",
       " 'первая',\n",
       " 'в',\n",
       " 'азербайджане',\n",
       " 'и',\n",
       " 'на',\n",
       " 'в',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'граждане',\n",
       " 'азербайджана',\n",
       " 'должны',\n",
       " 'будут',\n",
       " 'приносить',\n",
       " 'клятву',\n",
       " 'гражданина',\n",
       " 'граждане',\n",
       " 'азербай',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'эрдоган',\n",
       " 'саудовская',\n",
       " 'аравия',\n",
       " 'хочет',\n",
       " 'примирить',\n",
       " 'турцию',\n",
       " 'и',\n",
       " 'египет',\n",
       " 'египет',\n",
       " 'саудовская',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'в',\n",
       " 'сша',\n",
       " 'поймали',\n",
       " 'мужчину',\n",
       " 'сбежавшего',\n",
       " 'из',\n",
       " 'тюрьмы',\n",
       " 'в',\n",
       " 'году',\n",
       " 'житель',\n",
       " 'штата',\n",
       " 'огайо',\n",
       " 'фрэн',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'ввп',\n",
       " 'азербайджана',\n",
       " 'достигнет',\n",
       " 'млрд',\n",
       " 'долларов',\n",
       " '–',\n",
       " 'зияд',\n",
       " 'самедзаде',\n",
       " 'в',\n",
       " 'году',\n",
       " 'миро',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'на',\n",
       " 'южном',\n",
       " 'кавказе',\n",
       " 'решают',\n",
       " 'судьбу',\n",
       " 'иранского',\n",
       " 'газа',\n",
       " 'в',\n",
       " 'иране',\n",
       " 'обсудят',\n",
       " 'маршрут',\n",
       " 'поставок',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'газпром',\n",
       " 'не',\n",
       " 'продлит',\n",
       " 'транзитный',\n",
       " 'контракт',\n",
       " 'с',\n",
       " 'украиной',\n",
       " 'после',\n",
       " 'года',\n",
       " 'самый',\n",
       " 'простой',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'один',\n",
       " 'из',\n",
       " 'арестованных',\n",
       " 'в',\n",
       " 'дагестане',\n",
       " 'нурсистов',\n",
       " 'оказался',\n",
       " 'азербайджанцем',\n",
       " 'в',\n",
       " 'ходе',\n",
       " 'опе',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'лишение',\n",
       " 'ассанжа',\n",
       " 'свободы',\n",
       " 'признано',\n",
       " 'спецгруппой',\n",
       " 'оон',\n",
       " 'незаконным',\n",
       " 'рабочая',\n",
       " 'группа',\n",
       " 'он',\n",
       " 'п',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'завтра',\n",
       " 'в',\n",
       " 'азербайджане',\n",
       " 'ожидаются',\n",
       " 'осадки',\n",
       " 'в',\n",
       " 'баку',\n",
       " 'и',\n",
       " 'на',\n",
       " 'абшеронском',\n",
       " 'полуострове',\n",
       " 'завт',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'миа',\n",
       " 'россия',\n",
       " 'сегодня',\n",
       " 'объявляет',\n",
       " 'радиоконкурс',\n",
       " 'международное',\n",
       " 'информационное',\n",
       " 'агентс',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenize_list(text_df)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df/list of list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=</th>\n",
       "      <td>[America and the way its government treats its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=</th>\n",
       "      <td>[@ManotoNews اگه ایران به یمن و مقاومت کمک نکن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0+2DdcWQlF1LIe31q4foyvQMZYObIOeoh5woH5+4ySo=</th>\n",
       "      <td>[A group belonging to the HTS kidnapped Yasser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07CPSEe0H6QwZcanuJd4G4sYBjmx+NtXpcj2NdAAmr0=</th>\n",
       "      <td>[#США #Япония #Россия #Китай #Корея #Дяоюйдао ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0T+oJ4XBPG6ZbvgO0NQ+c+u6aQ5oDuzGtyT8lMLPEFM=</th>\n",
       "      <td>[Вот уж не думал, что Рашка сможет, Самое \"уда...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=</th>\n",
       "      <td>[People are not silent! This structure must ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=</th>\n",
       "      <td>[El pueblo indígena Kayapo cerró una important...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=</th>\n",
       "      <td>[@VoteMarsha Why Women Prefer to Vote for an r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067814896706994176</th>\n",
       "      <td>[Inilah bentuk rasionalitas islam dan ketiadaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091795789263921152</th>\n",
       "      <td>[اگه امشب مولانا توییتر میومد از همه مون راضی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099221870530961408</th>\n",
       "      <td>[Droit de vote à 16ans, vous êtes ?\\nEt pourqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213164353236504576</th>\n",
       "      <td>[🦠#Coronavirus, 🇰🇵#KimJongUn, 🇱🇾#Libya\\n\\nhttp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235289416370774016</th>\n",
       "      <td>[Trump has realized that he will be the loser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273528131861782528</th>\n",
       "      <td>[The Trumps have ruined our country and if ree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135AEY00MOP1tH7YCuKyQx2xM0hG1vsl7l+0QPTliyM=</th>\n",
       "      <td>[Insurgents shelled Al Nayrab of the #Aleppo g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1L0qn8rgg4bi6tCYH934gRpAQG59vTUg9kPubBzxM=</th>\n",
       "      <td>[just look at all the caravanserais that held ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Pqyt2W75POPX+6zd9UdZL89ALBtPPELN4NPrly0nag=</th>\n",
       "      <td>[haqqin.az Масштабные учения азербайджанских п...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Rf2s0L++cCmiGYutfy0oPxgMZWJVERRGF5P2Vryi0=</th>\n",
       "      <td>[Buenos días princesa, que el día ya ha comenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1lY66yW7i+XL4Fn6wRslwEStbOHd2vNXLSnJMpQjUg8=</th>\n",
       "      <td>[#НАТО #экология #прибалтика #балтийскоеморе #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rJVco1i2kqTr9XIp2G6n5jklStyGfK3DYfYjOSz3Pk=</th>\n",
       "      <td>[Looks like one more #fake. #Russian forces #K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213589457</th>\n",
       "      <td>[¡Quedan 3 episodios para el final!\\nSerie \"El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22vodAc2tmpYoHPMBh1l6aaGBbw23CRbg5S4OMthSU=</th>\n",
       "      <td>[#QuarantineAQuote Imagine if the roles were r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23vaC1gG734g7FYBCL66wVv4Z5k1I48mYXwAWmwsa1E=</th>\n",
       "      <td>[In case you missed it, the first US president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2RHBBCePF5Uasa4EGd9NRMi3v3EgZxWRjsDXIA4RVM=</th>\n",
       "      <td>[fotos de un adolescente estadounidense racist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nFqmLka396xUudTDoWTeXrpBt+q8inJmJYc3p58p4=</th>\n",
       "      <td>[Ледокольные суда - технологический прорыв Рос...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2rg8fiE11JB8Bh69A6aJWeRSBPcGTAmK8wnpFpH0=</th>\n",
       "      <td>[Interview w/ Ayaz Mutalibov, first President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31oxxNtP2VrM9ikKG3whNZjg9B4iE0sRtOakzh28qOU=</th>\n",
       "      <td>[#гагарин #GAGARIN \\nЗапрещенный Гагарин http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33Sm6bZv1nnOhdySB2Uw9CW54F7HhhZh1v9f9cjEmz8=</th>\n",
       "      <td>[ما از همین حالا جلوی ایجاد نانسی پلوسی ها و ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376365080</th>\n",
       "      <td>[весна обманчивая\\nк льдинам норовит присоедин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3HqwdUkxRabgmTyNHI1ZCilGchjYg8o91jHRFFRdWX0=</th>\n",
       "      <td>[Hi everybody. I'm an amateur photographer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3PGzTwb+Kk4yCSOyqgAZ3zPaUJ7xE3L+BSppo6ZLw8U=</th>\n",
       "      <td>[#HTS militants create girls' facebook pages a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3bc6BmmosKy9g+hwhMnLbHJWbe4pYksRUKf+aM50go=</th>\n",
       "      <td>[Viktor Krivopuskov, Minister of Defence os #U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3wyxtnGm6RUozXZ0pLy92lrUpF8WLHNFQ4zlc4TMO0=</th>\n",
       "      <td>[Iranian diplomats too have argued that the U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3zIYK8MEFJoOspSoDuQYI+Bqi7cyAOsQnlPHRdJue0=</th>\n",
       "      <td>[U.S. sacrifices #Kurds in #Syria, because in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46eJLsV6+iDw1rVv36i9NONigsfqfTfQ9EBzXr901c=</th>\n",
       "      <td>[: В Баку покончила с собой 15-летний подросто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4RHQs48X7Mzwe4HTmThSxmpMK3035MEWqXo3cnAtaFs=</th>\n",
       "      <td>[DR. Anthony Fauci: I congratulate Russians to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4fDgP2zd289XEnjWMomG2RATqLyehNzUjrqnJOq3I=</th>\n",
       "      <td>[The stronger the outcome is in favor of #Joe_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51qENUkzfVmrYDTbRru2Ny2zhFm3lVperQrco7TNiI=</th>\n",
       "      <td>[Quien con una sonrisa se levanta un buen día ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53159149</th>\n",
       "      <td>[France Arms Russian #Navy  http://bit.ly/iaN5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5O68KDqdztRXhsl9HkNpWLfdwjINlgxlCDiKbBCFzzc=</th>\n",
       "      <td>[Malawi is using bamboo to fight #climatechang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5lO2pgga8hVQbnn2K1oyw+Z2ecb7PQee0iJ3tTNs=</th>\n",
       "      <td>[Israel has used its cruel administrative dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6UQXw4Mnf0c4YkJ5rSJWtgfZlNBQFdx38mOzYUt16sI=</th>\n",
       "      <td>[Here's my burger thing😋🍔🥂\\n#NationalCheesebur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6nDcSemH7EpMzxlBrA8G5QRpuoEj4Bl2drKLTQnWE=</th>\n",
       "      <td>[Pro-Turkish militants from #SNA attacked Jibr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6oS8MGSDB5qwiNMvr+d2ITHHgU1DxnqXN94hWmGD1HM=</th>\n",
       "      <td>[🧐🧐 https://t.co/go8upieHJl, Researchers at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=</th>\n",
       "      <td>[Sungguh bodoh orang yang tidak mau membela ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6rZlwzFuvQH63uRh8lEbmPv6oyeNNJKrYhtzS68twq0=</th>\n",
       "      <td>[Trump is advertising that .... #Biden  #VoteB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6rdue70c97oL6cCnqXz5tdfnePCaHuDuOuYmbpx4mF4=</th>\n",
       "      <td>[ПРОВАЛЬНАЯ ПОЛИТИКА СИНДЗО АБЭ https://t.co/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794097607845015552</th>\n",
       "      <td>[#IslamicRevolution as a lesson for the whole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=</th>\n",
       "      <td>[god will punish you Aung San Suu Kyi #ShameOn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7CQHe488W6+t0uGOqaaxoJl6O3i3IkLdR6kUJJChJvs=</th>\n",
       "      <td>[СНГ объединяет усилия в борьбе с терроризмом ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     tweet_text\n",
       "userid                                                                                         \n",
       "+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=   [America and the way its government treats its...\n",
       "+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=  [@ManotoNews اگه ایران به یمن و مقاومت کمک نکن...\n",
       "0+2DdcWQlF1LIe31q4foyvQMZYObIOeoh5woH5+4ySo=  [A group belonging to the HTS kidnapped Yasser...\n",
       "07CPSEe0H6QwZcanuJd4G4sYBjmx+NtXpcj2NdAAmr0=  [#США #Япония #Россия #Китай #Корея #Дяоюйдао ...\n",
       "0T+oJ4XBPG6ZbvgO0NQ+c+u6aQ5oDuzGtyT8lMLPEFM=  [Вот уж не думал, что Рашка сможет, Самое \"уда...\n",
       "0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=  [People are not silent! This structure must ch...\n",
       "0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=   [El pueblo indígena Kayapo cerró una important...\n",
       "0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=  [@VoteMarsha Why Women Prefer to Vote for an r...\n",
       "1067814896706994176                           [Inilah bentuk rasionalitas islam dan ketiadaa...\n",
       "1091795789263921152                           [اگه امشب مولانا توییتر میومد از همه مون راضی ...\n",
       "1099221870530961408                           [Droit de vote à 16ans, vous êtes ?\\nEt pourqu...\n",
       "1213164353236504576                           [🦠#Coronavirus, 🇰🇵#KimJongUn, 🇱🇾#Libya\\n\\nhttp...\n",
       "1235289416370774016                           [Trump has realized that he will be the loser ...\n",
       "1273528131861782528                           [The Trumps have ruined our country and if ree...\n",
       "135AEY00MOP1tH7YCuKyQx2xM0hG1vsl7l+0QPTliyM=  [Insurgents shelled Al Nayrab of the #Aleppo g...\n",
       "1L0qn8rgg4bi6tCYH934gRpAQG59vTUg9kPubBzxM=    [just look at all the caravanserais that held ...\n",
       "1Pqyt2W75POPX+6zd9UdZL89ALBtPPELN4NPrly0nag=  [haqqin.az Масштабные учения азербайджанских п...\n",
       "1Rf2s0L++cCmiGYutfy0oPxgMZWJVERRGF5P2Vryi0=   [Buenos días princesa, que el día ya ha comenz...\n",
       "1lY66yW7i+XL4Fn6wRslwEStbOHd2vNXLSnJMpQjUg8=  [#НАТО #экология #прибалтика #балтийскоеморе #...\n",
       "1rJVco1i2kqTr9XIp2G6n5jklStyGfK3DYfYjOSz3Pk=  [Looks like one more #fake. #Russian forces #K...\n",
       "213589457                                     [¡Quedan 3 episodios para el final!\\nSerie \"El...\n",
       "22vodAc2tmpYoHPMBh1l6aaGBbw23CRbg5S4OMthSU=   [#QuarantineAQuote Imagine if the roles were r...\n",
       "23vaC1gG734g7FYBCL66wVv4Z5k1I48mYXwAWmwsa1E=  [In case you missed it, the first US president...\n",
       "2RHBBCePF5Uasa4EGd9NRMi3v3EgZxWRjsDXIA4RVM=   [fotos de un adolescente estadounidense racist...\n",
       "2nFqmLka396xUudTDoWTeXrpBt+q8inJmJYc3p58p4=   [Ледокольные суда - технологический прорыв Рос...\n",
       "2rg8fiE11JB8Bh69A6aJWeRSBPcGTAmK8wnpFpH0=     [Interview w/ Ayaz Mutalibov, first President ...\n",
       "31oxxNtP2VrM9ikKG3whNZjg9B4iE0sRtOakzh28qOU=  [#гагарин #GAGARIN \\nЗапрещенный Гагарин http:...\n",
       "33Sm6bZv1nnOhdySB2Uw9CW54F7HhhZh1v9f9cjEmz8=  [ما از همین حالا جلوی ایجاد نانسی پلوسی ها و ....\n",
       "376365080                                     [весна обманчивая\\nк льдинам норовит присоедин...\n",
       "3HqwdUkxRabgmTyNHI1ZCilGchjYg8o91jHRFFRdWX0=  [Hi everybody. I'm an amateur photographer and...\n",
       "3PGzTwb+Kk4yCSOyqgAZ3zPaUJ7xE3L+BSppo6ZLw8U=  [#HTS militants create girls' facebook pages a...\n",
       "3bc6BmmosKy9g+hwhMnLbHJWbe4pYksRUKf+aM50go=   [Viktor Krivopuskov, Minister of Defence os #U...\n",
       "3wyxtnGm6RUozXZ0pLy92lrUpF8WLHNFQ4zlc4TMO0=   [Iranian diplomats too have argued that the U....\n",
       "3zIYK8MEFJoOspSoDuQYI+Bqi7cyAOsQnlPHRdJue0=   [U.S. sacrifices #Kurds in #Syria, because in ...\n",
       "46eJLsV6+iDw1rVv36i9NONigsfqfTfQ9EBzXr901c=   [: В Баку покончила с собой 15-летний подросто...\n",
       "4RHQs48X7Mzwe4HTmThSxmpMK3035MEWqXo3cnAtaFs=  [DR. Anthony Fauci: I congratulate Russians to...\n",
       "4fDgP2zd289XEnjWMomG2RATqLyehNzUjrqnJOq3I=    [The stronger the outcome is in favor of #Joe_...\n",
       "51qENUkzfVmrYDTbRru2Ny2zhFm3lVperQrco7TNiI=   [Quien con una sonrisa se levanta un buen día ...\n",
       "53159149                                      [France Arms Russian #Navy  http://bit.ly/iaN5...\n",
       "5O68KDqdztRXhsl9HkNpWLfdwjINlgxlCDiKbBCFzzc=  [Malawi is using bamboo to fight #climatechang...\n",
       "5lO2pgga8hVQbnn2K1oyw+Z2ecb7PQee0iJ3tTNs=     [Israel has used its cruel administrative dete...\n",
       "6UQXw4Mnf0c4YkJ5rSJWtgfZlNBQFdx38mOzYUt16sI=  [Here's my burger thing😋🍔🥂\\n#NationalCheesebur...\n",
       "6nDcSemH7EpMzxlBrA8G5QRpuoEj4Bl2drKLTQnWE=    [Pro-Turkish militants from #SNA attacked Jibr...\n",
       "6oS8MGSDB5qwiNMvr+d2ITHHgU1DxnqXN94hWmGD1HM=  [🧐🧐 https://t.co/go8upieHJl, Researchers at th...\n",
       "6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=    [Sungguh bodoh orang yang tidak mau membela ba...\n",
       "6rZlwzFuvQH63uRh8lEbmPv6oyeNNJKrYhtzS68twq0=  [Trump is advertising that .... #Biden  #VoteB...\n",
       "6rdue70c97oL6cCnqXz5tdfnePCaHuDuOuYmbpx4mF4=  [ПРОВАЛЬНАЯ ПОЛИТИКА СИНДЗО АБЭ https://t.co/v...\n",
       "794097607845015552                            [#IslamicRevolution as a lesson for the whole ...\n",
       "79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=  [god will punish you Aung San Suu Kyi #ShameOn...\n",
       "7CQHe488W6+t0uGOqaaxoJl6O3i3IkLdR6kUJJChJvs=  [СНГ объединяет усилия в борьбе с терроризмом ..."
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df = (df\n",
    "           .groupby('userid')[['tweet_text']]\n",
    "           .agg(lambda x: list(x))\n",
    "          ).head(50)\n",
    "list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america',\n",
       " 'and',\n",
       " 'the',\n",
       " 'way',\n",
       " 'its',\n",
       " 'government',\n",
       " 'treats',\n",
       " 'its',\n",
       " 'people',\n",
       " 'must',\n",
       " 'be',\n",
       " 'reformed',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'poland',\n",
       " 'police',\n",
       " 'bureau',\n",
       " 'is',\n",
       " 'preparing',\n",
       " 'for',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'mass',\n",
       " 'gathering',\n",
       " 'events',\n",
       " 'being',\n",
       " 'planned',\n",
       " 'for',\n",
       " 'saturday',\n",
       " 'september',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'one',\n",
       " 'group',\n",
       " 'has',\n",
       " 'been',\n",
       " 'announced',\n",
       " 'they',\n",
       " 'will',\n",
       " 'hold',\n",
       " 'an',\n",
       " 'event',\n",
       " 'at',\n",
       " 'delta',\n",
       " 'park',\n",
       " 'at',\n",
       " 'noon',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'lies',\n",
       " 'why',\n",
       " 'hypocrisy',\n",
       " 'why',\n",
       " 'security',\n",
       " 'forces',\n",
       " 'why',\n",
       " 'racism',\n",
       " 'why',\n",
       " 'cut',\n",
       " 'budgets',\n",
       " 'to',\n",
       " 'deceive',\n",
       " 'people',\n",
       " 'no',\n",
       " 'trump',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'difference',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'he',\n",
       " 'has',\n",
       " 'destroyed',\n",
       " 'every',\n",
       " 'busines',\n",
       " '🐂',\n",
       " '🐃',\n",
       " '🐃',\n",
       " '🐃',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'even',\n",
       " 'if',\n",
       " 'the',\n",
       " 'power',\n",
       " 'to',\n",
       " 'negotiate',\n",
       " 'deals',\n",
       " 'is',\n",
       " 'handed',\n",
       " 'over',\n",
       " 'to',\n",
       " 'the',\n",
       " 'presidency',\n",
       " 'congress',\n",
       " 'will',\n",
       " 'still',\n",
       " 'have',\n",
       " 'the',\n",
       " 'final',\n",
       " 'say',\n",
       " 'and',\n",
       " 'judging',\n",
       " 'by',\n",
       " 'the',\n",
       " 'current',\n",
       " 'political',\n",
       " 'climate',\n",
       " 'johnson',\n",
       " 'will',\n",
       " 'not',\n",
       " 'fire',\n",
       " 'him',\n",
       " 'this',\n",
       " 'time',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'trump',\n",
       " 'trump',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'yes',\n",
       " 'biden',\n",
       " 'not',\n",
       " 'trump',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'and',\n",
       " '😭',\n",
       " '😭',\n",
       " '😭',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'democratic',\n",
       " 'presidential',\n",
       " 'nominee',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'had',\n",
       " 'also',\n",
       " 'warned',\n",
       " 'johnson',\n",
       " 'that',\n",
       " 'either',\n",
       " 'he',\n",
       " 'will',\n",
       " 'respect',\n",
       " 'nohern',\n",
       " 'ireland',\n",
       " '’',\n",
       " 's',\n",
       " 'peace',\n",
       " 'agreement',\n",
       " 'or',\n",
       " 'else',\n",
       " 'he',\n",
       " 'will',\n",
       " 'get',\n",
       " 'no',\n",
       " 'us',\n",
       " 'trade',\n",
       " 'deal',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " 'why',\n",
       " 'should',\n",
       " 'racism',\n",
       " 'exist',\n",
       " 'in',\n",
       " 'america',\n",
       " 'for',\n",
       " 'example',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'first',\n",
       " 'country',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'who',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idiot',\n",
       " 'the',\n",
       " 'one',\n",
       " 'who',\n",
       " 'extended',\n",
       " 'the',\n",
       " 'corona',\n",
       " 'who',\n",
       " 'is',\n",
       " 'trump',\n",
       " 'according',\n",
       " 'to',\n",
       " 'pelosi',\n",
       " 'corona',\n",
       " 'herself',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'our',\n",
       " 'president',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " 'he',\n",
       " 'is',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'raping',\n",
       " 'a',\n",
       " 'year-old',\n",
       " 'girl',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'this',\n",
       " 'photo',\n",
       " 'of',\n",
       " 'racism',\n",
       " 'is',\n",
       " 'complete',\n",
       " 'does',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'explained',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'are',\n",
       " 'democrats',\n",
       " 'angry',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'lying',\n",
       " 'about',\n",
       " 'vaccines',\n",
       " 'nono',\n",
       " 'no',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'heaven',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'reduction',\n",
       " 'in',\n",
       " 'brazilian',\n",
       " 'expos',\n",
       " 'to',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'although',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'its',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'brazil',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'it',\n",
       " 'is',\n",
       " 'something',\n",
       " 'else',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'in',\n",
       " 'america',\n",
       " 'the',\n",
       " 'law',\n",
       " 'goes',\n",
       " 'hand',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'with',\n",
       " 'the',\n",
       " 'police',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'people',\n",
       " 'die',\n",
       " 'every',\n",
       " 'day',\n",
       " 'and',\n",
       " 'trump',\n",
       " 'tells',\n",
       " 'new',\n",
       " 'lies',\n",
       " 'every',\n",
       " 'day',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'health',\n",
       " 'wants',\n",
       " 'a',\n",
       " 'long-term',\n",
       " 'plan',\n",
       " 'not',\n",
       " 'like',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'did',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'masks',\n",
       " 'after',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'again',\n",
       " 'when',\n",
       " 'coronary',\n",
       " 'hea',\n",
       " 'disease',\n",
       " 'spread',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'what',\n",
       " 'are',\n",
       " 'your',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'choosing',\n",
       " 'trump',\n",
       " 'as',\n",
       " 'the',\n",
       " 'successor',\n",
       " 'to',\n",
       " 'the',\n",
       " 'late',\n",
       " 'lady',\n",
       " 'of',\n",
       " 'american',\n",
       " 'justice',\n",
       " '<-#->',\n",
       " 'corona',\n",
       " 'is',\n",
       " 'for',\n",
       " 'all',\n",
       " 'ages',\n",
       " 'mask',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'corona',\n",
       " 'corona',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'medicine',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'biden',\n",
       " 'and',\n",
       " 'kissing',\n",
       " 'granddaughter',\n",
       " 'magically',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'corona',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'deadly',\n",
       " 'germs',\n",
       " 'ale',\n",
       " 'in',\n",
       " 'texas',\n",
       " 'drinking',\n",
       " 'water',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'look',\n",
       " '👇',\n",
       " '😭',\n",
       " '😭',\n",
       " '😭',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'and',\n",
       " 'corona',\n",
       " 'are',\n",
       " 'destroying',\n",
       " 'america',\n",
       " 'together',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'smile',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'no',\n",
       " 'impoant',\n",
       " '⚠',\n",
       " 'more',\n",
       " 'than',\n",
       " 'of',\n",
       " 'americans',\n",
       " 'say',\n",
       " 'the',\n",
       " 'debates',\n",
       " 'won',\n",
       " '’',\n",
       " 't',\n",
       " 'matter',\n",
       " 'much',\n",
       " 'to',\n",
       " 'them',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'journalnbc',\n",
       " 'news',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'my',\n",
       " 'veto',\n",
       " 'protective',\n",
       " 'mask',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '❤',\n",
       " '😂',\n",
       " '❤',\n",
       " '😂',\n",
       " '❤',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'liar',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'ginsburg',\n",
       " 'justice',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'dream',\n",
       " 'might',\n",
       " 'come',\n",
       " 'true',\n",
       " 'without',\n",
       " 'trump',\n",
       " 'yes',\n",
       " 'without',\n",
       " 'a',\n",
       " 'fool',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'a',\n",
       " 'tyrant',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'tyranny',\n",
       " 'if',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'elected',\n",
       " 'in',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'wear',\n",
       " 'a',\n",
       " 'mask',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'do',\n",
       " 'not',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'dumb',\n",
       " 'president',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'think',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'from',\n",
       " 'reality',\n",
       " 'to',\n",
       " 'lies',\n",
       " 'from',\n",
       " 'eah',\n",
       " 'to',\n",
       " 'sky',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'american',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'thanks',\n",
       " 'obama',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'destruction',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'do',\n",
       " 'you',\n",
       " 'blame',\n",
       " 'your',\n",
       " 'shocomings',\n",
       " 'and',\n",
       " 'your',\n",
       " 'government',\n",
       " 'on',\n",
       " 'the',\n",
       " 'states',\n",
       " 'and',\n",
       " 'condemn',\n",
       " 'them',\n",
       " 'trump',\n",
       " 'enough',\n",
       " 'lies',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'it',\n",
       " 'just',\n",
       " 'goes',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " 'whether',\n",
       " 'he',\n",
       " 'has',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'or',\n",
       " 'not',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'lying',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'that',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'was',\n",
       " 'not',\n",
       " 'produced',\n",
       " 'in',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'betraying',\n",
       " 'the',\n",
       " 'americans',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'a',\n",
       " 'world',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'just',\n",
       " 'for',\n",
       " 'voting',\n",
       " 'correctly',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '❤',\n",
       " '❤',\n",
       " '❤',\n",
       " 'the',\n",
       " 'miami',\n",
       " 'heat',\n",
       " 'team',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'finals',\n",
       " 'the',\n",
       " 'year',\n",
       " 'high',\n",
       " 'was',\n",
       " '❤',\n",
       " '❤',\n",
       " '❤',\n",
       " 'great',\n",
       " '<-url->',\n",
       " 'corona',\n",
       " 'means',\n",
       " 'an',\n",
       " 'excuse',\n",
       " 'for',\n",
       " 'dismissal',\n",
       " 'please',\n",
       " 'see',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'the',\n",
       " 'economy',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'the',\n",
       " 'cdc',\n",
       " 'director',\n",
       " 'says',\n",
       " 'young',\n",
       " 'people',\n",
       " 'are',\n",
       " 'expanding',\n",
       " 'the',\n",
       " 'corona',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'racism',\n",
       " 'in',\n",
       " 'a',\n",
       " 'country',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'claims',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-@->',\n",
       " 'deutschland',\n",
       " 'ist',\n",
       " 'wenn',\n",
       " 'nur',\n",
       " 'polizistinnen',\n",
       " 'nazis',\n",
       " 'davon',\n",
       " 'abhalten',\n",
       " 'den',\n",
       " 'bundestag',\n",
       " 'zu',\n",
       " 'stürmen',\n",
       " 'aber',\n",
       " 'einheiten',\n",
       " 'mit',\n",
       " 'hunden',\n",
       " 'pfe',\n",
       " '…',\n",
       " '<-@->',\n",
       " 'no',\n",
       " '❤',\n",
       " 'trump',\n",
       " 'no',\n",
       " '💚',\n",
       " 'no',\n",
       " '💜',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-@->',\n",
       " 'yesthis',\n",
       " 'is',\n",
       " 'awful',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'should',\n",
       " 'also',\n",
       " 'have',\n",
       " 'stoped',\n",
       " 'the',\n",
       " 'asteroid',\n",
       " 'from',\n",
       " 'wiping',\n",
       " 'out',\n",
       " 'the',\n",
       " 'dinosaurs',\n",
       " '<-@->',\n",
       " '“',\n",
       " 'my',\n",
       " 'most',\n",
       " 'fervent',\n",
       " 'wish',\n",
       " 'is',\n",
       " 'that',\n",
       " 'i',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'replaced',\n",
       " 'until',\n",
       " 'a',\n",
       " 'new',\n",
       " 'president',\n",
       " 'is',\n",
       " 'installed',\n",
       " '”',\n",
       " '–',\n",
       " 'justice',\n",
       " 'ruth',\n",
       " 'bader',\n",
       " 'ginsbur',\n",
       " '…',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'how',\n",
       " 'trump',\n",
       " 'handled',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'monster',\n",
       " '<-#->',\n",
       " '…',\n",
       " '<-@->',\n",
       " 'all',\n",
       " 'trump',\n",
       " 'suppoers',\n",
       " 'believe',\n",
       " 'bidens',\n",
       " 'truths',\n",
       " 'as',\n",
       " 'lies',\n",
       " 'but',\n",
       " 'believe',\n",
       " 'trumps',\n",
       " 'lies',\n",
       " 'as',\n",
       " 'truthshow',\n",
       " 'ironic',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " '…',\n",
       " '<-@->',\n",
       " 'sick',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'disturbing',\n",
       " 'things',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'how',\n",
       " 'he',\n",
       " 'has',\n",
       " 'embraced',\n",
       " 'and',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'normalize',\n",
       " 'so',\n",
       " 'many',\n",
       " 'distur',\n",
       " '…',\n",
       " '<-@->',\n",
       " 'so',\n",
       " 'trump',\n",
       " 'suppoers',\n",
       " 'are',\n",
       " 'saying',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'therapist',\n",
       " 'should',\n",
       " 'we',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'to',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'scientist',\n",
       " '<-@->',\n",
       " 'yes',\n",
       " '❤',\n",
       " '<-@->',\n",
       " 'اگه',\n",
       " 'ایران',\n",
       " 'به',\n",
       " 'یمن',\n",
       " 'و',\n",
       " 'مقاومت',\n",
       " 'کمک',\n",
       " 'نکنه',\n",
       " 'خاک',\n",
       " 'تو',\n",
       " 'سرش',\n",
       " 'لطفا',\n",
       " 'کسانی',\n",
       " 'که',\n",
       " 'واسه',\n",
       " 'ایران',\n",
       " 'و',\n",
       " 'مردم',\n",
       " 'سیل',\n",
       " 'زده',\n",
       " 'کمک',\n",
       " 'نکردند',\n",
       " 'نظر',\n",
       " 'ندن',\n",
       " '🔘',\n",
       " 'پهباد',\n",
       " 'سه',\n",
       " 'تا',\n",
       " '۱۰۰۰',\n",
       " 'یورو',\n",
       " '🔘',\n",
       " 'موشک',\n",
       " 'سوا',\n",
       " 'کن',\n",
       " 'جدا',\n",
       " 'کن',\n",
       " 'ببر',\n",
       " 'دعا',\n",
       " 'کن',\n",
       " 'دونه',\n",
       " 'ای',\n",
       " '۱۰۰۰',\n",
       " 'یورو',\n",
       " '🔘',\n",
       " 'ناو',\n",
       " 'غنیمتی',\n",
       " 'با',\n",
       " 'خدمه',\n",
       " 'آمریکایی',\n",
       " 'رایگان',\n",
       " '🔘',\n",
       " 'ناو',\n",
       " 'بدون',\n",
       " 'خدمه',\n",
       " 'قسطی',\n",
       " 'ماهی',\n",
       " '۱۰۰۰',\n",
       " 'یورو',\n",
       " 'بدو',\n",
       " 'اینور',\n",
       " 'بازار',\n",
       " '<-@->',\n",
       " 'بعضی',\n",
       " 'که',\n",
       " 'میرن',\n",
       " 'خارج',\n",
       " 'که',\n",
       " 'مثلا',\n",
       " 'آزاد',\n",
       " 'باشن',\n",
       " '،',\n",
       " 'چنان',\n",
       " 'درگیر',\n",
       " 'قوانین',\n",
       " 'اجباری',\n",
       " 'و',\n",
       " 'خشک',\n",
       " 'در',\n",
       " 'غربت',\n",
       " 'میشن',\n",
       " 'که',\n",
       " 'آزادیی',\n",
       " 'که',\n",
       " 'تو',\n",
       " 'ایران',\n",
       " 'داشتن',\n",
       " 'براشون',\n",
       " 'حسرت',\n",
       " 'و',\n",
       " 'رویا',\n",
       " 'میشه',\n",
       " 'اینجا',\n",
       " 'قانون',\n",
       " 'داره',\n",
       " 'و',\n",
       " 'هرچند',\n",
       " 'اشتباه',\n",
       " '،',\n",
       " 'باید',\n",
       " 'رعایت',\n",
       " 'کرد',\n",
       " 'رعایت',\n",
       " 'قانون',\n",
       " ...]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df = list_df.loc[:]['tweet_text']\n",
    "tokenized_iter = tokenize_iter(list_df)\n",
    "tokenized_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline:\n",
    "We are starting with a series of strings representing individual tweets. We can perform our analysis on\n",
    "- individual tweets\n",
    "- all tweets for a grouping of the dataframe (e.g. group by userid)\n",
    "- all tweets in the corpus\n",
    "\n",
    "In addition,\n",
    "- hashtags and urls are already in a separate column.\n",
    "\n",
    "In general, we want to convert tweet text into tokens for analysis. We will make utility functions which anticipate tokenizing for these levels of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = UsersData('../data/users')\n",
    "tweets = TweetsData('../data/tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets.df.loc[:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = df['campaign'] == 'iran202012'\n",
    "iran = df[campaign]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation for tweet text is defined as joining tweet strings into a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets = (iran\n",
    "               .groupby('userid')[['tweet_text']]\n",
    "               .agg(lambda x: list(x))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=</th>\n",
       "      <td>[America and the way its government treats its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=</th>\n",
       "      <td>[@ManotoNews اگه ایران به یمن و مقاومت کمک نکن...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=</th>\n",
       "      <td>[People are not silent! This structure must ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=</th>\n",
       "      <td>[El pueblo indígena Kayapo cerró una important...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=</th>\n",
       "      <td>[@VoteMarsha Why Women Prefer to Vote for an r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=</th>\n",
       "      <td>[Take a good look at #Trump and tweet me if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=</th>\n",
       "      <td>[Hapus zionisme hapus penjajahan.\\n#Palestine\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zFlH+vHUhiZD2qvvCLYyiU76qOha9+iYxCn1NVmzw=</th>\n",
       "      <td>[Karl Marx is the leader of These Do nothing D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zTUtu8WZ3RwxnwgMsYXnTU107UXsn4MQU5wrg8IDOU=</th>\n",
       "      <td>[I am sick and tired of being lied to by #real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zk4khaX7A3XhXVndteeiXLe4ma8xR7bYMBCOhCt68j8=</th>\n",
       "      <td>[Como #EEUU asesinó al general Soleimani, será...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     tweet_text\n",
       "userid                                                                                         \n",
       "+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=   [America and the way its government treats its...\n",
       "+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=  [@ManotoNews اگه ایران به یمن و مقاومت کمک نکن...\n",
       "0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=  [People are not silent! This structure must ch...\n",
       "0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=   [El pueblo indígena Kayapo cerró una important...\n",
       "0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=  [@VoteMarsha Why Women Prefer to Vote for an r...\n",
       "...                                                                                         ...\n",
       "y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=   [Take a good look at #Trump and tweet me if yo...\n",
       "z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=   [Hapus zionisme hapus penjajahan.\\n#Palestine\\...\n",
       "zFlH+vHUhiZD2qvvCLYyiU76qOha9+iYxCn1NVmzw=    [Karl Marx is the leader of These Do nothing D...\n",
       "zTUtu8WZ3RwxnwgMsYXnTU107UXsn4MQU5wrg8IDOU=   [I am sick and tired of being lied to by #real...\n",
       "zk4khaX7A3XhXVndteeiXLe4ma8xR7bYMBCOhCt68j8=  [Como #EEUU asesinó al general Soleimani, será...\n",
       "\n",
       "[209 rows x 1 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_of_lists = user_tweets\n",
    "iter_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['America and the way its government treats its people must be reformed https://t.co/DupN3cE2dd', 'https://t.co/ee5KZJMm5R', 'Portland Police Bureau is preparing for a variety of mass gathering events being planned for Saturday, September 26, 2020. At this time, one group has been announced they will hold an event at Delta Park at noon.  #PoliceLivesMatter  #Polizeigewalt  #Portland  #PortlandProtests https://t.co/3JSoa0UcOL', 'Why lies ..... why hypocrisy .... why security forces .... why racism ..... why cut budgets .... to deceive people    No Trump       No No   No #ARMY  #COVIDー19  #Biden #Trump https://t.co/v1WYXyidzJ', 'Difference #Biden https://t.co/Vl5lB7q2l6', 'He has destroyed every busines......🐂🐃🐃🐃🐃🐃 #TrumpMeltdown https://t.co/tKrPEdujCZ', 'Even if the power to negotiate deals is handed over to the presidency, Congress will still have the final say, and judging by the current political climate, Johnson will not fire him this time #Trump  #Covid_19  #DemocracyDay https://t.co/25ovVSWAFJ', 'Trump ...Trump\\n\\n..trump #Trump https://t.co/vHAZyS0LeZ', '#BlacklivesStillMatter  #BlackLivesMatter https://t.co/XQT3V5vGHZ', 'Yes, Biden ..... not Trump #BidenHarrisLandslide2020 https://t.co/TPYT11Zb4U', '..........and.............😭😭😭 #ThursdayThoughts https://t.co/WHWxf5D44L', 'Democratic Presidential Nominee Joe Biden had also warned Johnson that either he will respect Northern Ireland’s peace agreement or else he will get no U.S. trade deal. #HappyChenDay\\n #Trump #Covid19', 'Why should racism exist in America? For example, we are the first country in the world #Trump https://t.co/spSLY2UY47', 'Who is the idiot ... the one who extended the corona .... who is Trump according to Pelosi Corona herself #COVIDー19 https://t.co/Y5TRDpoZ6M', 'https://t.co/SRByuzX5jC', 'https://t.co/JVX1MaOxQG', 'Our president is ridiculous .... he is accused of raping a 13-year-old girl ...... #Trump #TrumpisaPedo https://t.co/BD3FsyXITS', 'This photo of racism is complete ........ does not want to be explained #Racism #Army #Democrats\\n #democracyday https://t.co/77OHHpy9qe', 'Are Democrats angry about Trump lying about vaccines?  NO.....NO\\n...NO #Trump2020\\n #COVID__19\\n #coronavirus  #Biden', 'The way to heaven https://t.co/Q1YJF6DZAA', 'https://t.co/gUd7uePIca', '32% reduction in Brazilian exports to the United States ..... Although the Trump administration is proud of its relations with Brazil, in practice it is something else #trump #Biden #TrumpKnew  #TrumpkillsAmericans https://t.co/mseaeJDB7O', 'In America, the law goes hand in hand with the police #seattleprotests https://t.co/n1FCwoCON8', '850 people die every day and Trump tells new lies every day #coronavirus\\n #COVID__19\\n #Covid_19 https://t.co/5CT3Q5AzE8', 'Health wants a long-term plan ... not like the Trump administration a few months ago did not believe in masks after a few months again when coronary heart disease spread .... #Health  #coronavirus  #COVID19 https://t.co/bU2vJxKs67', 'What are your plans for choosing Trump as the successor to the late Lady of American Justice? #trump', 'Corona is for all ages .... Mask is suitable for Corona .... Corona does not have any medicine at the moment #coronavirus https://t.co/5YrHdx72vI', '#Covid_19  #DemocracyDay https://t.co/UZS4xmbHRs', 'Biden and kissing granddaughter magically #Biden #trump #TrumpLandslideVictory2020\\n #BidenHarris2020 https://t.co/QDtqEOJPLU', 'Corona.....#coronavirus https://t.co/LcafZ6T7Fz', 'Deadly germs alert in Texas drinking water #COVIDー19 https://t.co/kB9TVzkdgE', '#COVID19 https://t.co/vcZAdxUnbx', 'https://t.co/Ke59HugLf5', 'Look.....👇😭😭😭😭😭😭 #TrumpTownHall https://t.co/CLpf9940mZ', 'Trump and Corona are destroying America together #Trump\\n #Corona\\n#TrumpPressConference https://t.co/0E1GVkA1ir', 'https://t.co/36dmHri4pG', '#TrumpTownHall https://t.co/WaF778uKj1', 'https://t.co/5hlUTfhf3g', 'smile https://t.co/nkfBCugmoJ', 'https://t.co/YcK6ypfmeQ', 'No important  ⚠More than 70% of Americans say the debates won’t matter much to them, a recent Wall Street Journal/NBC News #TrumpIsNotABillionaire\\n #TrumpTaxes  #Biden #VoteHimOut2020 https://t.co/y3dwMF3EnD', 'My veto protective mask #COVID19 https://t.co/LRxmlOrfN4', '❤😂❤😂❤ https://t.co/piQwxECUhp', 'Trump.....\\n\\n.Where is the vaccine liar? #COVID19 https://t.co/30NRZTXtNp', '#Trump https://t.co/YXBovhSAxr', 'Ginsburg Justice A beautiful dream might come true without Trump, yes without a fool #Biden #trump #BlackLivesMatter https://t.co/j1dVIrkTer', 'https://t.co/22wjWV5D1d', 'Trump is a tyrant ... the return of tyranny if Trump is elected in 2020 #TrumpIsNotABillionaire\\n #TrumpIsBroke\\n #TrumpTaxes https://t.co/tgDv3OzWWj', 'Wear a mask. The situation is bad. Do not listen to this dumb president #COVID__19\\n #coronavirus https://t.co/pwFAWCMy78', 'Think #DemocracyDay https://t.co/xwpL1RWvSx', 'From reality to lies from earth to sky ..... You are not American #ARMY  #trump #COVIDー19  #CoronaWarnApp  #BlackLivesMatter https://t.co/xqFPsiBE7g', 'Thanks  Obama. #DemocracyDay https://t.co/LrRdUgtWyv', 'https://t.co/XmlC8RJCKZ', 'https://t.co/JDbVJ8WGRD', 'Destruction https://t.co/oJFMnFDYO5', 'Why do you blame your shortcomings and your government on the states and condemn them? Trump .... Enough lies #Trump #Biden https://t.co/14wzsyfLtw', 'It just goes over his head whether he has the right to do so or not #DemocratsAreDestroyingAmerica\\n #BlackLivesMatter  #Seattle  #seattleprotests https://t.co/IxVmKrNPBK', 'Why are you lying so much about Trump that the vaccine was not produced in the end of betraying the Americans? #TrumpTownHall https://t.co/t1BeGBPtRa', 'https://t.co/RnIzFTK67y', 'A world proud of the future just for voting correctly #COVID19  #Trump https://t.co/4lJC0a2uXJ', 'https://t.co/JwwkPrT92u', 'https://t.co/eHgMb7kfRP', '❤❤❤❤The Miami Heat team reached the finals. The 6-year high ...... was ❤❤❤❤❤❤❤❤great', 'https://t.co/iunIsU9mAN', 'Corona ....... means an excuse for dismissal. Please see the problems of the economy #COVIDー19  #CoronaWarnApp https://t.co/Aj8VnDGslD', 'https://t.co/Qh74C0z9Ty', 'The CDC director says young people are expanding the corona #coronavirus  #Covid_19 https://t.co/a8ikKsIVBs', 'Racism in a country beyond the claims of humanity ..... is ridiculous #ThursdayThoughts\\n #BlackLivesMatter https://t.co/pTRUz1Xjxk', 'RT @annarmpeters: Deutschland ist, wenn nur 3 Polizist*innen Nazis davon abhalten, den Bundestag zu stürmen, aber Einheiten mit Hunden, Pfe…', 'RT @Shawwwwwn1: No ❤trump......2020 No 💚No💜 #TrumpCrimeFamily https://t.co/uLQ1kF1h8s', '@cnnbrk Yes.....This is awful', 'RT @Baligubadle1: @ProjectLincoln @pjlacasse22 Joe Biden should also have stoped the asteroid from wiping out the dinosaurs', 'RT @SenKamalaHarris: “My most fervent wish is that I will not be replaced until a new president is installed.” – Justice Ruth Bader Ginsbur…', 'RT @schland2014: @Rachet090604 @lonepalm99 @daveinla @Jim622 @JoeBiden The difference is how Trump handled the virus. He is a monster. #Tru…', 'RT @ThomasVanBarnes: All Trump Supporters believe Bidens truths as lies. But Believe Trumps lies as truths..How ironic. I mean most of the…', 'RT @JasonOverstreet: Sick! \\n\\nOne of the most disturbing things about Trump is how he has embraced and attempted to normalize so many distur…', 'RT @ThomasVanBarnes: So Trump supporters are saying \"Go see a therapist\" should we tell them to \"Go see a scientist\"??', '@ThomasVanBarnes Yes❤']\n"
     ]
    }
   ],
   "source": [
    "print(iter_of_lists.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-46ed5e84de72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_of_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "all_tokens(iter_of_lists['tweet_text'])[.head()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocess_tweet(all_tokens(iter_of_lists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(iterable_of_lists):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        iterable_of_lists: e.g. a dataframe or list of lists [of strings]\n",
    "    Return:\n",
    "        dict of {'word':'frequency'} sorted by frequency (high to low)\n",
    "    N.B.:\n",
    "        list(itertools.chain(*iterable_of_lists_of_strings))\n",
    "        # vs\n",
    "        list(*itertools.chain.from_iterable(iterable_of_lists_of_strings))\n",
    "    \"\"\"\n",
    "    \n",
    "    all_words = list(*itertools.chain.from_iterable(iterable_of_lists))\n",
    "    word_dict = dict()\n",
    "\n",
    "    for word in all_words:\n",
    "        if word in word_dict:\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "\n",
    "    # counts = collections.Counter(iterable_of_lists_of_strings)\n",
    "    \n",
    "    return sorted(word_dict.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokenize_iter() takes 1 positional argument but 209 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-5e1fa21a7dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miter_of_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenized_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tokenize_iter() takes 1 positional argument but 209 were given"
     ]
    }
   ],
   "source": [
    "tokenized_df = tokenize_iter(iter_of_lists)\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = word_frequency(tokenized_df)\n",
    "freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing\n",
    "\n",
    "Using sklearn's CountVectorizer to turn the corpus into a text-term matrix allows us to easily count tokens. CountVectorizer can count n-grams as well as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_matrix(list_of_strings,\n",
    "                      stop_words=None,\n",
    "                      ngram_range=(1,2)):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "       list_of_strings: iterable of strings\n",
    "       stop_words: a list of stop words or the string 'english' to use a\n",
    "                   built-in English language stop word list.\n",
    "                   Default: no stop words\n",
    "       ngram_range: a single int, or a 2 tuple representing the range of ngrams to count.\n",
    "                    Default: (1,2); counts 1- and 2- grams.\n",
    "    Return:\n",
    "       dataframe of counts indexed by n-gram\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer(analyzer='word',\n",
    "                                 tokenizer=tweet_tokenizer,\n",
    "                                 stop_words=stop_words,\n",
    "                                 ngram_range=ngram_range\n",
    "                                )\n",
    "    \n",
    "    ngram_freq_matrix = count_vectorizer.fit_transform(list_of_strings)\n",
    "    ngrams = count_vectorizer.get_feature_names()\n",
    "\n",
    "    return ngram_freq_matrix, ngrams\n",
    "\n",
    "def count_freq_matrix(ngram_freq_matrix):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ngram_frequencies = term_freq_matrix.sum(axis=0).tolist()[0]\n",
    "    freq_dict = dict(zip(terms, term_frequencies))\n",
    "    \n",
    "    return (pd.DataFrame(freq_dict, \n",
    "                         index_column='ngram'\n",
    "                         columns=['ngram', 'count'])\n",
    "                        .sort_values(\"count\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = all_text(all_tokens(list_df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = preprocess_tweet(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenize_df(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america',\n",
       " 'and',\n",
       " 'the',\n",
       " 'way',\n",
       " 'its',\n",
       " 'government',\n",
       " 'treats',\n",
       " 'its',\n",
       " 'people',\n",
       " 'must',\n",
       " 'be',\n",
       " 'reformed',\n",
       " 'https://t.co/DupN3cE2dd',\n",
       " 'https://t.co/ee5KZJMm5R',\n",
       " 'portland',\n",
       " 'police',\n",
       " 'bureau',\n",
       " 'is',\n",
       " 'preparing',\n",
       " 'for',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'mass',\n",
       " 'gathering',\n",
       " 'events',\n",
       " 'being',\n",
       " 'planned',\n",
       " 'for',\n",
       " 'saturday',\n",
       " 'september',\n",
       " '26',\n",
       " '2020',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'one',\n",
       " 'group',\n",
       " 'has',\n",
       " 'been',\n",
       " 'announced',\n",
       " 'they',\n",
       " 'will',\n",
       " 'hold',\n",
       " 'an',\n",
       " 'event',\n",
       " 'at',\n",
       " 'delta',\n",
       " 'park',\n",
       " 'at',\n",
       " 'noon',\n",
       " '#policelivesmatter',\n",
       " '#polizeigewalt',\n",
       " '#portland',\n",
       " '#portlandprotests',\n",
       " 'https://t.co/3JSoa0UcOL',\n",
       " 'why',\n",
       " 'lies',\n",
       " '...',\n",
       " 'why',\n",
       " 'hypocrisy',\n",
       " '...',\n",
       " 'why',\n",
       " 'security',\n",
       " 'forces',\n",
       " '...',\n",
       " 'why',\n",
       " 'racism',\n",
       " '...',\n",
       " 'why',\n",
       " 'cut',\n",
       " 'budgets',\n",
       " '...',\n",
       " 'to',\n",
       " 'deceive',\n",
       " 'people',\n",
       " 'no',\n",
       " 'trump',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " '#army',\n",
       " '#covidー19',\n",
       " '#biden',\n",
       " '#trump',\n",
       " 'https://t.co/v1WYXyidzJ',\n",
       " 'difference',\n",
       " '#biden',\n",
       " 'https://t.co/Vl5lB7q2l6',\n",
       " 'he',\n",
       " 'has',\n",
       " 'destroyed',\n",
       " 'every',\n",
       " 'busines',\n",
       " '...',\n",
       " '🐂',\n",
       " '🐃',\n",
       " '🐃',\n",
       " '🐃',\n",
       " '#trumpmeltdown',\n",
       " 'https://t.co/tKrPEdujCZ',\n",
       " 'even',\n",
       " 'if',\n",
       " 'the',\n",
       " 'power',\n",
       " 'to',\n",
       " 'negotiate',\n",
       " 'deals',\n",
       " 'is',\n",
       " 'handed',\n",
       " 'over',\n",
       " 'to',\n",
       " 'the',\n",
       " 'presidency',\n",
       " 'congress',\n",
       " 'will',\n",
       " 'still',\n",
       " 'have',\n",
       " 'the',\n",
       " 'final',\n",
       " 'say',\n",
       " 'and',\n",
       " 'judging',\n",
       " 'by',\n",
       " 'the',\n",
       " 'current',\n",
       " 'political',\n",
       " 'climate',\n",
       " 'johnson',\n",
       " 'will',\n",
       " 'not',\n",
       " 'fire',\n",
       " 'him',\n",
       " 'this',\n",
       " 'time',\n",
       " '#trump',\n",
       " '#covid_19',\n",
       " '#democracyday',\n",
       " 'https://t.co/25ovVSWAFJ',\n",
       " 'trump',\n",
       " '...',\n",
       " 'trump',\n",
       " '..',\n",
       " 'trump',\n",
       " '#trump',\n",
       " 'https://t.co/vHAZyS0LeZ',\n",
       " '#blacklivesstillmatter',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/XQT3V5vGHZ',\n",
       " 'yes',\n",
       " 'biden',\n",
       " '...',\n",
       " 'not',\n",
       " 'trump',\n",
       " '#bidenharrislandslide2020',\n",
       " 'https://t.co/TPYT11Zb4U',\n",
       " '...',\n",
       " 'and',\n",
       " '...',\n",
       " '😭',\n",
       " '😭',\n",
       " '😭',\n",
       " '#thursdaythoughts',\n",
       " 'https://t.co/WHWxf5D44L',\n",
       " 'democratic',\n",
       " 'presidential',\n",
       " 'nominee',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'had',\n",
       " 'also',\n",
       " 'warned',\n",
       " 'johnson',\n",
       " 'that',\n",
       " 'either',\n",
       " 'he',\n",
       " 'will',\n",
       " 'respect',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " '’',\n",
       " 's',\n",
       " 'peace',\n",
       " 'agreement',\n",
       " 'or',\n",
       " 'else',\n",
       " 'he',\n",
       " 'will',\n",
       " 'get',\n",
       " 'no',\n",
       " 'u',\n",
       " 's',\n",
       " 'trade',\n",
       " 'deal',\n",
       " '#happychenday',\n",
       " '#trump',\n",
       " '#covid19',\n",
       " 'why',\n",
       " 'should',\n",
       " 'racism',\n",
       " 'exist',\n",
       " 'in',\n",
       " 'america',\n",
       " 'for',\n",
       " 'example',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'first',\n",
       " 'country',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '#trump',\n",
       " 'https://t.co/spSLY2UY47',\n",
       " 'who',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idiot',\n",
       " '...',\n",
       " 'the',\n",
       " 'one',\n",
       " 'who',\n",
       " 'extended',\n",
       " 'the',\n",
       " 'corona',\n",
       " '...',\n",
       " 'who',\n",
       " 'is',\n",
       " 'trump',\n",
       " 'according',\n",
       " 'to',\n",
       " 'pelosi',\n",
       " 'corona',\n",
       " 'herself',\n",
       " '#covidー19',\n",
       " 'https://t.co/Y5TRDpoZ6M',\n",
       " 'https://t.co/SRByuzX5jC',\n",
       " 'https://t.co/JVX1MaOxQG',\n",
       " 'our',\n",
       " 'president',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '...',\n",
       " 'he',\n",
       " 'is',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'raping',\n",
       " 'a',\n",
       " '13',\n",
       " 'year-old',\n",
       " 'girl',\n",
       " '...',\n",
       " '#trump',\n",
       " '#trumpisapedo',\n",
       " 'https://t.co/BD3FsyXITS',\n",
       " 'this',\n",
       " 'photo',\n",
       " 'of',\n",
       " 'racism',\n",
       " 'is',\n",
       " 'complete',\n",
       " '...',\n",
       " 'does',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'explained',\n",
       " '#racism',\n",
       " '#army',\n",
       " '#democrats',\n",
       " '#democracyday',\n",
       " 'https://t.co/77OHHpy9qe',\n",
       " 'are',\n",
       " 'democrats',\n",
       " 'angry',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'lying',\n",
       " 'about',\n",
       " 'vaccines',\n",
       " 'no',\n",
       " '...',\n",
       " 'no',\n",
       " '...',\n",
       " 'no',\n",
       " '#trump2020',\n",
       " '#covid__19',\n",
       " '#coronavirus',\n",
       " '#biden',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'heaven',\n",
       " 'https://t.co/Q1YJF6DZAA',\n",
       " 'https://t.co/gUd7uePIca',\n",
       " '32',\n",
       " 'reduction',\n",
       " 'in',\n",
       " 'brazilian',\n",
       " 'exports',\n",
       " 'to',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '...',\n",
       " 'although',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'its',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'brazil',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'it',\n",
       " 'is',\n",
       " 'something',\n",
       " 'else',\n",
       " '#trump',\n",
       " '#biden',\n",
       " '#trumpknew',\n",
       " '#trumpkillsamericans',\n",
       " 'https://t.co/mseaeJDB7O',\n",
       " 'in',\n",
       " 'america',\n",
       " 'the',\n",
       " 'law',\n",
       " 'goes',\n",
       " 'hand',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'with',\n",
       " 'the',\n",
       " 'police',\n",
       " '#seattleprotests',\n",
       " 'https://t.co/n1FCwoCON8',\n",
       " '850',\n",
       " 'people',\n",
       " 'die',\n",
       " 'every',\n",
       " 'day',\n",
       " 'and',\n",
       " 'trump',\n",
       " 'tells',\n",
       " 'new',\n",
       " 'lies',\n",
       " 'every',\n",
       " 'day',\n",
       " '#coronavirus',\n",
       " '#covid__19',\n",
       " '#covid_19',\n",
       " 'https://t.co/5CT3Q5AzE8',\n",
       " 'health',\n",
       " 'wants',\n",
       " 'a',\n",
       " 'long-term',\n",
       " 'plan',\n",
       " '...',\n",
       " 'not',\n",
       " 'like',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'did',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'masks',\n",
       " 'after',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'again',\n",
       " 'when',\n",
       " 'coronary',\n",
       " 'heart',\n",
       " 'disease',\n",
       " 'spread',\n",
       " '...',\n",
       " '#health',\n",
       " '#coronavirus',\n",
       " '#covid19',\n",
       " 'https://t.co/bU2vJxKs67',\n",
       " 'what',\n",
       " 'are',\n",
       " 'your',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'choosing',\n",
       " 'trump',\n",
       " 'as',\n",
       " 'the',\n",
       " 'successor',\n",
       " 'to',\n",
       " 'the',\n",
       " 'late',\n",
       " 'lady',\n",
       " 'of',\n",
       " 'american',\n",
       " 'justice',\n",
       " '#trump',\n",
       " 'corona',\n",
       " 'is',\n",
       " 'for',\n",
       " 'all',\n",
       " 'ages',\n",
       " '...',\n",
       " 'mask',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'corona',\n",
       " '...',\n",
       " 'corona',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'medicine',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " '#coronavirus',\n",
       " 'https://t.co/5YrHdx72vI',\n",
       " '#covid_19',\n",
       " '#democracyday',\n",
       " 'https://t.co/UZS4xmbHRs',\n",
       " 'biden',\n",
       " 'and',\n",
       " 'kissing',\n",
       " 'granddaughter',\n",
       " 'magically',\n",
       " '#biden',\n",
       " '#trump',\n",
       " '#trumplandslidevictory2020',\n",
       " '#bidenharris2020',\n",
       " 'https://t.co/QDtqEOJPLU',\n",
       " 'corona',\n",
       " '...',\n",
       " '#coronavirus',\n",
       " 'https://t.co/LcafZ6T7Fz',\n",
       " 'deadly',\n",
       " 'germs',\n",
       " 'alert',\n",
       " 'in',\n",
       " 'texas',\n",
       " 'drinking',\n",
       " 'water',\n",
       " '#covidー19',\n",
       " 'https://t.co/kB9TVzkdgE',\n",
       " '#covid19',\n",
       " 'https://t.co/vcZAdxUnbx',\n",
       " 'https://t.co/Ke59HugLf5',\n",
       " 'look',\n",
       " '...',\n",
       " '👇',\n",
       " '😭',\n",
       " '😭',\n",
       " '😭',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/CLpf9940mZ',\n",
       " 'trump',\n",
       " 'and',\n",
       " 'corona',\n",
       " 'are',\n",
       " 'destroying',\n",
       " 'america',\n",
       " 'together',\n",
       " '#trump',\n",
       " '#corona',\n",
       " '#trumppressconference',\n",
       " 'https://t.co/0E1GVkA1ir',\n",
       " 'https://t.co/36dmHri4pG',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/WaF778uKj1',\n",
       " 'https://t.co/5hlUTfhf3g',\n",
       " 'smile',\n",
       " 'https://t.co/nkfBCugmoJ',\n",
       " 'https://t.co/YcK6ypfmeQ',\n",
       " 'no',\n",
       " 'important',\n",
       " '⚠',\n",
       " 'more',\n",
       " 'than',\n",
       " '70',\n",
       " 'of',\n",
       " 'americans',\n",
       " 'say',\n",
       " 'the',\n",
       " 'debates',\n",
       " 'won',\n",
       " '’',\n",
       " 't',\n",
       " 'matter',\n",
       " 'much',\n",
       " 'to',\n",
       " 'them',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'journal',\n",
       " 'nbc',\n",
       " 'news',\n",
       " '#trumpisnotabillionaire',\n",
       " '#trumptaxes',\n",
       " '#biden',\n",
       " '#votehimout2020',\n",
       " 'https://t.co/y3dwMF3EnD',\n",
       " 'my',\n",
       " 'veto',\n",
       " 'protective',\n",
       " 'mask',\n",
       " '#covid19',\n",
       " 'https://t.co/LRxmlOrfN4',\n",
       " '❤',\n",
       " '😂',\n",
       " '❤',\n",
       " '😂',\n",
       " '❤',\n",
       " 'https://t.co/piQwxECUhp',\n",
       " 'trump',\n",
       " '...\\n\\n.',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'liar',\n",
       " '#covid19',\n",
       " 'https://t.co/30NRZTXtNp',\n",
       " '#trump',\n",
       " 'https://t.co/YXBovhSAxr',\n",
       " 'ginsburg',\n",
       " 'justice',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'dream',\n",
       " 'might',\n",
       " 'come',\n",
       " 'true',\n",
       " 'without',\n",
       " 'trump',\n",
       " 'yes',\n",
       " 'without',\n",
       " 'a',\n",
       " 'fool',\n",
       " '#biden',\n",
       " '#trump',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/j1dVIrkTer',\n",
       " 'https://t.co/22wjWV5D1d',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'a',\n",
       " 'tyrant',\n",
       " '...',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'tyranny',\n",
       " 'if',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'elected',\n",
       " 'in',\n",
       " '2020',\n",
       " '#trumpisnotabillionaire',\n",
       " '#trumpisbroke',\n",
       " '#trumptaxes',\n",
       " 'https://t.co/tgDv3OzWWj',\n",
       " 'wear',\n",
       " 'a',\n",
       " 'mask',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'do',\n",
       " 'not',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'dumb',\n",
       " 'president',\n",
       " '#covid__19',\n",
       " '#coronavirus',\n",
       " 'https://t.co/pwFAWCMy78',\n",
       " 'think',\n",
       " '#democracyday',\n",
       " 'https://t.co/xwpL1RWvSx',\n",
       " 'from',\n",
       " 'reality',\n",
       " 'to',\n",
       " 'lies',\n",
       " 'from',\n",
       " 'earth',\n",
       " 'to',\n",
       " 'sky',\n",
       " '...',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'american',\n",
       " '#army',\n",
       " '#trump',\n",
       " '#covidー19',\n",
       " '#coronawarnapp',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/xqFPsiBE7g',\n",
       " 'thanks',\n",
       " 'obama',\n",
       " '#democracyday',\n",
       " 'https://t.co/LrRdUgtWyv',\n",
       " 'https://t.co/XmlC8RJCKZ',\n",
       " 'https://t.co/JDbVJ8WGRD',\n",
       " 'destruction',\n",
       " 'https://t.co/oJFMnFDYO5',\n",
       " 'why',\n",
       " 'do',\n",
       " 'you',\n",
       " 'blame',\n",
       " 'your',\n",
       " 'shortcomings',\n",
       " 'and',\n",
       " 'your',\n",
       " 'government',\n",
       " 'on',\n",
       " 'the',\n",
       " 'states',\n",
       " 'and',\n",
       " 'condemn',\n",
       " 'them',\n",
       " 'trump',\n",
       " '...',\n",
       " 'enough',\n",
       " 'lies',\n",
       " '#trump',\n",
       " '#biden',\n",
       " 'https://t.co/14wzsyfLtw',\n",
       " 'it',\n",
       " 'just',\n",
       " 'goes',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " 'whether',\n",
       " 'he',\n",
       " 'has',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'or',\n",
       " 'not',\n",
       " '#democratsaredestroyingamerica',\n",
       " '#blacklivesmatter',\n",
       " '#seattle',\n",
       " '#seattleprotests',\n",
       " 'https://t.co/IxVmKrNPBK',\n",
       " 'why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'lying',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'that',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'was',\n",
       " 'not',\n",
       " 'produced',\n",
       " 'in',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'betraying',\n",
       " 'the',\n",
       " 'americans',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/t1BeGBPtRa',\n",
       " 'https://t.co/RnIzFTK67y',\n",
       " 'a',\n",
       " 'world',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'just',\n",
       " 'for',\n",
       " 'voting',\n",
       " 'correctly',\n",
       " '#covid19',\n",
       " '#trump',\n",
       " 'https://t.co/4lJC0a2uXJ',\n",
       " 'https://t.co/JwwkPrT92u',\n",
       " 'https://t.co/eHgMb7kfRP',\n",
       " '❤',\n",
       " '❤',\n",
       " '❤',\n",
       " 'the',\n",
       " 'miami',\n",
       " 'heat',\n",
       " 'team',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'finals',\n",
       " 'the',\n",
       " '6',\n",
       " 'year',\n",
       " 'high',\n",
       " '...',\n",
       " 'was',\n",
       " '❤',\n",
       " '❤',\n",
       " '❤',\n",
       " 'great',\n",
       " 'https://t.co/iunIsU9mAN',\n",
       " 'corona',\n",
       " '...',\n",
       " 'means',\n",
       " 'an',\n",
       " 'excuse',\n",
       " 'for',\n",
       " 'dismissal',\n",
       " 'please',\n",
       " 'see',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'the',\n",
       " 'economy',\n",
       " '#covidー19',\n",
       " '#coronawarnapp',\n",
       " 'https://t.co/Aj8VnDGslD',\n",
       " 'https://t.co/Qh74C0z9Ty',\n",
       " 'the',\n",
       " 'cdc',\n",
       " 'director',\n",
       " 'says',\n",
       " 'young',\n",
       " 'people',\n",
       " 'are',\n",
       " 'expanding',\n",
       " 'the',\n",
       " 'corona',\n",
       " '#coronavirus',\n",
       " '#covid_19',\n",
       " 'https://t.co/a8ikKsIVBs',\n",
       " 'racism',\n",
       " 'in',\n",
       " 'a',\n",
       " 'country',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'claims',\n",
       " 'of',\n",
       " 'humanity',\n",
       " '...',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '#thursdaythoughts',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/pTRUz1Xjxk',\n",
       " 'rt',\n",
       " '@annarmpeters',\n",
       " 'deutschland',\n",
       " 'ist',\n",
       " 'wenn',\n",
       " 'nur',\n",
       " '3',\n",
       " 'polizist',\n",
       " 'innen',\n",
       " 'nazis',\n",
       " 'davon',\n",
       " 'abhalten',\n",
       " 'den',\n",
       " 'bundestag',\n",
       " 'zu',\n",
       " 'stürmen',\n",
       " 'aber',\n",
       " 'einheiten',\n",
       " 'mit',\n",
       " 'hunden',\n",
       " 'pfe',\n",
       " '…',\n",
       " 'rt',\n",
       " '@shawwwn1',\n",
       " 'no',\n",
       " '❤',\n",
       " 'trump',\n",
       " '...',\n",
       " '2020',\n",
       " 'no',\n",
       " '💚',\n",
       " 'no',\n",
       " '💜',\n",
       " '#trumpcrimefamily',\n",
       " 'https://t.co/uLQ1kF1h8s',\n",
       " '@cnnbrk',\n",
       " 'yes',\n",
       " '...',\n",
       " 'this',\n",
       " 'is',\n",
       " 'awful',\n",
       " 'rt',\n",
       " '@baligubadle1',\n",
       " '@projectlincoln',\n",
       " '@pjlacasse22',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'should',\n",
       " 'also',\n",
       " 'have',\n",
       " 'stoped',\n",
       " 'the',\n",
       " 'asteroid',\n",
       " 'from',\n",
       " 'wiping',\n",
       " 'out',\n",
       " 'the',\n",
       " 'dinosaurs',\n",
       " 'rt',\n",
       " '@senkamalaharris',\n",
       " '“',\n",
       " 'my',\n",
       " 'most',\n",
       " 'fervent',\n",
       " 'wish',\n",
       " 'is',\n",
       " 'that',\n",
       " 'i',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'replaced',\n",
       " 'until',\n",
       " 'a',\n",
       " 'new',\n",
       " 'president',\n",
       " 'is',\n",
       " 'installed',\n",
       " '”',\n",
       " '–',\n",
       " 'justice',\n",
       " 'ruth',\n",
       " 'bader',\n",
       " 'ginsbur',\n",
       " '…',\n",
       " 'rt',\n",
       " '@schland2014',\n",
       " '@rachet090604',\n",
       " '@lonepalm99',\n",
       " '@daveinla',\n",
       " '@jim622',\n",
       " '@joebiden',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'how',\n",
       " 'trump',\n",
       " 'handled',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'monster',\n",
       " '#tru',\n",
       " '…',\n",
       " 'rt',\n",
       " '@thomasvanbarnes',\n",
       " 'all',\n",
       " 'trump',\n",
       " 'supporters',\n",
       " 'believe',\n",
       " 'bidens',\n",
       " 'truths',\n",
       " 'as',\n",
       " 'lies',\n",
       " 'but',\n",
       " 'believe',\n",
       " 'trumps',\n",
       " 'lies',\n",
       " 'as',\n",
       " 'truths',\n",
       " '..',\n",
       " 'how',\n",
       " 'ironic',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " '…',\n",
       " 'rt',\n",
       " '@jasonoverstreet',\n",
       " 'sick',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'disturbing',\n",
       " 'things',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'how',\n",
       " 'he',\n",
       " 'has',\n",
       " 'embraced',\n",
       " 'and',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'normalize',\n",
       " 'so',\n",
       " 'many',\n",
       " 'distur',\n",
       " '…',\n",
       " 'rt',\n",
       " '@thomasvanbarnes',\n",
       " 'so',\n",
       " 'trump',\n",
       " 'supporters',\n",
       " 'are',\n",
       " 'saying',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'therapist',\n",
       " 'should',\n",
       " 'we',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'to',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'scientist',\n",
       " '@thomasvanbarnes',\n",
       " 'yes',\n",
       " '❤',\n",
       " '@manotonews',\n",
       " 'اگه',\n",
       " 'ایران',\n",
       " 'به',\n",
       " 'یمن',\n",
       " 'و',\n",
       " 'مقاومت',\n",
       " 'کمک',\n",
       " 'نکنه',\n",
       " 'خاک',\n",
       " 'تو',\n",
       " 'سرش',\n",
       " 'لطفا',\n",
       " 'کسانی',\n",
       " 'که',\n",
       " 'واسه',\n",
       " 'ایران',\n",
       " 'و',\n",
       " 'مردم',\n",
       " 'سیل',\n",
       " 'زده',\n",
       " 'کمک',\n",
       " 'نکردند',\n",
       " 'نظر',\n",
       " 'ندن',\n",
       " '🔘',\n",
       " 'پهباد',\n",
       " 'سه',\n",
       " 'تا',\n",
       " '۱۰۰۰',\n",
       " 'یورو',\n",
       " '🔘',\n",
       " 'موشک',\n",
       " 'سوا',\n",
       " 'کن',\n",
       " 'جدا',\n",
       " 'کن',\n",
       " 'ببر',\n",
       " 'دعا',\n",
       " 'کن',\n",
       " 'دونه',\n",
       " 'ای',\n",
       " '۱۰۰۰',\n",
       " 'یورو',\n",
       " '🔘',\n",
       " ...]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('america', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('its', 'PRP$'),\n",
       " ('government', 'NN'),\n",
       " ('treats', 'VBZ'),\n",
       " ('its', 'PRP$'),\n",
       " ('people', 'NNS'),\n",
       " ('must', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('reformed', 'VBN'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('poland', 'NN'),\n",
       " ('police', 'NN'),\n",
       " ('bureau', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('preparing', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('variety', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('gathering', 'NN'),\n",
       " ('events', 'NNS'),\n",
       " ('being', 'VBG'),\n",
       " ('planned', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('saturday', 'JJ'),\n",
       " ('september', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('one', 'CD'),\n",
       " ('group', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('announced', 'VBN'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('hold', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('delta', 'NN'),\n",
       " ('park', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('noon', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('lies', 'VBZ'),\n",
       " ('why', 'WRB'),\n",
       " ('hypocrisy', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('security', 'NN'),\n",
       " ('forces', 'NNS'),\n",
       " ('why', 'WRB'),\n",
       " ('racism', 'NN'),\n",
       " ('why', 'WRB'),\n",
       " ('cut', 'NN'),\n",
       " ('budgets', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('deceive', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('no', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('no', 'RB'),\n",
       " ('no', 'DT'),\n",
       " ('no', 'DT'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('difference', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('destroyed', 'VBN'),\n",
       " ('every', 'DT'),\n",
       " ('busines', 'NNS'),\n",
       " ('🐂', 'VBP'),\n",
       " ('🐃', 'JJ'),\n",
       " ('🐃', 'NNP'),\n",
       " ('🐃', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('even', 'RB'),\n",
       " ('if', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('power', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('negotiate', 'JJ'),\n",
       " ('deals', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('handed', 'VBN'),\n",
       " ('over', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('presidency', 'NN'),\n",
       " ('congress', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('still', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('final', 'JJ'),\n",
       " ('say', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('judging', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('political', 'JJ'),\n",
       " ('climate', 'NN'),\n",
       " ('johnson', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('fire', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('this', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('trump', 'NN'),\n",
       " ('trump', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('biden', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('trump', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('😭', 'NNP'),\n",
       " ('😭', 'NNP'),\n",
       " ('😭', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NNP'),\n",
       " ('democratic', 'JJ'),\n",
       " ('presidential', 'JJ'),\n",
       " ('nominee', 'NN'),\n",
       " ('joe', 'NN'),\n",
       " ('biden', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('also', 'RB'),\n",
       " ('warned', 'VBN'),\n",
       " ('johnson', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('either', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('respect', 'VB'),\n",
       " ('nohern', 'JJ'),\n",
       " ('ireland', 'NN'),\n",
       " ('’', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('peace', 'NN'),\n",
       " ('agreement', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('else', 'RB'),\n",
       " ('he', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('get', 'VB'),\n",
       " ('no', 'DT'),\n",
       " ('us', 'PRP'),\n",
       " ('trade', 'VB'),\n",
       " ('deal', 'VB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('should', 'MD'),\n",
       " ('racism', 'VB'),\n",
       " ('exist', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('america', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('example', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('country', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('idiot', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('one', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('extended', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('corona', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('trump', 'JJ'),\n",
       " ('according', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('pelosi', 'VB'),\n",
       " ('corona', 'VB'),\n",
       " ('herself', 'PRP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('our', 'PRP$'),\n",
       " ('president', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('ridiculous', 'JJ'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('accused', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('raping', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('-', ':'),\n",
       " ('year-old', 'JJ'),\n",
       " ('girl', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('photo', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('racism', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('complete', 'JJ'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('explained', 'VBN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('democrats', 'VBN'),\n",
       " ('angry', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('lying', 'VBG'),\n",
       " ('about', 'IN'),\n",
       " ('vaccines', 'NNS'),\n",
       " ('nono', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('heaven', 'VB'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('reduction', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('brazilian', 'JJ'),\n",
       " ('expos', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('united', 'JJ'),\n",
       " ('states', 'NNS'),\n",
       " ('although', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('trump', 'JJ'),\n",
       " ('administration', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('proud', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('relations', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('brazil', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('practice', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('something', 'NN'),\n",
       " ('else', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('america', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('law', 'NN'),\n",
       " ('goes', 'VBZ'),\n",
       " ('hand', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('hand', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('police', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('die', 'VBP'),\n",
       " ('every', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('trump', 'NN'),\n",
       " ('tells', 'NNS'),\n",
       " ('new', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('every', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('health', 'NN'),\n",
       " ('wants', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('long-term', 'JJ'),\n",
       " ('plan', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('administration', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('ago', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('believe', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('masks', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('again', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('coronary', 'JJ'),\n",
       " ('hea', 'NN'),\n",
       " ('disease', 'NN'),\n",
       " ('spread', 'VBD'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('what', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('plans', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('choosing', 'VBG'),\n",
       " ('trump', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('successor', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('late', 'JJ'),\n",
       " ('lady', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('american', 'JJ'),\n",
       " ('justice', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('ages', 'NNS'),\n",
       " ('mask', 'VBP'),\n",
       " ('is', 'VBZ'),\n",
       " ('suitable', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('corona', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('medicine', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('biden', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('kissing', 'VBG'),\n",
       " ('granddaughter', 'NN'),\n",
       " ('magically', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('corona', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('deadly', 'RB'),\n",
       " ('germs', 'NNS'),\n",
       " ('ale', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('texas', 'NN'),\n",
       " ('drinking', 'NN'),\n",
       " ('water', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('look', 'NN'),\n",
       " ('👇', 'NNP'),\n",
       " ('😭', 'NNP'),\n",
       " ('😭', 'NNP'),\n",
       " ('😭', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('corona', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('destroying', 'VBG'),\n",
       " ('america', 'IN'),\n",
       " ('together', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('smile', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('impoant', 'JJ'),\n",
       " ('⚠', 'VBZ'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('americans', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('debates', 'NNS'),\n",
       " ('won', 'VBD'),\n",
       " ('’', 'JJ'),\n",
       " ('t', 'JJ'),\n",
       " ('matter', 'NN'),\n",
       " ('much', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('them', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('recent', 'JJ'),\n",
       " ('wall', 'NN'),\n",
       " ('street', 'NN'),\n",
       " ('journalnbc', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('veto', 'NN'),\n",
       " ('protective', 'JJ'),\n",
       " ('mask', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('❤', 'NN'),\n",
       " ('😂', 'NNP'),\n",
       " ('❤', 'NNP'),\n",
       " ('😂', 'NNP'),\n",
       " ('❤', 'NNP'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('vaccine', 'NN'),\n",
       " ('liar', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('ginsburg', 'NN'),\n",
       " ('justice', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('dream', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('come', 'VB'),\n",
       " ('true', 'JJ'),\n",
       " ('without', 'IN'),\n",
       " ('trump', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('without', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('fool', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('tyrant', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('tyranny', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('elected', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('wear', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('mask', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('situation', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('bad', 'JJ'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('listen', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('this', 'DT'),\n",
       " ('dumb', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('think', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('reality', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('lies', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('eah', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('sky', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('american', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('thanks', 'NNS'),\n",
       " ('obama', 'IN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('destruction', 'NN'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('blame', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('shocomings', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('your', 'PRP$'),\n",
       " ('government', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('states', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('condemn', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('trump', 'VB'),\n",
       " ('enough', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('goes', 'VBZ'),\n",
       " ('over', 'RP'),\n",
       " ('his', 'PRP$'),\n",
       " ('head', 'NN'),\n",
       " ('whether', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('or', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('lying', 'VBG'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('vaccine', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('produced', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('betraying', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('americans', 'NNS'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('proud', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('future', 'NN'),\n",
       " ('just', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('voting', 'VBG'),\n",
       " ('correctly', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('❤', 'NN'),\n",
       " ('❤', 'NNP'),\n",
       " ('❤', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('miami', 'NN'),\n",
       " ('heat', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('reached', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('finals', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('-', ':'),\n",
       " ('year', 'NN'),\n",
       " ('high', 'JJ'),\n",
       " ('was', 'VBD'),\n",
       " ('❤', 'JJ'),\n",
       " ('❤', 'NNP'),\n",
       " ('❤', 'NNP'),\n",
       " ('great', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('excuse', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('dismissal', 'NN'),\n",
       " ('please', 'NN'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('problems', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('economy', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('cdc', 'NNS'),\n",
       " ('director', 'NN'),\n",
       " ('says', 'VBZ'),\n",
       " ('young', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('expanding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('corona', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('racism', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('country', 'NN'),\n",
       " ('beyond', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('claims', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('humanity', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('ridiculous', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('deutschland', 'NN'),\n",
       " ('ist', 'NN'),\n",
       " ('wenn', 'NN'),\n",
       " ('nur', 'JJ'),\n",
       " ('polizistinnen', 'NN'),\n",
       " ('nazis', 'NN'),\n",
       " ('davon', 'VBD'),\n",
       " ('abhalten', 'JJ'),\n",
       " ('den', 'JJ'),\n",
       " ('bundestag', 'NN'),\n",
       " ('zu', 'NN'),\n",
       " ('stürmen', 'NNS'),\n",
       " ('aber', 'VBP'),\n",
       " ('einheiten', 'JJ'),\n",
       " ('mit', 'NN'),\n",
       " ('hunden', 'NN'),\n",
       " ('pfe', 'NN'),\n",
       " ('…', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('❤', 'NNP'),\n",
       " ('trump', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('💚', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('💜', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('yesthis', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('awful', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('joe', 'NN'),\n",
       " ('biden', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('stoped', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('asteroid', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('wiping', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('dinosaurs', 'NNS'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('“', 'NNP'),\n",
       " ('my', 'PRP$'),\n",
       " ('most', 'JJS'),\n",
       " ('fervent', 'JJ'),\n",
       " ('wish', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('replaced', 'VBN'),\n",
       " ('until', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('installed', 'VBN'),\n",
       " ('”', 'JJ'),\n",
       " ('–', 'NNP'),\n",
       " ('justice', 'NN'),\n",
       " ('ruth', 'NN'),\n",
       " ('bader', 'NN'),\n",
       " ('ginsbur', 'NN'),\n",
       " ('…', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('difference', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('trump', 'JJ'),\n",
       " ('handled', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('virus', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('monster', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('…', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('all', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('suppoers', 'NNS'),\n",
       " ('believe', 'VBP'),\n",
       " ('bidens', 'VBZ'),\n",
       " ('truths', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('lies', 'NNS'),\n",
       " ('but', 'CC'),\n",
       " ('believe', 'VBP'),\n",
       " ('trumps', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('truthshow', 'NN'),\n",
       " ('ironic', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('mean', 'VBP'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('…', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('sick', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('disturbing', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('embraced', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('attempted', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('normalize', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('distur', 'JJ'),\n",
       " ('…', 'JJ'),\n",
       " ('<-@->', 'NNS'),\n",
       " ('so', 'RB'),\n",
       " ('trump', 'JJ'),\n",
       " ('suppoers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('saying', 'VBG'),\n",
       " ('go', 'VB'),\n",
       " ('see', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('therapist', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('we', 'PRP'),\n",
       " ('tell', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('see', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('scientist', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('❤', 'POS'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('اگه', 'NN'),\n",
       " ('ایران', 'NNP'),\n",
       " ('به', 'NNP'),\n",
       " ('یمن', 'NNP'),\n",
       " ('و', 'NNP'),\n",
       " ('مقاومت', 'NNP'),\n",
       " ('کمک', 'NNP'),\n",
       " ('نکنه', 'NNP'),\n",
       " ('خاک', 'NNP'),\n",
       " ('تو', 'NNP'),\n",
       " ('سرش', 'NNP'),\n",
       " ('لطفا', 'NNP'),\n",
       " ('کسانی', 'NNP'),\n",
       " ('که', 'NNP'),\n",
       " ('واسه', 'NNP'),\n",
       " ('ایران', 'NNP'),\n",
       " ('و', 'NNP'),\n",
       " ('مردم', 'NNP'),\n",
       " ('سیل', 'NNP'),\n",
       " ('زده', 'NNP'),\n",
       " ('کمک', 'NNP'),\n",
       " ('نکردند', 'NNP'),\n",
       " ('نظر', 'NNP'),\n",
       " ('ندن', 'NNP'),\n",
       " ('🔘', 'NNP'),\n",
       " ('پهباد', 'NNP'),\n",
       " ('سه', 'NNP'),\n",
       " ('تا', 'NNP'),\n",
       " ('۱۰۰۰', 'CD'),\n",
       " ('یورو', 'NNP'),\n",
       " ('🔘', 'NNP'),\n",
       " ('موشک', 'NNP'),\n",
       " ('سوا', 'NNP'),\n",
       " ('کن', 'NNP'),\n",
       " ('جدا', 'NNP'),\n",
       " ('کن', 'NNP'),\n",
       " ('ببر', 'NNP'),\n",
       " ('دعا', 'NNP'),\n",
       " ('کن', 'NNP'),\n",
       " ('دونه', 'NNP'),\n",
       " ('ای', 'NNP'),\n",
       " ('۱۰۰۰', 'CD'),\n",
       " ('یورو', 'NNP'),\n",
       " ('🔘', 'NNP'),\n",
       " ('ناو', 'NNP'),\n",
       " ('غنیمتی', 'NNP'),\n",
       " ('با', 'NNP'),\n",
       " ('خدمه', 'NNP'),\n",
       " ('آمریکایی', 'NNP'),\n",
       " ('رایگان', 'NNP'),\n",
       " ('🔘', 'NNP'),\n",
       " ('ناو', 'NNP'),\n",
       " ('بدون', 'NNP'),\n",
       " ('خدمه', 'NNP'),\n",
       " ('قسطی', 'NNP'),\n",
       " ('ماهی', 'NNP'),\n",
       " ('۱۰۰۰', 'CD'),\n",
       " ('یورو', 'NNP'),\n",
       " ('بدو', 'NNP'),\n",
       " ('اینور', 'NNP'),\n",
       " ('بازار', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('بعضی', 'NNP'),\n",
       " ('که', 'NNP'),\n",
       " ('میرن', 'NNP'),\n",
       " ('خارج', 'NNP'),\n",
       " ('که', 'NNP'),\n",
       " ('مثلا', 'NNP'),\n",
       " ('آزاد', 'NNP'),\n",
       " ('باشن', 'NNP'),\n",
       " ('،', 'NNP'),\n",
       " ('چنان', 'NNP'),\n",
       " ('درگیر', 'NNP'),\n",
       " ('قوانین', 'NNP'),\n",
       " ('اجباری', 'NNP'),\n",
       " ('و', 'NNP'),\n",
       " ('خشک', 'NNP'),\n",
       " ('در', 'NNP'),\n",
       " ('غربت', 'NNP'),\n",
       " ('میشن', 'NNP'),\n",
       " ('که', 'NNP'),\n",
       " ('آزادیی', 'NNP'),\n",
       " ('که', 'NNP'),\n",
       " ('تو', 'NNP'),\n",
       " ('ایران', 'NNP'),\n",
       " ('داشتن', 'NNP'),\n",
       " ('براشون', 'NNP'),\n",
       " ('حسرت', 'NNP'),\n",
       " ('و', 'NNP'),\n",
       " ('رویا', 'NNP'),\n",
       " ('میشه', 'NNP'),\n",
       " ('اینجا', 'NNP'),\n",
       " ('قانون', 'NNP'),\n",
       " ('داره', 'NNP'),\n",
       " ('و', 'NNP'),\n",
       " ('هرچند', 'NNP'),\n",
       " ('اشتباه', 'NNP'),\n",
       " ('،', 'NNP'),\n",
       " ('باید', 'NNP'),\n",
       " ('رعایت', 'NNP'),\n",
       " ('کرد', 'NNP'),\n",
       " ...]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_speech = dict(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-29e3ab001cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         ).astype({'count':'int64',\n\u001b[1;32m     12\u001b[0m                                   'part_of_speech':'category'})\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_of_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-208-29e3ab001cac>\u001b[0m in \u001b[0;36mpart_of_speech\u001b[0;34m(iterable_of_lists)\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'part_of_speech'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         ).astype({'count':'int64',\n\u001b[0;32m---> 12\u001b[0;31m                                   'part_of_speech':'category'})\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_of_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5682\u001b[0m                     results.append(\n\u001b[0;32m-> 5683\u001b[0;31m                         \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5684\u001b[0m                     )\n\u001b[1;32m   5685\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "def part_of_speech(iterable_of_lists):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    all_words = tokenize_list(iterable_of_lists)\n",
    "    tokens = remove_stopwords(all_words)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    part_of_speech = dict(tagged)\n",
    "    \n",
    "    return pd.DataFrame(part_of_speech, \n",
    "                        index=part_of_speech.keys(),\n",
    "                        columns=['count','part_of_speech']\n",
    "                        ).astype({'count':'int64',\n",
    "                                  'part_of_speech':'category'})\n",
    "pos = part_of_speech(list_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(words,\n",
    "              limit=100,\n",
    "              color=(150,50,50)):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    cloud = WordCloud(background_color=\"white\",\n",
    "                  prefer_horizontal=0.9,\n",
    "                  max_font_size=40,\n",
    "                  relative_scaling=.5,\n",
    "                  color_func=lambda *args,**kwargs:color)\n",
    "    cloud.generate_from_frequencies(dict(word_freq[:limit]))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cloud)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "    \"\"\"Convert a list of tokens to a matrix of token counts.\"\"\"\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    frequency_matrix = vectorizer.fit_transform(df)\n",
    "    \n",
    "    # Sum all the frequencies for each word\n",
    "    total_count = np.sum(frequency_matrix, axis=0)\n",
    "    \n",
    "    # Squeeze to remove single-dimensional entries\n",
    "    frequency = np.squeeze(np.asarray(sum_frequencies))\n",
    "    \n",
    "    # Make a dataframe of the words and their frequencies\n",
    "    frequency_df = pd.DataFrame([frequency], columns=vectorizer.get_feature_names()).transpose()\n",
    "    return frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(word_frequency):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    labels = word_frequency[0][1:51].index\n",
    "    title = 'Word Frequency'\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(np.arange(50), word_frequency[0][1:51], width = 0.8, color = sns.color_palette(\"bwr\"), alpha=0.5, \n",
    "            edgecolor = \"black\", capsize=8, linewidth=1);\n",
    "    plt.xticks(np.arange(50), labels, rotation=90, size=14);\n",
    "    plt.xlabel(\"Word\");\n",
    "    plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.title(title, size=18)\n",
    "    plt.grid(False);\n",
    "    plt.gca().spines[\"top\"].set_visible(False);\n",
    "    plt.gca().spines[\"right\"].set_visible(False);\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 560571 entries, 1271764746983952390 to 948848104362663936\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   userid                    560571 non-null  string        \n",
      " 1   user_display_name         560571 non-null  string        \n",
      " 2   user_screen_name          560571 non-null  string        \n",
      " 3   user_reported_location    417523 non-null  string        \n",
      " 4   user_profile_description  530518 non-null  string        \n",
      " 5   user_profile_url          338535 non-null  string        \n",
      " 6   follower_count            560571 non-null  int64         \n",
      " 7   following_count           560571 non-null  int64         \n",
      " 8   account_creation_date     560571 non-null  datetime64[ns]\n",
      " 9   account_language          560571 non-null  string        \n",
      " 10  tweet_language            444758 non-null  string        \n",
      " 11  tweet_text                560571 non-null  string        \n",
      " 12  tweet_time                560571 non-null  datetime64[ns]\n",
      " 13  tweet_client_name         560571 non-null  category      \n",
      " 14  in_reply_to_userid        95096 non-null   string        \n",
      " 15  in_reply_to_tweetid       89139 non-null   float64       \n",
      " 16  quoted_tweet_tweetid      18513 non-null   float64       \n",
      " 17  is_retweet                560571 non-null  bool          \n",
      " 18  retweet_userid            17981 non-null   string        \n",
      " 19  retweet_tweetid           100446 non-null  float64       \n",
      " 20  latitude                  560571 non-null  category      \n",
      " 21  longitude                 560571 non-null  category      \n",
      " 22  quote_count               560571 non-null  int64         \n",
      " 23  reply_count               560571 non-null  int64         \n",
      " 24  like_count                560571 non-null  int64         \n",
      " 25  retweet_count             560571 non-null  int64         \n",
      " 26  hashtags                  444588 non-null  string        \n",
      " 27  urls                      465724 non-null  string        \n",
      " 28  user_mentions             560571 non-null  string        \n",
      " 29  file                      560571 non-null  string        \n",
      " 30  campaign                  560571 non-null  string        \n",
      " 31  release                   560571 non-null  object        \n",
      " 32  government                560571 non-null  string        \n",
      " 33  type                      560571 non-null  object        \n",
      " 34  has_quote                 560571 non-null  bool          \n",
      "dtypes: bool(2), category(3), datetime64[ns](2), float64(3), int64(6), object(2), string(17)\n",
      "memory usage: 155.3+ MB\n"
     ]
    }
   ],
   "source": [
    "iran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = (iran\n",
    "            .loc[:][['tweetid','userid','tweet_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.tweet, table.sentiment, test_size=0.2, shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data, features):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokenization = TfidfVectorizer(max_features=features)\n",
    "    tokenization.fit(dataset)\n",
    "    return tokenization.transform(data).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
