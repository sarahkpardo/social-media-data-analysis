{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from topic_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(string):\n",
    "    \"\"\"Remove symbols; replace urls, hashtags, and user \n",
    "       mentions with a placeholder token.\n",
    "    \"\"\"\n",
    "    # \"rt\" (\"retweet\") \n",
    "    string = re.sub('rt', '', string.lower())\n",
    "    \n",
    "    # @-mentions\n",
    "    string = re.sub(r'@\\w+', '<-@->', string)\n",
    "    \n",
    "    # hyperlinks\n",
    "    string = re.sub(r'http\\S+', '<-URL->', string)\n",
    "    string = re.sub(r'www.[^ ]+', '<-URL->', string)\n",
    "    \n",
    "    # hashtags\n",
    "    string = re.sub(r'#\\w+', '<-#->', string)\n",
    "    \n",
    "    # digits\n",
    "    string = re.sub(r'[0-9]+', '', string)\n",
    "    \n",
    "    # symbols\n",
    "    string = re.sub(r'[!\"$%&()*+,./:;=?[\\]^_`{|}~]', '', string)\n",
    "    \n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_string(string):\n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(string))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions on dataframes\n",
    "For use with ```.pipe()``` and ```.apply()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tweet(df):\n",
    "    \"\"\"Remove symbols; replace urls, hashtags, and user \n",
    "       mentions with a placeholder token.\n",
    "    \"\"\"\n",
    "    # \"rt\" (\"retweet\") \n",
    "    df = df.str.lower().replace('rt', '')\n",
    "    \n",
    "    # @-mentions\n",
    "    df = df.str.replace(r'@\\w+', '<-@->')\n",
    "    \n",
    "    # hyperlinks\n",
    "    df = df.str.replace('http\\S+', '<-URL->')\n",
    "    df = df.str.replace('www.[^ ]+', '<-URL->')\n",
    "    \n",
    "    # hashtags\n",
    "    df = df.str.replace(r'#\\w+', '<-#->')\n",
    "    \n",
    "    # digits\n",
    "    df = df.str.replace(r'[0-9]+', '')\n",
    "    \n",
    "    # symbols\n",
    "    df = df.str.replace(r'[!\"$%&()*+,./:;=?[\\]^_`{|}~]', '')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_tokenize(df):\n",
    "    \"\"\"\n",
    "    Convert `in_string` of text to a list of tokens using NLTK's TweetTokenizer\n",
    "    \"\"\"\n",
    "    tokenizer = TweetTokenizer(preserve_case=False,\n",
    "                               reduce_len=True,\n",
    "                               strip_handles=False)\n",
    "    df = df.map(tokenizer.tokenize)\n",
    "    return df\n",
    "\n",
    "def tokenize(df):\n",
    "    \"\"\"Apply nltk tokenizing function to a dataframe,\n",
    "       removing single-character tokens.\n",
    "    \"\"\"\n",
    "    df = df.map(word_tokenize)\n",
    "    df = df.apply(lambda x: [x for token in x if len(token)>2])\n",
    "    return df\n",
    "\n",
    "def remove_stopwords(df):\n",
    "    \"\"\"Remove stop words, based on nltk list.\"\"\"\n",
    "    \n",
    "    cache = set(stopwords.words())\n",
    "    df = df.apply(lambda x: [word for word in x \n",
    "                                    if word.lower() not in cache])\n",
    "    return df\n",
    "\n",
    "def lemmatize(df):\n",
    "    \"\"\"Lemmatize using nltk WordNet method.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    df = df.apply(lambda x: [lemmatizer.lemmatize(word)\n",
    "                                  for word in x\n",
    "                                  if len(lemmatizer.lemmatize(w))>3])\n",
    "    return df\n",
    "\n",
    "def preprocess_words(df, tweet_tokenizer=True, lemmatize=False):\n",
    "    \"\"\"Apply word-level preprocessing.\"\"\"\n",
    "    \n",
    "    if tweet_tokenizer:\n",
    "        token_fn = tweet_tokenize\n",
    "    else: token_fn = tokenize\n",
    "        \n",
    "    if lemmatize:\n",
    "        df = df.pipe(token_fn).pipe(remove_stopwords).pipe(lemmatize)\n",
    "        return df\n",
    "    \n",
    "    df = df.pipe(token_fn).pipe(remove_stopwords)\n",
    "    return df\n",
    "\n",
    "def preprocess_text(self, tweet_tokenize, lemmatize):\n",
    "    \"\"\"Pre-process text in a dataframe column.\n",
    "\n",
    "    Usage:\n",
    "\n",
    "        df['processed_text'] = preprocess_data(df['not_processed_text'])\n",
    "\n",
    "    \"\"\"\n",
    "    return df.pipe(preprocess_string).pipe(preprocess_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_text(list_of_strings):\n",
    "    \"\"\"\n",
    "    Concatenate a list of strings into a single string.\n",
    "    \"\"\"\n",
    "    return ' '.join([string for string in list_of_strings])\n",
    "\n",
    "def all_tokens(list_of_lists):\n",
    "    \"\"\"\n",
    "    Concatenate items from multiple lists into a single list.\n",
    "    \"\"\"\n",
    "    return list(itertools.chain(*list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_iter(df_of_lists):\n",
    "    \"\"\"\n",
    "    Usage: df.pipe(tokenize_df)\n",
    "    \"\"\"\n",
    "    # Concatenate into a long string to be tokenized\n",
    "    long_string = all_text(all_tokens(df_of_lists))\n",
    "    preprocessed = preprocess_tweet(long_string)\n",
    "    \n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(preprocessed))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_list(list_of_strings):\n",
    "    \"\"\"\n",
    "    Usage: df.map(tokenize_list)\n",
    "    \"\"\"\n",
    "    long_string = all_text(list_of_strings)\n",
    "    preprocessed = preprocess_tweet(long_string)\n",
    "    \n",
    "    tokens = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(preprocessed))\n",
    "    # remove symbol-only tokens\n",
    "    tokens = [t for t in tokens if not t in string.punctuation]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid\n",
       "1331706590525874184    –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –§—Ä–∞–Ω—Ü–∏–∏ –∑–∞—è–≤–ª—è–µ—Ç, —á—Ç–æ –Ω–µ –ø—Ä–∏–∑–Ω–∞–µ...\n",
       "1100358276435398656    Interview w/ Ayaz Mutalibov, first President o...\n",
       "1100389340914569216    Dana Mazalova, Czech Journalist, is the author...\n",
       "724982683118358528     Baku Declaration of the 7th UNAOC Global Forum...\n",
       "728142042765742080     FM Mammadyarov: #Azerbaijan is &amp; will rema...\n",
       "727245477867974656     Azerbaijani army is and will defend its citize...\n",
       "728581480545325057     Terter'de Ermenilerin sivilleri hedef almasƒ± s...\n",
       "650550450320601088     newsazerbaijan.ru –£ –±–µ—Ä–µ–≥–æ–≤ –ò—Å–ø–∞–Ω–∏–∏ —Å–ø–∞—Å–µ–Ω—ã –æ–∫...\n",
       "661914640331333632     newsazerbaijan.ru –†–§ –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ –∑–∞—â–∏—Ç—É –≤–∑–∞–∏–º–Ω...\n",
       "535744142437933056     newsazerbaijan.ru –í 2014 –≥–æ–¥—É –≤ –ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ –∑...\n",
       "Name: tweet_text, dtype: string"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = df.loc[:]['tweet_text'].head(50)\n",
    "text_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ',\n",
       " '—Ñ—Ä–∞–Ω—Ü–∏–∏',\n",
       " '–∑–∞—è–≤–ª—è–µ—Ç',\n",
       " '—á—Ç–æ',\n",
       " '–Ω–µ',\n",
       " '–ø—Ä–∏–∑–Ω–∞–µ—Ç',\n",
       " '–∫–∞—Ä–∞–±–∞—Ö',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'interview',\n",
       " 'w',\n",
       " 'ayaz',\n",
       " 'mutalibov',\n",
       " 'first',\n",
       " 'president',\n",
       " 'of',\n",
       " '<-#->',\n",
       " '‚Äú',\n",
       " 'the',\n",
       " 'corridor',\n",
       " 'by',\n",
       " 'which',\n",
       " 'people',\n",
       " 'could',\n",
       " 'escape',\n",
       " 'had',\n",
       " 'nonetheless',\n",
       " 'been',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'armenians',\n",
       " 'so',\n",
       " 'why',\n",
       " 'would',\n",
       " 'they',\n",
       " 'fire',\n",
       " '‚Äù',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'dana',\n",
       " 'mazalova',\n",
       " 'czech',\n",
       " 'journalist',\n",
       " 'is',\n",
       " 'the',\n",
       " 'author',\n",
       " 'of',\n",
       " 'the',\n",
       " 'famous',\n",
       " 'interview',\n",
       " 'with',\n",
       " 'ayaz',\n",
       " 'mutalibov',\n",
       " 'published',\n",
       " 'in',\n",
       " '‚Äú',\n",
       " 'nezavisimaya',\n",
       " 'gazeta',\n",
       " '‚Äù',\n",
       " 'where',\n",
       " 'mutalibov',\n",
       " 'acknowledges',\n",
       " 'the',\n",
       " 'existence',\n",
       " 'of',\n",
       " 'the',\n",
       " 'humanitarian',\n",
       " 'corridor',\n",
       " 'left',\n",
       " 'by',\n",
       " 'the',\n",
       " 'armenian',\n",
       " 'side',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'baku',\n",
       " 'declaration',\n",
       " 'of',\n",
       " 'the',\n",
       " 'th',\n",
       " 'unaoc',\n",
       " 'global',\n",
       " 'forum',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'fm',\n",
       " 'mammadyarov',\n",
       " '<-#->',\n",
       " 'is',\n",
       " 'amp',\n",
       " 'will',\n",
       " 'remain',\n",
       " 'a',\n",
       " 'committed',\n",
       " 'paner',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'joint',\n",
       " 'strategic',\n",
       " 'interests',\n",
       " 'in',\n",
       " 'field',\n",
       " 'o',\n",
       " '<-url->',\n",
       " 'azerbaijani',\n",
       " 'army',\n",
       " 'is',\n",
       " 'and',\n",
       " 'will',\n",
       " 'defend',\n",
       " 'its',\n",
       " 'citizens',\n",
       " 'and',\n",
       " 'will',\n",
       " 'give',\n",
       " 'a',\n",
       " 'strong',\n",
       " 'response',\n",
       " 'to',\n",
       " 'every',\n",
       " 'armed',\n",
       " 'provocation',\n",
       " 'a',\n",
       " '<-url->',\n",
       " \"teer'de\",\n",
       " 'ermenilerin',\n",
       " 'sivilleri',\n",
       " 'hedef',\n",
       " 'almasƒ±',\n",
       " 'sonucu',\n",
       " 'zarar',\n",
       " 'g√∂ren',\n",
       " 'bir',\n",
       " 'evde',\n",
       " 't√ºrk',\n",
       " 'milli',\n",
       " 'takƒ±mƒ±nƒ±n',\n",
       " 'posteri',\n",
       " 'g√∂r√ºl√ºy',\n",
       " '<-url->',\n",
       " 'newsazerbaijanru',\n",
       " '—É',\n",
       " '–±–µ—Ä–µ–≥–æ–≤',\n",
       " '–∏—Å–ø–∞–Ω–∏–∏',\n",
       " '—Å–ø–∞—Å–µ–Ω—ã',\n",
       " '–æ–∫–æ–ª–æ',\n",
       " '–∏–º–º–∏–≥—Ä–∞–Ω—Ç–æ–≤',\n",
       " '—Å–ø–∞—Å–µ–Ω–Ω—ã–µ',\n",
       " '–º–∏–≥—Ä–∞–Ω—Ç—ã',\n",
       " '–≤',\n",
       " '–±–ª–∏–∂–∞–π—à–µ–µ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Ä—Ñ',\n",
       " '–ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞',\n",
       " '–∑–∞—â–∏—Ç—É',\n",
       " '–≤–∑–∞–∏–º–Ω—ã—Ö',\n",
       " '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π',\n",
       " '—Å',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–æ–º',\n",
       " '–Ω–∞',\n",
       " '—Å–µ–≥–æ–¥–Ω—è—à–Ω–∏–π',\n",
       " '–¥–µ–Ω—å',\n",
       " '—Ä',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤',\n",
       " '–≥–æ–¥—É',\n",
       " '–≤',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ',\n",
       " '–∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω–æ',\n",
       " '–ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π',\n",
       " '—Å–æ–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö',\n",
       " '–¥–µ—Ç—å–º–∏',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—ç–∫—Å–ø–µ—Ä—Ç',\n",
       " '–∏—Å—Ç–∏–Ω–Ω—ã–º–∏',\n",
       " '–∫–æ–Ω—Ç—Ä–∞–≥–µ–Ω—Ç–∞–º–∏',\n",
       " '–¥–∞–∏—à',\n",
       " '—è–≤–ª—è—é—Ç—Å—è',\n",
       " '–æ—Ç–Ω—é–¥—å',\n",
       " '–Ω–µ',\n",
       " '–≤–ª–∞—Å—Ç–∏',\n",
       " '—Ç—É—Ä—Ü–∏–∏',\n",
       " '—Å–∞–Ω–∫—Ü–∏–∏',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—É–∂–µ—Å—Ç–æ—á–∞–µ—Ç—Å—è',\n",
       " '–Ω–∞–∫–∞–∑–∞–Ω–∏–µ',\n",
       " '–∑–∞',\n",
       " '–Ω–∞—Ä—É—à–µ–Ω–∏–µ',\n",
       " '—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π',\n",
       " '–∑–∞–∫–æ–Ω–∞',\n",
       " '–∞—Ä',\n",
       " '¬´',\n",
       " '–æ',\n",
       " '—Ç–µ–ª–µ—Ä–∞–¥–∏–æ–≤–µ—â–∞–Ω–∏–∏',\n",
       " '¬ª',\n",
       " '—Å',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≥–ª–∞–≤–∞',\n",
       " '–º–∏–¥',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '–æ—Ç–ø—Ä–∞–≤–∏–ª—Å—è',\n",
       " '–≤',\n",
       " '–ø–∞—Ä–∏–∂',\n",
       " '–Ω–∞',\n",
       " '–≤—Å—Ç—Ä–µ—á—É',\n",
       " '—Å',\n",
       " '–º–≥',\n",
       " '–æ–±—Å–µ',\n",
       " '–º–∏–Ω–∏—Å—Ç—Ä',\n",
       " '–∏–Ω–æ—Å—Ç—Ä–∞–Ω',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–∫—Ä–æ–º–µ',\n",
       " '–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è',\n",
       " '–¥—Ä—É–≥–æ–≥–æ',\n",
       " '–ø—É—Ç–∏',\n",
       " '—Ä–∞–∑–≤–∏—Ç–∏—è',\n",
       " '—Å–µ–ª—å—Å–∫–æ–≥–æ',\n",
       " '—Ö–æ–∑—è–π—Å—Ç–≤–∞',\n",
       " '–Ω–µ—Ç',\n",
       " '–æ—Å–æ–±–æ–µ',\n",
       " '–≤–Ω–∏–º–∞–Ω–∏',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'live',\n",
       " '–ø–æ–ª—É—Ñ–∏–Ω–∞–ª',\n",
       " '–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–≥–æ',\n",
       " '–∫–æ–Ω–∫—É—Ä—Å–∞',\n",
       " '–ø–æ',\n",
       " '—Ç–∞–Ω–∫–æ–≤–æ–º—É',\n",
       " '–±–∏–∞—Ç–ª–æ–Ω—É',\n",
       " '–≤',\n",
       " '–∞–ª–∞–±–∏–Ω–æ',\n",
       " '–≤',\n",
       " '–ø–æ–ª—É—Ñ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤',\n",
       " '–≥–∞–±–∞–ª–µ',\n",
       " '–∑–∞–≤–µ—Ä—à–∏–ª—Å—è',\n",
       " '–∫—É–±–æ–∫',\n",
       " '–º–∏—Ä–∞',\n",
       " '–ø–æ',\n",
       " '–æ–ª–∏–º–ø–∏–π—Å–∫–∏–º',\n",
       " '–≤–∏–¥–∞–º',\n",
       " '—Å—Ç—Ä–µ–ª—å–±—ã',\n",
       " '–¥–∞–Ω–Ω—ã–µ',\n",
       " '—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤—Ä',\n",
       " '–º–æ–∂–µ—Ç',\n",
       " '–∑–∞–º–æ—Ä–æ–∑–∏—Ç—å',\n",
       " '—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é',\n",
       " '—Ä—è–¥–∞',\n",
       " '–ø—Ä–æ–µ–∫—Ç–æ–≤',\n",
       " '–∏–∑-–∑–∞',\n",
       " '–Ω–∏–∑–∫–æ–π',\n",
       " '—Ü–µ–Ω—ã',\n",
       " '–Ω–∞',\n",
       " '–Ω–µ—Ñ—Ç—å',\n",
       " '–∫—Ä–æ–º–µ',\n",
       " '—Ç',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–ø–æ–ª–∏—Ü–∏—è',\n",
       " '–∑–∞–¥–µ—Ä–∂–∞–ª–∞',\n",
       " '–Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö',\n",
       " '–∞–∫—Ç–∏–≤–∏—Å—Ç–æ–≤',\n",
       " '—É',\n",
       " '–±–∞–∑—ã',\n",
       " '—è–¥–µ—Ä–Ω—ã—Ö',\n",
       " '–ø–æ–¥–ª–æ–¥–æ–∫',\n",
       " '–≤',\n",
       " '—à–æ—Ç–ª–∞–Ω–¥–∏–∏',\n",
       " '–ø–æ–ª',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–ø—Ä–æ–∂–∏—Ç–æ—á–Ω—ã–π',\n",
       " '–º–∏–Ω–∏–º—É–º',\n",
       " '–≤',\n",
       " '–∞—Ä',\n",
       " '–º–æ–∂–µ—Ç',\n",
       " '–±—ã—Ç—å',\n",
       " '—É–≤–µ–ª–∏—á–µ–Ω',\n",
       " '–¥–æ',\n",
       " '–º–∞–Ω–∞—Ç–æ–≤',\n",
       " '–ø—Ä–æ–∂–∏—Ç–æ—á–Ω—ã–π',\n",
       " '–º–∏–Ω–∏–º—É–º',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–æ—Ç–≤–µ—Ç',\n",
       " '–≤—Å',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '–∑–∞',\n",
       " '–ø–æ–≥–∏–±—à–∏—Ö',\n",
       " '—Å–æ–ª–¥–∞—Ç',\n",
       " '–±—É–¥–µ—Ç',\n",
       " '—Å–æ–∫—Ä—É—à–∏—Ç–µ–ª—å–Ω—ã–º',\n",
       " '‚Äì',\n",
       " '–º–∏–Ω–æ–±–æ—Ä–æ–Ω—ã',\n",
       " '–∞—Ä',\n",
       " '–≤',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–∫—É—Ä—Å',\n",
       " '–¥–æ–ª–ª–∞—Ä–∞',\n",
       " '–Ω–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ',\n",
       " '–∫–æ–ª–µ–±–ª–µ—Ç—Å—è',\n",
       " '–∫',\n",
       " '–º–∏—Ä–æ–≤—ã–º',\n",
       " '–≤–∞–ª—é—Ç–∞–º',\n",
       " '–ø–æ',\n",
       " '—Å–æ—Å—Ç–æ—è–Ω–∏—é',\n",
       " '–Ω–∞',\n",
       " '–º',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–∫—Ä–æ–≤–∞–≤—ã–π',\n",
       " '—Å–ø–∏—Å–æ–∫',\n",
       " '–¥—Ç–ø',\n",
       " '–≤',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—ç–∫—Å-–¥–∏—Ä–µ–∫—Ç–æ—Ä',\n",
       " '–º–≤—Ñ',\n",
       " '–ø—Ä–∏–≥–æ–≤–æ—Ä–µ–Ω',\n",
       " '–∫',\n",
       " '—à—Ç—Ä–∞—Ñ—É',\n",
       " '–∑–∞',\n",
       " '–º–∞—Ö–∏–Ω–∞—Ü–∏–∏',\n",
       " '—Å—É–¥—å—è',\n",
       " '–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π',\n",
       " '—Å—É–¥–µ–±–Ω–æ–π',\n",
       " '–∫',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Å–∞–º–æ–π',\n",
       " '–≤—ã—Å–æ–∫–æ–π',\n",
       " '–ø–∏—Ä–∞–º–∏–¥–µ',\n",
       " '–∏–∑',\n",
       " '–º–æ–Ω–µ—Ç',\n",
       " '–∏—Å–ø–æ–ª–Ω—è–µ—Ç—Å—è',\n",
       " '–≥–æ–¥–∞',\n",
       " '–∞–ª–µ–∫—Å',\n",
       " '—á–µ—Ä–≤–∏–Ω—Å–∫–∏–π',\n",
       " '–ø–æ–ø–∞–ª',\n",
       " '–≤',\n",
       " '–∫–Ω',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å',\n",
       " '–ø–æ–ª–Ω–æ–º–∞—Å—à—Ç–∞–±–Ω–æ–π',\n",
       " '–≤–æ–π–Ω—ã',\n",
       " '–≤',\n",
       " '–µ–≤—Ä–æ–ø–µ',\n",
       " '–Ω–µ',\n",
       " '–æ—á–µ–Ω—å',\n",
       " '—É–±–µ–¥–∏—Ç–µ–ª—å–Ω–∞',\n",
       " '‚Äì',\n",
       " '–ø–æ–ª–∏—Ç–æ–ª–æ–≥',\n",
       " '–≤–æ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤—Ä–∞—á–∏',\n",
       " '–Ω–∞—É—á–∏–ª–∏',\n",
       " '–∫–æ–º–ø—å—é—Ç–µ—Ä—ã',\n",
       " '–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å',\n",
       " '–∂–∞–ª–æ–±—ã',\n",
       " '–ø–∞—Ü–∏–µ–Ω—Ç–æ–≤',\n",
       " '–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–∏',\n",
       " '—Å–æ–∑–¥–∞–ª–∏',\n",
       " '–∫–æ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Å—Ç—Ä–∞–Ω—ã',\n",
       " '–≤–æ—Å—Ç–æ—á–Ω–æ–π',\n",
       " '–µ–≤—Ä–æ–ø—ã',\n",
       " '—Ö–æ—Ç—è—Ç',\n",
       " '–≤—Å—Ç—É–ø–∏—Ç—å',\n",
       " '–≤',\n",
       " '–Ω–∞—Ç–æ',\n",
       " '–∞',\n",
       " '–Ω–µ',\n",
       " '–∞–ª—å—è–Ω—Å',\n",
       " '–¥–≤–∏–∂–µ—Ç—Å—è',\n",
       " '–Ω–∞',\n",
       " '–≤–æ—Å—Ç–æ–∫',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Å—É–±–±–æ—Ç–∞',\n",
       " '–≤',\n",
       " '–≥–æ—Ä–æ–¥–µ',\n",
       " '–≤—ã—Å—Ç–∞–≤–∫–∏',\n",
       " '–æ—Ç–¥—ã—Ö–∞—è',\n",
       " '–æ—Ç',\n",
       " '—Ç—Ä—É–¥–æ–≤',\n",
       " '–ø—Ä–∞–≤–µ–¥–Ω—ã—Ö',\n",
       " '–∏–º–µ–µ—Ç',\n",
       " '—Å–º—ã—Å–ª',\n",
       " '–ø–æ–±–∞–ª–æ–≤–∞—Ç—å',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤–∞—à–∏–Ω–≥—Ç–æ–Ω',\n",
       " '–ø—Ä–∏–∫–ª–∞–¥—ã–≤–∞–µ—Ç',\n",
       " '–≤—Å–µ',\n",
       " '—É—Å–∏–ª–∏—è',\n",
       " '—á—Ç–æ–±—ã',\n",
       " '–µ–∞—ç—Å',\n",
       " '–ø—Ä–∏–∫–∞–∑–∞–ª',\n",
       " '–¥–æ–ª–≥–æ',\n",
       " '–∂–∏—Ç—å',\n",
       " '–≤–∏—Ç–∞–ª–∏–π',\n",
       " '–∞—Ä—å–∫',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–∑–∞–¥–µ—Ä–∂–∞–Ω—ã',\n",
       " '—á–µ–ª–æ–≤–µ–∫',\n",
       " '–≤',\n",
       " '—Å–≤—è–∑–∏',\n",
       " '—Å',\n",
       " '—Ç–µ—Ä–∞–∫—Ç–æ–º',\n",
       " '–≤',\n",
       " '–∞–Ω–∫–∞—Ä–µ',\n",
       " '–ø–æ',\n",
       " '—Å–ª–æ–≤–∞–º',\n",
       " '–ø—Ä–µ–º—å–µ—Ä-–º–∏–Ω–∏—Å—Ç—Ä–∞',\n",
       " '—Ç—É—Ä',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–ø–æ–∑–∏—Ü–∏—è',\n",
       " '–≥—Ä–µ—Ü–∏–∏',\n",
       " '—Å–Ω–∏–∂–∞–µ—Ç',\n",
       " '–∏–Ω—Ç–µ—Ä–µ—Å',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '–∫',\n",
       " '—Ç–∞—Ä',\n",
       " '‚Äì',\n",
       " '–¥–µ–ø—É—Ç–∞—Ç',\n",
       " '–º–º',\n",
       " '¬´',\n",
       " '–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ',\n",
       " '—Å',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'ford',\n",
       " '–ø–µ—Ä–≤—ã–º',\n",
       " '–≤',\n",
       " '–º–∏—Ä–µ',\n",
       " '–ø—Ä–∏–º–µ–Ω–∏—Ç',\n",
       " '–ø–ª–∞—Å—Ç–∏—á–Ω—ã–π',\n",
       " '–∞–ª—é–º–∏–Ω–∏–π',\n",
       " '–Ω–æ–≤—ã–π',\n",
       " '—Å–ø–ª–∞–≤',\n",
       " '–∏–∑–≥–æ—Ç–æ–≤–ª–µ–Ω',\n",
       " '–ø–æ',\n",
       " '—Ç–µ—Ö',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–±–∞–∫—É',\n",
       " '—Å–∞—Ä—Å–∞–Ω–≥—Å–∫–æ–µ',\n",
       " '–≤–æ–¥–æ—Ö—Ä–∞–Ω–∏–ª–∏—â–µ',\n",
       " '–ø—Ä–µ–≤—Ä–∞—â–µ–Ω–æ',\n",
       " '–µ—Ä–µ–≤–∞–Ω–æ–º',\n",
       " '–≤',\n",
       " '–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç',\n",
       " '—É–≥—Ä–æ–∑',\n",
       " '–Ω–∞',\n",
       " '–≤—Å—Ç—Ä–µ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " 'wsj',\n",
       " '—Å–∏–ª—å–Ω—ã–π',\n",
       " '–¥–æ–ª–ª–∞—Ä',\n",
       " '–Ω–∞–≤—Ä–µ–¥–∏—Ç',\n",
       " '–º–Ω–æ–≥–∏–º',\n",
       " '–∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–º',\n",
       " '–∫–æ–º–ø–∞–Ω–∏—è–º',\n",
       " '–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π',\n",
       " '—ç—Ñ—Ñ–µ–∫—Ç',\n",
       " '–≤',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Ç—É—Ä–µ—Ü–∫–∏–π',\n",
       " '–ø–æ—Ç–æ–∫',\n",
       " '–±—É–¥–µ—Ç',\n",
       " '—Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω',\n",
       " '–µ–≤—Ä–æ–∫–æ–º–∏—Å—Å–∏–µ–π',\n",
       " '–ø—Ä–æ–µ–∫—Ç',\n",
       " '—Ç—É—Ä–µ—Ü–∫–∏–π',\n",
       " '–ø–æ—Ç–æ–∫',\n",
       " '–±—É–¥–µ—Ç',\n",
       " '—Ä',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–Ω–∞–π–¥–µ–Ω–æ',\n",
       " '—Ç–µ–ª–æ',\n",
       " '–µ—â–µ',\n",
       " '–æ–¥–Ω–æ–≥–æ',\n",
       " '–ø—Ä–æ–ø–∞–≤—à–µ–≥–æ',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–æ–≥–æ',\n",
       " '–Ω–µ—Ñ—Ç—è–Ω–∏–∫–∞',\n",
       " '—Ç–µ–ª–æ',\n",
       " '–æ–¥–Ω–æ–≥–æ',\n",
       " '–∏–∑',\n",
       " '–ø—Ä',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—Ä—É–±–ª—å',\n",
       " '–æ—Ç–∫—Ä—ã–ª',\n",
       " '–ø–æ—Å–ª–µ–¥–Ω—é—é',\n",
       " '—Ç–æ—Ä–≥–æ–≤—É—é',\n",
       " '–Ω–µ–¥–µ–ª—é',\n",
       " '–≥–æ–¥–∞',\n",
       " '—Ä–µ–∑–∫–∏–º',\n",
       " '—Å–Ω–∏–∂–µ–Ω–∏–µ–º',\n",
       " '–Ω–æ',\n",
       " '–≤',\n",
       " '–Ω–∞—á–∞–ª–µ',\n",
       " '–≥',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤',\n",
       " '–≥—Ä—É–∑–∏–∏',\n",
       " '–ø–æ',\n",
       " '–¥–µ–ª—É',\n",
       " '–æ',\n",
       " '–≥–∏–±–µ–ª–∏',\n",
       " '–∂–≤–∞–Ω–∏—è',\n",
       " '–ø—Ä–µ–¥—ä—è–≤–ª–µ–Ω–æ',\n",
       " '–æ–±–≤–∏–Ω–µ–Ω–∏–µ',\n",
       " '—ç–∫—Å-–ø—Ä–æ–∫—É—Ä–æ—Ä—É',\n",
       " '—Å—Ç—Ä–∞–Ω—ã',\n",
       " '–≥—Ä—É',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       " '–∏–ª—å—Ö–∞–º',\n",
       " '–∞–ª–∏–µ–≤',\n",
       " '–ø–æ–∑–¥—Ä–∞–≤–∏–ª',\n",
       " '–Ω–∞—Ä–æ–¥',\n",
       " '—Å',\n",
       " '–≥—É—Ä–±–∞–Ω',\n",
       " '–±–∞–π—Ä–∞–º—ã',\n",
       " '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ',\n",
       " '–æ—Ç–º–µ—á–∞–µ—Ç—Å—è',\n",
       " '–¥–µ–Ω—å',\n",
       " '–Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π',\n",
       " '–º—É–∑—ã–∫–∏',\n",
       " '–ø–µ—Ä–≤–∞—è',\n",
       " '–≤',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ',\n",
       " '–∏',\n",
       " '–Ω–∞',\n",
       " '–≤',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≥—Ä–∞–∂–¥–∞–Ω–µ',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '–¥–æ–ª–∂–Ω—ã',\n",
       " '–±—É–¥—É—Ç',\n",
       " '–ø—Ä–∏–Ω–æ—Å–∏—Ç—å',\n",
       " '–∫–ª—è—Ç–≤—É',\n",
       " '–≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–∞',\n",
       " '–≥—Ä–∞–∂–¥–∞–Ω–µ',\n",
       " '–∞–∑–µ—Ä–±–∞–π',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '—ç—Ä–¥–æ–≥–∞–Ω',\n",
       " '—Å–∞—É–¥–æ–≤—Å–∫–∞—è',\n",
       " '–∞—Ä–∞–≤–∏—è',\n",
       " '—Ö–æ—á–µ—Ç',\n",
       " '–ø—Ä–∏–º–∏—Ä–∏—Ç—å',\n",
       " '—Ç—É—Ä—Ü–∏—é',\n",
       " '–∏',\n",
       " '–µ–≥–∏–ø–µ—Ç',\n",
       " '–µ–≥–∏–ø–µ—Ç',\n",
       " '—Å–∞—É–¥–æ–≤—Å–∫–∞—è',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤',\n",
       " '—Å—à–∞',\n",
       " '–ø–æ–π–º–∞–ª–∏',\n",
       " '–º—É–∂—á–∏–Ω—É',\n",
       " '—Å–±–µ–∂–∞–≤—à–µ–≥–æ',\n",
       " '–∏–∑',\n",
       " '—Ç—é—Ä—å–º—ã',\n",
       " '–≤',\n",
       " '–≥–æ–¥—É',\n",
       " '–∂–∏—Ç–µ–ª—å',\n",
       " '—à—Ç–∞—Ç–∞',\n",
       " '–æ–≥–∞–π–æ',\n",
       " '—Ñ—Ä—ç–Ω',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≤–≤–ø',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–∞',\n",
       " '–¥–æ—Å—Ç–∏–≥–Ω–µ—Ç',\n",
       " '–º–ª—Ä–¥',\n",
       " '–¥–æ–ª–ª–∞—Ä–æ–≤',\n",
       " '‚Äì',\n",
       " '–∑–∏—è–¥',\n",
       " '—Å–∞–º–µ–¥–∑–∞–¥–µ',\n",
       " '–≤',\n",
       " '–≥–æ–¥—É',\n",
       " '–º–∏—Ä–æ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–Ω–∞',\n",
       " '—é–∂–Ω–æ–º',\n",
       " '–∫–∞–≤–∫–∞–∑–µ',\n",
       " '—Ä–µ—à–∞—é—Ç',\n",
       " '—Å—É–¥—å–±—É',\n",
       " '–∏—Ä–∞–Ω—Å–∫–æ–≥–æ',\n",
       " '–≥–∞–∑–∞',\n",
       " '–≤',\n",
       " '–∏—Ä–∞–Ω–µ',\n",
       " '–æ–±—Å—É–¥—è—Ç',\n",
       " '–º–∞—Ä—à—Ä—É—Ç',\n",
       " '–ø–æ—Å—Ç–∞–≤–æ–∫',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–≥–∞–∑–ø—Ä–æ–º',\n",
       " '–Ω–µ',\n",
       " '–ø—Ä–æ–¥–ª–∏—Ç',\n",
       " '—Ç—Ä–∞–Ω–∑–∏—Ç–Ω—ã–π',\n",
       " '–∫–æ–Ω—Ç—Ä–∞–∫—Ç',\n",
       " '—Å',\n",
       " '—É–∫—Ä–∞–∏–Ω–æ–π',\n",
       " '–ø–æ—Å–ª–µ',\n",
       " '–≥–æ–¥–∞',\n",
       " '—Å–∞–º—ã–π',\n",
       " '–ø—Ä–æ—Å—Ç–æ–π',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–æ–¥–∏–Ω',\n",
       " '–∏–∑',\n",
       " '–∞—Ä–µ—Å—Ç–æ–≤–∞–Ω–Ω—ã—Ö',\n",
       " '–≤',\n",
       " '–¥–∞–≥–µ—Å—Ç–∞–Ω–µ',\n",
       " '–Ω—É—Ä—Å–∏—Å—Ç–æ–≤',\n",
       " '–æ–∫–∞–∑–∞–ª—Å—è',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Ü–µ–º',\n",
       " '–≤',\n",
       " '—Ö–æ–¥–µ',\n",
       " '–æ–ø–µ',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–ª–∏—à–µ–Ω–∏–µ',\n",
       " '–∞—Å—Å–∞–Ω–∂–∞',\n",
       " '—Å–≤–æ–±–æ–¥—ã',\n",
       " '–ø—Ä–∏–∑–Ω–∞–Ω–æ',\n",
       " '—Å–ø–µ—Ü–≥—Ä—É–ø–ø–æ–π',\n",
       " '–æ–æ–Ω',\n",
       " '–Ω–µ–∑–∞–∫–æ–Ω–Ω—ã–º',\n",
       " '—Ä–∞–±–æ—á–∞—è',\n",
       " '–≥—Ä—É–ø–ø–∞',\n",
       " '–æ–Ω',\n",
       " '–ø',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–∑–∞–≤—Ç—Ä–∞',\n",
       " '–≤',\n",
       " '–∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ',\n",
       " '–æ–∂–∏–¥–∞—é—Ç—Å—è',\n",
       " '–æ—Å–∞–¥–∫–∏',\n",
       " '–≤',\n",
       " '–±–∞–∫—É',\n",
       " '–∏',\n",
       " '–Ω–∞',\n",
       " '–∞–±—à–µ—Ä–æ–Ω—Å–∫–æ–º',\n",
       " '–ø–æ–ª—É–æ—Å—Ç—Ä–æ–≤–µ',\n",
       " '–∑–∞–≤—Ç',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce',\n",
       " 'newsazerbaijanru',\n",
       " '–º–∏–∞',\n",
       " '—Ä–æ—Å—Å–∏—è',\n",
       " '—Å–µ–≥–æ–¥–Ω—è',\n",
       " '–æ–±—ä—è–≤–ª—è–µ—Ç',\n",
       " '—Ä–∞–¥–∏–æ–∫–æ–Ω–∫—É—Ä—Å',\n",
       " '–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–µ',\n",
       " '–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–æ–µ',\n",
       " '–∞–≥–µ–Ω—Ç—Å',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " 'nikwjokmyhuopgce']"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text = tokenize_list(text_df)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df/list of list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=</th>\n",
       "      <td>[America and the way its government treats its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=</th>\n",
       "      <td>[@ManotoNews ÿß⁄ØŸá ÿß€åÿ±ÿßŸÜ ÿ®Ÿá €åŸÖŸÜ Ÿà ŸÖŸÇÿßŸàŸÖÿ™ ⁄©ŸÖ⁄© ŸÜ⁄©ŸÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0+2DdcWQlF1LIe31q4foyvQMZYObIOeoh5woH5+4ySo=</th>\n",
       "      <td>[A group belonging to the HTS kidnapped Yasser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07CPSEe0H6QwZcanuJd4G4sYBjmx+NtXpcj2NdAAmr0=</th>\n",
       "      <td>[#–°–®–ê #–Ø–ø–æ–Ω–∏—è #–†–æ—Å—Å–∏—è #–ö–∏—Ç–∞–π #–ö–æ—Ä–µ—è #–î—è–æ—é–π–¥–∞–æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0T+oJ4XBPG6ZbvgO0NQ+c+u6aQ5oDuzGtyT8lMLPEFM=</th>\n",
       "      <td>[–í–æ—Ç —É–∂ –Ω–µ –¥—É–º–∞–ª, —á—Ç–æ –†–∞—à–∫–∞ —Å–º–æ–∂–µ—Ç, –°–∞–º–æ–µ \"—É–¥–∞...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=</th>\n",
       "      <td>[People are not silent! This structure must ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=</th>\n",
       "      <td>[El pueblo ind√≠gena Kayapo cerr√≥ una important...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=</th>\n",
       "      <td>[@VoteMarsha Why Women Prefer to Vote for an r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067814896706994176</th>\n",
       "      <td>[Inilah bentuk rasionalitas islam dan ketiadaa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091795789263921152</th>\n",
       "      <td>[ÿß⁄ØŸá ÿßŸÖÿ¥ÿ® ŸÖŸàŸÑÿßŸÜÿß ÿ™Ÿà€å€åÿ™ÿ± ŸÖ€åŸàŸÖÿØ ÿßÿ≤ ŸáŸÖŸá ŸÖŸàŸÜ ÿ±ÿßÿ∂€å ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099221870530961408</th>\n",
       "      <td>[Droit de vote √† 16ans, vous √™tes ?\\nEt pourqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213164353236504576</th>\n",
       "      <td>[ü¶†#Coronavirus, üá∞üáµ#KimJongUn, üá±üáæ#Libya\\n\\nhttp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235289416370774016</th>\n",
       "      <td>[Trump has realized that he will be the loser ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273528131861782528</th>\n",
       "      <td>[The Trumps have ruined our country and if ree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135AEY00MOP1tH7YCuKyQx2xM0hG1vsl7l+0QPTliyM=</th>\n",
       "      <td>[Insurgents shelled Al Nayrab of the #Aleppo g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1L0qn8rgg4bi6tCYH934gRpAQG59vTUg9kPubBzxM=</th>\n",
       "      <td>[just look at all the caravanserais that held ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Pqyt2W75POPX+6zd9UdZL89ALBtPPELN4NPrly0nag=</th>\n",
       "      <td>[haqqin.az –ú–∞—Å—à—Ç–∞–±–Ω—ã–µ —É—á–µ–Ω–∏—è –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏—Ö –ø...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1Rf2s0L++cCmiGYutfy0oPxgMZWJVERRGF5P2Vryi0=</th>\n",
       "      <td>[Buenos d√≠as princesa, que el d√≠a ya ha comenz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1lY66yW7i+XL4Fn6wRslwEStbOHd2vNXLSnJMpQjUg8=</th>\n",
       "      <td>[#–ù–ê–¢–û #—ç–∫–æ–ª–æ–≥–∏—è #–ø—Ä–∏–±–∞–ª—Ç–∏–∫–∞ #–±–∞–ª—Ç–∏–π—Å–∫–æ–µ–º–æ—Ä–µ #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1rJVco1i2kqTr9XIp2G6n5jklStyGfK3DYfYjOSz3Pk=</th>\n",
       "      <td>[Looks like one more #fake. #Russian forces #K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213589457</th>\n",
       "      <td>[¬°Quedan 3 episodios para el final!\\nSerie \"El...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22vodAc2tmpYoHPMBh1l6aaGBbw23CRbg5S4OMthSU=</th>\n",
       "      <td>[#QuarantineAQuote Imagine if the roles were r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23vaC1gG734g7FYBCL66wVv4Z5k1I48mYXwAWmwsa1E=</th>\n",
       "      <td>[In case you missed it, the first US president...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2RHBBCePF5Uasa4EGd9NRMi3v3EgZxWRjsDXIA4RVM=</th>\n",
       "      <td>[fotos de un adolescente estadounidense racist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nFqmLka396xUudTDoWTeXrpBt+q8inJmJYc3p58p4=</th>\n",
       "      <td>[–õ–µ–¥–æ–∫–æ–ª—å–Ω—ã–µ —Å—É–¥–∞ - —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ä—ã–≤ –†–æ—Å...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2rg8fiE11JB8Bh69A6aJWeRSBPcGTAmK8wnpFpH0=</th>\n",
       "      <td>[Interview w/ Ayaz Mutalibov, first President ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31oxxNtP2VrM9ikKG3whNZjg9B4iE0sRtOakzh28qOU=</th>\n",
       "      <td>[#–≥–∞–≥–∞—Ä–∏–Ω #GAGARIN \\n–ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –ì–∞–≥–∞—Ä–∏–Ω http:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33Sm6bZv1nnOhdySB2Uw9CW54F7HhhZh1v9f9cjEmz8=</th>\n",
       "      <td>[ŸÖÿß ÿßÿ≤ ŸáŸÖ€åŸÜ ÿ≠ÿßŸÑÿß ÿ¨ŸÑŸà€å ÿß€åÿ¨ÿßÿØ ŸÜÿßŸÜÿ≥€å ŸæŸÑŸàÿ≥€å Ÿáÿß Ÿà ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376365080</th>\n",
       "      <td>[–≤–µ—Å–Ω–∞ –æ–±–º–∞–Ω—á–∏–≤–∞—è\\n–∫ –ª—å–¥–∏–Ω–∞–º –Ω–æ—Ä–æ–≤–∏—Ç –ø—Ä–∏—Å–æ–µ–¥–∏–Ω...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3HqwdUkxRabgmTyNHI1ZCilGchjYg8o91jHRFFRdWX0=</th>\n",
       "      <td>[Hi everybody. I'm an amateur photographer and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3PGzTwb+Kk4yCSOyqgAZ3zPaUJ7xE3L+BSppo6ZLw8U=</th>\n",
       "      <td>[#HTS militants create girls' facebook pages a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3bc6BmmosKy9g+hwhMnLbHJWbe4pYksRUKf+aM50go=</th>\n",
       "      <td>[Viktor Krivopuskov, Minister of Defence os #U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3wyxtnGm6RUozXZ0pLy92lrUpF8WLHNFQ4zlc4TMO0=</th>\n",
       "      <td>[Iranian diplomats too have argued that the U....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3zIYK8MEFJoOspSoDuQYI+Bqi7cyAOsQnlPHRdJue0=</th>\n",
       "      <td>[U.S. sacrifices #Kurds in #Syria, because in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46eJLsV6+iDw1rVv36i9NONigsfqfTfQ9EBzXr901c=</th>\n",
       "      <td>[: –í –ë–∞–∫—É –ø–æ–∫–æ–Ω—á–∏–ª–∞ —Å —Å–æ–±–æ–π 15-–ª–µ—Ç–Ω–∏–π –ø–æ–¥—Ä–æ—Å—Ç–æ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4RHQs48X7Mzwe4HTmThSxmpMK3035MEWqXo3cnAtaFs=</th>\n",
       "      <td>[DR. Anthony Fauci: I congratulate Russians to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4fDgP2zd289XEnjWMomG2RATqLyehNzUjrqnJOq3I=</th>\n",
       "      <td>[The stronger the outcome is in favor of #Joe_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51qENUkzfVmrYDTbRru2Ny2zhFm3lVperQrco7TNiI=</th>\n",
       "      <td>[Quien con una sonrisa se levanta un buen d√≠a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53159149</th>\n",
       "      <td>[France Arms Russian #Navy  http://bit.ly/iaN5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5O68KDqdztRXhsl9HkNpWLfdwjINlgxlCDiKbBCFzzc=</th>\n",
       "      <td>[Malawi is using bamboo to fight #climatechang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5lO2pgga8hVQbnn2K1oyw+Z2ecb7PQee0iJ3tTNs=</th>\n",
       "      <td>[Israel has used its cruel administrative dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6UQXw4Mnf0c4YkJ5rSJWtgfZlNBQFdx38mOzYUt16sI=</th>\n",
       "      <td>[Here's my burger thingüòãüçîü•Ç\\n#NationalCheesebur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6nDcSemH7EpMzxlBrA8G5QRpuoEj4Bl2drKLTQnWE=</th>\n",
       "      <td>[Pro-Turkish militants from #SNA attacked Jibr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6oS8MGSDB5qwiNMvr+d2ITHHgU1DxnqXN94hWmGD1HM=</th>\n",
       "      <td>[üßêüßê https://t.co/go8upieHJl, Researchers at th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=</th>\n",
       "      <td>[Sungguh bodoh orang yang tidak mau membela ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6rZlwzFuvQH63uRh8lEbmPv6oyeNNJKrYhtzS68twq0=</th>\n",
       "      <td>[Trump is advertising that .... #Biden  #VoteB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6rdue70c97oL6cCnqXz5tdfnePCaHuDuOuYmbpx4mF4=</th>\n",
       "      <td>[–ü–†–û–í–ê–õ–¨–ù–ê–Ø –ü–û–õ–ò–¢–ò–ö–ê –°–ò–ù–î–ó–û –ê–ë–≠ https://t.co/v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794097607845015552</th>\n",
       "      <td>[#IslamicRevolution as a lesson for the whole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=</th>\n",
       "      <td>[god will punish you Aung San Suu Kyi #ShameOn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7CQHe488W6+t0uGOqaaxoJl6O3i3IkLdR6kUJJChJvs=</th>\n",
       "      <td>[–°–ù–ì –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —É—Å–∏–ª–∏—è –≤ –±–æ—Ä—å–±–µ —Å —Ç–µ—Ä—Ä–æ—Ä–∏–∑–º–æ–º ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     tweet_text\n",
       "userid                                                                                         \n",
       "+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=   [America and the way its government treats its...\n",
       "+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=  [@ManotoNews ÿß⁄ØŸá ÿß€åÿ±ÿßŸÜ ÿ®Ÿá €åŸÖŸÜ Ÿà ŸÖŸÇÿßŸàŸÖÿ™ ⁄©ŸÖ⁄© ŸÜ⁄©ŸÜ...\n",
       "0+2DdcWQlF1LIe31q4foyvQMZYObIOeoh5woH5+4ySo=  [A group belonging to the HTS kidnapped Yasser...\n",
       "07CPSEe0H6QwZcanuJd4G4sYBjmx+NtXpcj2NdAAmr0=  [#–°–®–ê #–Ø–ø–æ–Ω–∏—è #–†–æ—Å—Å–∏—è #–ö–∏—Ç–∞–π #–ö–æ—Ä–µ—è #–î—è–æ—é–π–¥–∞–æ ...\n",
       "0T+oJ4XBPG6ZbvgO0NQ+c+u6aQ5oDuzGtyT8lMLPEFM=  [–í–æ—Ç —É–∂ –Ω–µ –¥—É–º–∞–ª, —á—Ç–æ –†–∞—à–∫–∞ —Å–º–æ–∂–µ—Ç, –°–∞–º–æ–µ \"—É–¥–∞...\n",
       "0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=  [People are not silent! This structure must ch...\n",
       "0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=   [El pueblo ind√≠gena Kayapo cerr√≥ una important...\n",
       "0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=  [@VoteMarsha Why Women Prefer to Vote for an r...\n",
       "1067814896706994176                           [Inilah bentuk rasionalitas islam dan ketiadaa...\n",
       "1091795789263921152                           [ÿß⁄ØŸá ÿßŸÖÿ¥ÿ® ŸÖŸàŸÑÿßŸÜÿß ÿ™Ÿà€å€åÿ™ÿ± ŸÖ€åŸàŸÖÿØ ÿßÿ≤ ŸáŸÖŸá ŸÖŸàŸÜ ÿ±ÿßÿ∂€å ...\n",
       "1099221870530961408                           [Droit de vote √† 16ans, vous √™tes ?\\nEt pourqu...\n",
       "1213164353236504576                           [ü¶†#Coronavirus, üá∞üáµ#KimJongUn, üá±üáæ#Libya\\n\\nhttp...\n",
       "1235289416370774016                           [Trump has realized that he will be the loser ...\n",
       "1273528131861782528                           [The Trumps have ruined our country and if ree...\n",
       "135AEY00MOP1tH7YCuKyQx2xM0hG1vsl7l+0QPTliyM=  [Insurgents shelled Al Nayrab of the #Aleppo g...\n",
       "1L0qn8rgg4bi6tCYH934gRpAQG59vTUg9kPubBzxM=    [just look at all the caravanserais that held ...\n",
       "1Pqyt2W75POPX+6zd9UdZL89ALBtPPELN4NPrly0nag=  [haqqin.az –ú–∞—Å—à—Ç–∞–±–Ω—ã–µ —É—á–µ–Ω–∏—è –∞–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω—Å–∫–∏—Ö –ø...\n",
       "1Rf2s0L++cCmiGYutfy0oPxgMZWJVERRGF5P2Vryi0=   [Buenos d√≠as princesa, que el d√≠a ya ha comenz...\n",
       "1lY66yW7i+XL4Fn6wRslwEStbOHd2vNXLSnJMpQjUg8=  [#–ù–ê–¢–û #—ç–∫–æ–ª–æ–≥–∏—è #–ø—Ä–∏–±–∞–ª—Ç–∏–∫–∞ #–±–∞–ª—Ç–∏–π—Å–∫–æ–µ–º–æ—Ä–µ #...\n",
       "1rJVco1i2kqTr9XIp2G6n5jklStyGfK3DYfYjOSz3Pk=  [Looks like one more #fake. #Russian forces #K...\n",
       "213589457                                     [¬°Quedan 3 episodios para el final!\\nSerie \"El...\n",
       "22vodAc2tmpYoHPMBh1l6aaGBbw23CRbg5S4OMthSU=   [#QuarantineAQuote Imagine if the roles were r...\n",
       "23vaC1gG734g7FYBCL66wVv4Z5k1I48mYXwAWmwsa1E=  [In case you missed it, the first US president...\n",
       "2RHBBCePF5Uasa4EGd9NRMi3v3EgZxWRjsDXIA4RVM=   [fotos de un adolescente estadounidense racist...\n",
       "2nFqmLka396xUudTDoWTeXrpBt+q8inJmJYc3p58p4=   [–õ–µ–¥–æ–∫–æ–ª—å–Ω—ã–µ —Å—É–¥–∞ - —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ä—ã–≤ –†–æ—Å...\n",
       "2rg8fiE11JB8Bh69A6aJWeRSBPcGTAmK8wnpFpH0=     [Interview w/ Ayaz Mutalibov, first President ...\n",
       "31oxxNtP2VrM9ikKG3whNZjg9B4iE0sRtOakzh28qOU=  [#–≥–∞–≥–∞—Ä–∏–Ω #GAGARIN \\n–ó–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –ì–∞–≥–∞—Ä–∏–Ω http:...\n",
       "33Sm6bZv1nnOhdySB2Uw9CW54F7HhhZh1v9f9cjEmz8=  [ŸÖÿß ÿßÿ≤ ŸáŸÖ€åŸÜ ÿ≠ÿßŸÑÿß ÿ¨ŸÑŸà€å ÿß€åÿ¨ÿßÿØ ŸÜÿßŸÜÿ≥€å ŸæŸÑŸàÿ≥€å Ÿáÿß Ÿà ....\n",
       "376365080                                     [–≤–µ—Å–Ω–∞ –æ–±–º–∞–Ω—á–∏–≤–∞—è\\n–∫ –ª—å–¥–∏–Ω–∞–º –Ω–æ—Ä–æ–≤–∏—Ç –ø—Ä–∏—Å–æ–µ–¥–∏–Ω...\n",
       "3HqwdUkxRabgmTyNHI1ZCilGchjYg8o91jHRFFRdWX0=  [Hi everybody. I'm an amateur photographer and...\n",
       "3PGzTwb+Kk4yCSOyqgAZ3zPaUJ7xE3L+BSppo6ZLw8U=  [#HTS militants create girls' facebook pages a...\n",
       "3bc6BmmosKy9g+hwhMnLbHJWbe4pYksRUKf+aM50go=   [Viktor Krivopuskov, Minister of Defence os #U...\n",
       "3wyxtnGm6RUozXZ0pLy92lrUpF8WLHNFQ4zlc4TMO0=   [Iranian diplomats too have argued that the U....\n",
       "3zIYK8MEFJoOspSoDuQYI+Bqi7cyAOsQnlPHRdJue0=   [U.S. sacrifices #Kurds in #Syria, because in ...\n",
       "46eJLsV6+iDw1rVv36i9NONigsfqfTfQ9EBzXr901c=   [: –í –ë–∞–∫—É –ø–æ–∫–æ–Ω—á–∏–ª–∞ —Å —Å–æ–±–æ–π 15-–ª–µ—Ç–Ω–∏–π –ø–æ–¥—Ä–æ—Å—Ç–æ...\n",
       "4RHQs48X7Mzwe4HTmThSxmpMK3035MEWqXo3cnAtaFs=  [DR. Anthony Fauci: I congratulate Russians to...\n",
       "4fDgP2zd289XEnjWMomG2RATqLyehNzUjrqnJOq3I=    [The stronger the outcome is in favor of #Joe_...\n",
       "51qENUkzfVmrYDTbRru2Ny2zhFm3lVperQrco7TNiI=   [Quien con una sonrisa se levanta un buen d√≠a ...\n",
       "53159149                                      [France Arms Russian #Navy  http://bit.ly/iaN5...\n",
       "5O68KDqdztRXhsl9HkNpWLfdwjINlgxlCDiKbBCFzzc=  [Malawi is using bamboo to fight #climatechang...\n",
       "5lO2pgga8hVQbnn2K1oyw+Z2ecb7PQee0iJ3tTNs=     [Israel has used its cruel administrative dete...\n",
       "6UQXw4Mnf0c4YkJ5rSJWtgfZlNBQFdx38mOzYUt16sI=  [Here's my burger thingüòãüçîü•Ç\\n#NationalCheesebur...\n",
       "6nDcSemH7EpMzxlBrA8G5QRpuoEj4Bl2drKLTQnWE=    [Pro-Turkish militants from #SNA attacked Jibr...\n",
       "6oS8MGSDB5qwiNMvr+d2ITHHgU1DxnqXN94hWmGD1HM=  [üßêüßê https://t.co/go8upieHJl, Researchers at th...\n",
       "6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=    [Sungguh bodoh orang yang tidak mau membela ba...\n",
       "6rZlwzFuvQH63uRh8lEbmPv6oyeNNJKrYhtzS68twq0=  [Trump is advertising that .... #Biden  #VoteB...\n",
       "6rdue70c97oL6cCnqXz5tdfnePCaHuDuOuYmbpx4mF4=  [–ü–†–û–í–ê–õ–¨–ù–ê–Ø –ü–û–õ–ò–¢–ò–ö–ê –°–ò–ù–î–ó–û –ê–ë–≠ https://t.co/v...\n",
       "794097607845015552                            [#IslamicRevolution as a lesson for the whole ...\n",
       "79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=  [god will punish you Aung San Suu Kyi #ShameOn...\n",
       "7CQHe488W6+t0uGOqaaxoJl6O3i3IkLdR6kUJJChJvs=  [–°–ù–ì –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç —É—Å–∏–ª–∏—è –≤ –±–æ—Ä—å–±–µ —Å —Ç–µ—Ä—Ä–æ—Ä–∏–∑–º–æ–º ..."
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df = (df\n",
    "           .groupby('userid')[['tweet_text']]\n",
    "           .agg(lambda x: list(x))\n",
    "          ).head(50)\n",
    "list_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america',\n",
       " 'and',\n",
       " 'the',\n",
       " 'way',\n",
       " 'its',\n",
       " 'government',\n",
       " 'treats',\n",
       " 'its',\n",
       " 'people',\n",
       " 'must',\n",
       " 'be',\n",
       " 'reformed',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'poland',\n",
       " 'police',\n",
       " 'bureau',\n",
       " 'is',\n",
       " 'preparing',\n",
       " 'for',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'mass',\n",
       " 'gathering',\n",
       " 'events',\n",
       " 'being',\n",
       " 'planned',\n",
       " 'for',\n",
       " 'saturday',\n",
       " 'september',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'one',\n",
       " 'group',\n",
       " 'has',\n",
       " 'been',\n",
       " 'announced',\n",
       " 'they',\n",
       " 'will',\n",
       " 'hold',\n",
       " 'an',\n",
       " 'event',\n",
       " 'at',\n",
       " 'delta',\n",
       " 'park',\n",
       " 'at',\n",
       " 'noon',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'lies',\n",
       " 'why',\n",
       " 'hypocrisy',\n",
       " 'why',\n",
       " 'security',\n",
       " 'forces',\n",
       " 'why',\n",
       " 'racism',\n",
       " 'why',\n",
       " 'cut',\n",
       " 'budgets',\n",
       " 'to',\n",
       " 'deceive',\n",
       " 'people',\n",
       " 'no',\n",
       " 'trump',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'difference',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'he',\n",
       " 'has',\n",
       " 'destroyed',\n",
       " 'every',\n",
       " 'busines',\n",
       " 'üêÇ',\n",
       " 'üêÉ',\n",
       " 'üêÉ',\n",
       " 'üêÉ',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'even',\n",
       " 'if',\n",
       " 'the',\n",
       " 'power',\n",
       " 'to',\n",
       " 'negotiate',\n",
       " 'deals',\n",
       " 'is',\n",
       " 'handed',\n",
       " 'over',\n",
       " 'to',\n",
       " 'the',\n",
       " 'presidency',\n",
       " 'congress',\n",
       " 'will',\n",
       " 'still',\n",
       " 'have',\n",
       " 'the',\n",
       " 'final',\n",
       " 'say',\n",
       " 'and',\n",
       " 'judging',\n",
       " 'by',\n",
       " 'the',\n",
       " 'current',\n",
       " 'political',\n",
       " 'climate',\n",
       " 'johnson',\n",
       " 'will',\n",
       " 'not',\n",
       " 'fire',\n",
       " 'him',\n",
       " 'this',\n",
       " 'time',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'trump',\n",
       " 'trump',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'yes',\n",
       " 'biden',\n",
       " 'not',\n",
       " 'trump',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'and',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'democratic',\n",
       " 'presidential',\n",
       " 'nominee',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'had',\n",
       " 'also',\n",
       " 'warned',\n",
       " 'johnson',\n",
       " 'that',\n",
       " 'either',\n",
       " 'he',\n",
       " 'will',\n",
       " 'respect',\n",
       " 'nohern',\n",
       " 'ireland',\n",
       " '‚Äô',\n",
       " 's',\n",
       " 'peace',\n",
       " 'agreement',\n",
       " 'or',\n",
       " 'else',\n",
       " 'he',\n",
       " 'will',\n",
       " 'get',\n",
       " 'no',\n",
       " 'us',\n",
       " 'trade',\n",
       " 'deal',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " 'why',\n",
       " 'should',\n",
       " 'racism',\n",
       " 'exist',\n",
       " 'in',\n",
       " 'america',\n",
       " 'for',\n",
       " 'example',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'first',\n",
       " 'country',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'who',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idiot',\n",
       " 'the',\n",
       " 'one',\n",
       " 'who',\n",
       " 'extended',\n",
       " 'the',\n",
       " 'corona',\n",
       " 'who',\n",
       " 'is',\n",
       " 'trump',\n",
       " 'according',\n",
       " 'to',\n",
       " 'pelosi',\n",
       " 'corona',\n",
       " 'herself',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'our',\n",
       " 'president',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " 'he',\n",
       " 'is',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'raping',\n",
       " 'a',\n",
       " 'year-old',\n",
       " 'girl',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'this',\n",
       " 'photo',\n",
       " 'of',\n",
       " 'racism',\n",
       " 'is',\n",
       " 'complete',\n",
       " 'does',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'explained',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'are',\n",
       " 'democrats',\n",
       " 'angry',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'lying',\n",
       " 'about',\n",
       " 'vaccines',\n",
       " 'nono',\n",
       " 'no',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'heaven',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'reduction',\n",
       " 'in',\n",
       " 'brazilian',\n",
       " 'expos',\n",
       " 'to',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " 'although',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'its',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'brazil',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'it',\n",
       " 'is',\n",
       " 'something',\n",
       " 'else',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'in',\n",
       " 'america',\n",
       " 'the',\n",
       " 'law',\n",
       " 'goes',\n",
       " 'hand',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'with',\n",
       " 'the',\n",
       " 'police',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'people',\n",
       " 'die',\n",
       " 'every',\n",
       " 'day',\n",
       " 'and',\n",
       " 'trump',\n",
       " 'tells',\n",
       " 'new',\n",
       " 'lies',\n",
       " 'every',\n",
       " 'day',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'health',\n",
       " 'wants',\n",
       " 'a',\n",
       " 'long-term',\n",
       " 'plan',\n",
       " 'not',\n",
       " 'like',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'did',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'masks',\n",
       " 'after',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'again',\n",
       " 'when',\n",
       " 'coronary',\n",
       " 'hea',\n",
       " 'disease',\n",
       " 'spread',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'what',\n",
       " 'are',\n",
       " 'your',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'choosing',\n",
       " 'trump',\n",
       " 'as',\n",
       " 'the',\n",
       " 'successor',\n",
       " 'to',\n",
       " 'the',\n",
       " 'late',\n",
       " 'lady',\n",
       " 'of',\n",
       " 'american',\n",
       " 'justice',\n",
       " '<-#->',\n",
       " 'corona',\n",
       " 'is',\n",
       " 'for',\n",
       " 'all',\n",
       " 'ages',\n",
       " 'mask',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'corona',\n",
       " 'corona',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'medicine',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'biden',\n",
       " 'and',\n",
       " 'kissing',\n",
       " 'granddaughter',\n",
       " 'magically',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'corona',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'deadly',\n",
       " 'germs',\n",
       " 'ale',\n",
       " 'in',\n",
       " 'texas',\n",
       " 'drinking',\n",
       " 'water',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'look',\n",
       " 'üëá',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'and',\n",
       " 'corona',\n",
       " 'are',\n",
       " 'destroying',\n",
       " 'america',\n",
       " 'together',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'smile',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'no',\n",
       " 'impoant',\n",
       " '‚ö†',\n",
       " 'more',\n",
       " 'than',\n",
       " 'of',\n",
       " 'americans',\n",
       " 'say',\n",
       " 'the',\n",
       " 'debates',\n",
       " 'won',\n",
       " '‚Äô',\n",
       " 't',\n",
       " 'matter',\n",
       " 'much',\n",
       " 'to',\n",
       " 'them',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'journalnbc',\n",
       " 'news',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'my',\n",
       " 'veto',\n",
       " 'protective',\n",
       " 'mask',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '‚ù§',\n",
       " 'üòÇ',\n",
       " '‚ù§',\n",
       " 'üòÇ',\n",
       " '‚ù§',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'liar',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'ginsburg',\n",
       " 'justice',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'dream',\n",
       " 'might',\n",
       " 'come',\n",
       " 'true',\n",
       " 'without',\n",
       " 'trump',\n",
       " 'yes',\n",
       " 'without',\n",
       " 'a',\n",
       " 'fool',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'a',\n",
       " 'tyrant',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'tyranny',\n",
       " 'if',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'elected',\n",
       " 'in',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'wear',\n",
       " 'a',\n",
       " 'mask',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'do',\n",
       " 'not',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'dumb',\n",
       " 'president',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'think',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'from',\n",
       " 'reality',\n",
       " 'to',\n",
       " 'lies',\n",
       " 'from',\n",
       " 'eah',\n",
       " 'to',\n",
       " 'sky',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'american',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'thanks',\n",
       " 'obama',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'destruction',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'do',\n",
       " 'you',\n",
       " 'blame',\n",
       " 'your',\n",
       " 'shocomings',\n",
       " 'and',\n",
       " 'your',\n",
       " 'government',\n",
       " 'on',\n",
       " 'the',\n",
       " 'states',\n",
       " 'and',\n",
       " 'condemn',\n",
       " 'them',\n",
       " 'trump',\n",
       " 'enough',\n",
       " 'lies',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'it',\n",
       " 'just',\n",
       " 'goes',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " 'whether',\n",
       " 'he',\n",
       " 'has',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'or',\n",
       " 'not',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'lying',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'that',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'was',\n",
       " 'not',\n",
       " 'produced',\n",
       " 'in',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'betraying',\n",
       " 'the',\n",
       " 'americans',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'a',\n",
       " 'world',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'just',\n",
       " 'for',\n",
       " 'voting',\n",
       " 'correctly',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " 'the',\n",
       " 'miami',\n",
       " 'heat',\n",
       " 'team',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'finals',\n",
       " 'the',\n",
       " 'year',\n",
       " 'high',\n",
       " 'was',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " 'great',\n",
       " '<-url->',\n",
       " 'corona',\n",
       " 'means',\n",
       " 'an',\n",
       " 'excuse',\n",
       " 'for',\n",
       " 'dismissal',\n",
       " 'please',\n",
       " 'see',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'the',\n",
       " 'economy',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-url->',\n",
       " 'the',\n",
       " 'cdc',\n",
       " 'director',\n",
       " 'says',\n",
       " 'young',\n",
       " 'people',\n",
       " 'are',\n",
       " 'expanding',\n",
       " 'the',\n",
       " 'corona',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " 'racism',\n",
       " 'in',\n",
       " 'a',\n",
       " 'country',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'claims',\n",
       " 'of',\n",
       " 'humanity',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '<-#->',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-@->',\n",
       " 'deutschland',\n",
       " 'ist',\n",
       " 'wenn',\n",
       " 'nur',\n",
       " 'polizistinnen',\n",
       " 'nazis',\n",
       " 'davon',\n",
       " 'abhalten',\n",
       " 'den',\n",
       " 'bundestag',\n",
       " 'zu',\n",
       " 'st√ºrmen',\n",
       " 'aber',\n",
       " 'einheiten',\n",
       " 'mit',\n",
       " 'hunden',\n",
       " 'pfe',\n",
       " '‚Ä¶',\n",
       " '<-@->',\n",
       " 'no',\n",
       " '‚ù§',\n",
       " 'trump',\n",
       " 'no',\n",
       " 'üíö',\n",
       " 'no',\n",
       " 'üíú',\n",
       " '<-#->',\n",
       " '<-url->',\n",
       " '<-@->',\n",
       " 'yesthis',\n",
       " 'is',\n",
       " 'awful',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'should',\n",
       " 'also',\n",
       " 'have',\n",
       " 'stoped',\n",
       " 'the',\n",
       " 'asteroid',\n",
       " 'from',\n",
       " 'wiping',\n",
       " 'out',\n",
       " 'the',\n",
       " 'dinosaurs',\n",
       " '<-@->',\n",
       " '‚Äú',\n",
       " 'my',\n",
       " 'most',\n",
       " 'fervent',\n",
       " 'wish',\n",
       " 'is',\n",
       " 'that',\n",
       " 'i',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'replaced',\n",
       " 'until',\n",
       " 'a',\n",
       " 'new',\n",
       " 'president',\n",
       " 'is',\n",
       " 'installed',\n",
       " '‚Äù',\n",
       " '‚Äì',\n",
       " 'justice',\n",
       " 'ruth',\n",
       " 'bader',\n",
       " 'ginsbur',\n",
       " '‚Ä¶',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " '<-@->',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'how',\n",
       " 'trump',\n",
       " 'handled',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'monster',\n",
       " '<-#->',\n",
       " '‚Ä¶',\n",
       " '<-@->',\n",
       " 'all',\n",
       " 'trump',\n",
       " 'suppoers',\n",
       " 'believe',\n",
       " 'bidens',\n",
       " 'truths',\n",
       " 'as',\n",
       " 'lies',\n",
       " 'but',\n",
       " 'believe',\n",
       " 'trumps',\n",
       " 'lies',\n",
       " 'as',\n",
       " 'truthshow',\n",
       " 'ironic',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " '‚Ä¶',\n",
       " '<-@->',\n",
       " 'sick',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'disturbing',\n",
       " 'things',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'how',\n",
       " 'he',\n",
       " 'has',\n",
       " 'embraced',\n",
       " 'and',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'normalize',\n",
       " 'so',\n",
       " 'many',\n",
       " 'distur',\n",
       " '‚Ä¶',\n",
       " '<-@->',\n",
       " 'so',\n",
       " 'trump',\n",
       " 'suppoers',\n",
       " 'are',\n",
       " 'saying',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'therapist',\n",
       " 'should',\n",
       " 'we',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'to',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'scientist',\n",
       " '<-@->',\n",
       " 'yes',\n",
       " '‚ù§',\n",
       " '<-@->',\n",
       " 'ÿß⁄ØŸá',\n",
       " 'ÿß€åÿ±ÿßŸÜ',\n",
       " 'ÿ®Ÿá',\n",
       " '€åŸÖŸÜ',\n",
       " 'Ÿà',\n",
       " 'ŸÖŸÇÿßŸàŸÖÿ™',\n",
       " '⁄©ŸÖ⁄©',\n",
       " 'ŸÜ⁄©ŸÜŸá',\n",
       " 'ÿÆÿß⁄©',\n",
       " 'ÿ™Ÿà',\n",
       " 'ÿ≥ÿ±ÿ¥',\n",
       " 'ŸÑÿ∑ŸÅÿß',\n",
       " '⁄©ÿ≥ÿßŸÜ€å',\n",
       " '⁄©Ÿá',\n",
       " 'Ÿàÿßÿ≥Ÿá',\n",
       " 'ÿß€åÿ±ÿßŸÜ',\n",
       " 'Ÿà',\n",
       " 'ŸÖÿ±ÿØŸÖ',\n",
       " 'ÿ≥€åŸÑ',\n",
       " 'ÿ≤ÿØŸá',\n",
       " '⁄©ŸÖ⁄©',\n",
       " 'ŸÜ⁄©ÿ±ÿØŸÜÿØ',\n",
       " 'ŸÜÿ∏ÿ±',\n",
       " 'ŸÜÿØŸÜ',\n",
       " 'üîò',\n",
       " 'ŸæŸáÿ®ÿßÿØ',\n",
       " 'ÿ≥Ÿá',\n",
       " 'ÿ™ÿß',\n",
       " '€±€∞€∞€∞',\n",
       " '€åŸàÿ±Ÿà',\n",
       " 'üîò',\n",
       " 'ŸÖŸàÿ¥⁄©',\n",
       " 'ÿ≥Ÿàÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿ¨ÿØÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿ®ÿ®ÿ±',\n",
       " 'ÿØÿπÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿØŸàŸÜŸá',\n",
       " 'ÿß€å',\n",
       " '€±€∞€∞€∞',\n",
       " '€åŸàÿ±Ÿà',\n",
       " 'üîò',\n",
       " 'ŸÜÿßŸà',\n",
       " 'ÿ∫ŸÜ€åŸÖÿ™€å',\n",
       " 'ÿ®ÿß',\n",
       " 'ÿÆÿØŸÖŸá',\n",
       " 'ÿ¢ŸÖÿ±€å⁄©ÿß€å€å',\n",
       " 'ÿ±ÿß€å⁄ØÿßŸÜ',\n",
       " 'üîò',\n",
       " 'ŸÜÿßŸà',\n",
       " 'ÿ®ÿØŸàŸÜ',\n",
       " 'ÿÆÿØŸÖŸá',\n",
       " 'ŸÇÿ≥ÿ∑€å',\n",
       " 'ŸÖÿßŸá€å',\n",
       " '€±€∞€∞€∞',\n",
       " '€åŸàÿ±Ÿà',\n",
       " 'ÿ®ÿØŸà',\n",
       " 'ÿß€åŸÜŸàÿ±',\n",
       " 'ÿ®ÿßÿ≤ÿßÿ±',\n",
       " '<-@->',\n",
       " 'ÿ®ÿπÿ∂€å',\n",
       " '⁄©Ÿá',\n",
       " 'ŸÖ€åÿ±ŸÜ',\n",
       " 'ÿÆÿßÿ±ÿ¨',\n",
       " '⁄©Ÿá',\n",
       " 'ŸÖÿ´ŸÑÿß',\n",
       " 'ÿ¢ÿ≤ÿßÿØ',\n",
       " 'ÿ®ÿßÿ¥ŸÜ',\n",
       " 'ÿå',\n",
       " '⁄ÜŸÜÿßŸÜ',\n",
       " 'ÿØÿ±⁄Ø€åÿ±',\n",
       " 'ŸÇŸàÿßŸÜ€åŸÜ',\n",
       " 'ÿßÿ¨ÿ®ÿßÿ±€å',\n",
       " 'Ÿà',\n",
       " 'ÿÆÿ¥⁄©',\n",
       " 'ÿØÿ±',\n",
       " 'ÿ∫ÿ±ÿ®ÿ™',\n",
       " 'ŸÖ€åÿ¥ŸÜ',\n",
       " '⁄©Ÿá',\n",
       " 'ÿ¢ÿ≤ÿßÿØ€å€å',\n",
       " '⁄©Ÿá',\n",
       " 'ÿ™Ÿà',\n",
       " 'ÿß€åÿ±ÿßŸÜ',\n",
       " 'ÿØÿßÿ¥ÿ™ŸÜ',\n",
       " 'ÿ®ÿ±ÿßÿ¥ŸàŸÜ',\n",
       " 'ÿ≠ÿ≥ÿ±ÿ™',\n",
       " 'Ÿà',\n",
       " 'ÿ±Ÿà€åÿß',\n",
       " 'ŸÖ€åÿ¥Ÿá',\n",
       " 'ÿß€åŸÜÿ¨ÿß',\n",
       " 'ŸÇÿßŸÜŸàŸÜ',\n",
       " 'ÿØÿßÿ±Ÿá',\n",
       " 'Ÿà',\n",
       " 'Ÿáÿ±⁄ÜŸÜÿØ',\n",
       " 'ÿßÿ¥ÿ™ÿ®ÿßŸá',\n",
       " 'ÿå',\n",
       " 'ÿ®ÿß€åÿØ',\n",
       " 'ÿ±ÿπÿß€åÿ™',\n",
       " '⁄©ÿ±ÿØ',\n",
       " 'ÿ±ÿπÿß€åÿ™',\n",
       " 'ŸÇÿßŸÜŸàŸÜ',\n",
       " ...]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df = list_df.loc[:]['tweet_text']\n",
    "tokenized_iter = tokenize_iter(list_df)\n",
    "tokenized_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline:\n",
    "We are starting with a series of strings representing individual tweets. We can perform our analysis on\n",
    "- individual tweets\n",
    "- all tweets for a grouping of the dataframe (e.g. group by userid)\n",
    "- all tweets in the corpus\n",
    "\n",
    "In addition,\n",
    "- hashtags and urls are already in a separate column.\n",
    "\n",
    "In general, we want to convert tweet text into tokens for analysis. We will make utility functions which anticipate tokenizing for these levels of analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = UsersData('../data/users')\n",
    "tweets = TweetsData('../data/tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets.df.loc[:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "campaign = df['campaign'] == 'iran202012'\n",
    "iran = df[campaign]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation for tweet text is defined as joining tweet strings into a list of strings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets = (iran\n",
    "               .groupby('userid')[['tweet_text']]\n",
    "               .agg(lambda x: list(x))\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=</th>\n",
       "      <td>[America and the way its government treats its...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=</th>\n",
       "      <td>[@ManotoNews ÿß⁄ØŸá ÿß€åÿ±ÿßŸÜ ÿ®Ÿá €åŸÖŸÜ Ÿà ŸÖŸÇÿßŸàŸÖÿ™ ⁄©ŸÖ⁄© ŸÜ⁄©ŸÜ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=</th>\n",
       "      <td>[People are not silent! This structure must ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=</th>\n",
       "      <td>[El pueblo ind√≠gena Kayapo cerr√≥ una important...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=</th>\n",
       "      <td>[@VoteMarsha Why Women Prefer to Vote for an r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=</th>\n",
       "      <td>[Take a good look at #Trump and tweet me if yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=</th>\n",
       "      <td>[Hapus zionisme hapus penjajahan.\\n#Palestine\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zFlH+vHUhiZD2qvvCLYyiU76qOha9+iYxCn1NVmzw=</th>\n",
       "      <td>[Karl Marx is the leader of These Do nothing D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zTUtu8WZ3RwxnwgMsYXnTU107UXsn4MQU5wrg8IDOU=</th>\n",
       "      <td>[I am sick and tired of being lied to by #real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zk4khaX7A3XhXVndteeiXLe4ma8xR7bYMBCOhCt68j8=</th>\n",
       "      <td>[Como #EEUU asesin√≥ al general Soleimani, ser√°...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     tweet_text\n",
       "userid                                                                                         \n",
       "+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=   [America and the way its government treats its...\n",
       "+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=  [@ManotoNews ÿß⁄ØŸá ÿß€åÿ±ÿßŸÜ ÿ®Ÿá €åŸÖŸÜ Ÿà ŸÖŸÇÿßŸàŸÖÿ™ ⁄©ŸÖ⁄© ŸÜ⁄©ŸÜ...\n",
       "0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=  [People are not silent! This structure must ch...\n",
       "0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=   [El pueblo ind√≠gena Kayapo cerr√≥ una important...\n",
       "0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=  [@VoteMarsha Why Women Prefer to Vote for an r...\n",
       "...                                                                                         ...\n",
       "y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=   [Take a good look at #Trump and tweet me if yo...\n",
       "z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=   [Hapus zionisme hapus penjajahan.\\n#Palestine\\...\n",
       "zFlH+vHUhiZD2qvvCLYyiU76qOha9+iYxCn1NVmzw=    [Karl Marx is the leader of These Do nothing D...\n",
       "zTUtu8WZ3RwxnwgMsYXnTU107UXsn4MQU5wrg8IDOU=   [I am sick and tired of being lied to by #real...\n",
       "zk4khaX7A3XhXVndteeiXLe4ma8xR7bYMBCOhCt68j8=  [Como #EEUU asesin√≥ al general Soleimani, ser√°...\n",
       "\n",
       "[209 rows x 1 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_of_lists = user_tweets\n",
    "iter_of_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['America and the way its government treats its people must be reformed https://t.co/DupN3cE2dd', 'https://t.co/ee5KZJMm5R', 'Portland Police Bureau is preparing for a variety of mass gathering events being planned for Saturday, September 26, 2020. At this time, one group has been announced they will hold an event at Delta Park at noon.  #PoliceLivesMatter  #Polizeigewalt  #Portland  #PortlandProtests https://t.co/3JSoa0UcOL', 'Why lies ..... why hypocrisy .... why security forces .... why racism ..... why cut budgets .... to deceive people    No Trump       No No   No #ARMY  #COVID„Éº19  #Biden #Trump https://t.co/v1WYXyidzJ', 'Difference #Biden https://t.co/Vl5lB7q2l6', 'He has destroyed every busines......üêÇüêÉüêÉüêÉüêÉüêÉ #TrumpMeltdown https://t.co/tKrPEdujCZ', 'Even if the power to negotiate deals is handed over to the presidency, Congress will still have the final say, and judging by the current political climate, Johnson will not fire him this time #Trump  #Covid_19  #DemocracyDay https://t.co/25ovVSWAFJ', 'Trump ...Trump\\n\\n..trump #Trump https://t.co/vHAZyS0LeZ', '#BlacklivesStillMatter  #BlackLivesMatter https://t.co/XQT3V5vGHZ', 'Yes, Biden ..... not Trump #BidenHarrisLandslide2020 https://t.co/TPYT11Zb4U', '..........and.............üò≠üò≠üò≠ #ThursdayThoughts https://t.co/WHWxf5D44L', 'Democratic Presidential Nominee Joe Biden had also warned Johnson that either he will respect Northern Ireland‚Äôs peace agreement or else he will get no U.S. trade deal. #HappyChenDay\\n #Trump #Covid19', 'Why should racism exist in America? For example, we are the first country in the world #Trump https://t.co/spSLY2UY47', 'Who is the idiot ... the one who extended the corona .... who is Trump according to Pelosi Corona herself #COVID„Éº19 https://t.co/Y5TRDpoZ6M', 'https://t.co/SRByuzX5jC', 'https://t.co/JVX1MaOxQG', 'Our president is ridiculous .... he is accused of raping a 13-year-old girl ...... #Trump #TrumpisaPedo https://t.co/BD3FsyXITS', 'This photo of racism is complete ........ does not want to be explained #Racism #Army #Democrats\\n #democracyday https://t.co/77OHHpy9qe', 'Are Democrats angry about Trump lying about vaccines?  NO.....NO\\n...NO #Trump2020\\n #COVID__19\\n #coronavirus  #Biden', 'The way to heaven https://t.co/Q1YJF6DZAA', 'https://t.co/gUd7uePIca', '32% reduction in Brazilian exports to the United States ..... Although the Trump administration is proud of its relations with Brazil, in practice it is something else #trump #Biden #TrumpKnew  #TrumpkillsAmericans https://t.co/mseaeJDB7O', 'In America, the law goes hand in hand with the police #seattleprotests https://t.co/n1FCwoCON8', '850 people die every day and Trump tells new lies every day #coronavirus\\n #COVID__19\\n #Covid_19 https://t.co/5CT3Q5AzE8', 'Health wants a long-term plan ... not like the Trump administration a few months ago did not believe in masks after a few months again when coronary heart disease spread .... #Health  #coronavirus  #COVID19 https://t.co/bU2vJxKs67', 'What are your plans for choosing Trump as the successor to the late Lady of American Justice? #trump', 'Corona is for all ages .... Mask is suitable for Corona .... Corona does not have any medicine at the moment #coronavirus https://t.co/5YrHdx72vI', '#Covid_19  #DemocracyDay https://t.co/UZS4xmbHRs', 'Biden and kissing granddaughter magically #Biden #trump #TrumpLandslideVictory2020\\n #BidenHarris2020 https://t.co/QDtqEOJPLU', 'Corona.....#coronavirus https://t.co/LcafZ6T7Fz', 'Deadly germs alert in Texas drinking water #COVID„Éº19 https://t.co/kB9TVzkdgE', '#COVID19 https://t.co/vcZAdxUnbx', 'https://t.co/Ke59HugLf5', 'Look.....üëáüò≠üò≠üò≠üò≠üò≠üò≠ #TrumpTownHall https://t.co/CLpf9940mZ', 'Trump and Corona are destroying America together #Trump\\n #Corona\\n#TrumpPressConference https://t.co/0E1GVkA1ir', 'https://t.co/36dmHri4pG', '#TrumpTownHall https://t.co/WaF778uKj1', 'https://t.co/5hlUTfhf3g', 'smile https://t.co/nkfBCugmoJ', 'https://t.co/YcK6ypfmeQ', 'No important  ‚ö†More than 70% of Americans say the debates won‚Äôt matter much to them, a recent Wall Street Journal/NBC News #TrumpIsNotABillionaire\\n #TrumpTaxes  #Biden #VoteHimOut2020 https://t.co/y3dwMF3EnD', 'My veto protective mask #COVID19 https://t.co/LRxmlOrfN4', '‚ù§üòÇ‚ù§üòÇ‚ù§ https://t.co/piQwxECUhp', 'Trump.....\\n\\n.Where is the vaccine liar? #COVID19 https://t.co/30NRZTXtNp', '#Trump https://t.co/YXBovhSAxr', 'Ginsburg Justice A beautiful dream might come true without Trump, yes without a fool #Biden #trump #BlackLivesMatter https://t.co/j1dVIrkTer', 'https://t.co/22wjWV5D1d', 'Trump is a tyrant ... the return of tyranny if Trump is elected in 2020 #TrumpIsNotABillionaire\\n #TrumpIsBroke\\n #TrumpTaxes https://t.co/tgDv3OzWWj', 'Wear a mask. The situation is bad. Do not listen to this dumb president #COVID__19\\n #coronavirus https://t.co/pwFAWCMy78', 'Think #DemocracyDay https://t.co/xwpL1RWvSx', 'From reality to lies from earth to sky ..... You are not American #ARMY  #trump #COVID„Éº19  #CoronaWarnApp  #BlackLivesMatter https://t.co/xqFPsiBE7g', 'Thanks  Obama. #DemocracyDay https://t.co/LrRdUgtWyv', 'https://t.co/XmlC8RJCKZ', 'https://t.co/JDbVJ8WGRD', 'Destruction https://t.co/oJFMnFDYO5', 'Why do you blame your shortcomings and your government on the states and condemn them? Trump .... Enough lies #Trump #Biden https://t.co/14wzsyfLtw', 'It just goes over his head whether he has the right to do so or not #DemocratsAreDestroyingAmerica\\n #BlackLivesMatter  #Seattle  #seattleprotests https://t.co/IxVmKrNPBK', 'Why are you lying so much about Trump that the vaccine was not produced in the end of betraying the Americans? #TrumpTownHall https://t.co/t1BeGBPtRa', 'https://t.co/RnIzFTK67y', 'A world proud of the future just for voting correctly #COVID19  #Trump https://t.co/4lJC0a2uXJ', 'https://t.co/JwwkPrT92u', 'https://t.co/eHgMb7kfRP', '‚ù§‚ù§‚ù§‚ù§The Miami Heat team reached the finals. The 6-year high ...... was ‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§‚ù§great', 'https://t.co/iunIsU9mAN', 'Corona ....... means an excuse for dismissal. Please see the problems of the economy #COVID„Éº19  #CoronaWarnApp https://t.co/Aj8VnDGslD', 'https://t.co/Qh74C0z9Ty', 'The CDC director says young people are expanding the corona #coronavirus  #Covid_19 https://t.co/a8ikKsIVBs', 'Racism in a country beyond the claims of humanity ..... is ridiculous #ThursdayThoughts\\n #BlackLivesMatter https://t.co/pTRUz1Xjxk', 'RT @annarmpeters: Deutschland ist, wenn nur 3 Polizist*innen Nazis davon abhalten, den Bundestag zu st√ºrmen, aber Einheiten mit Hunden, Pfe‚Ä¶', 'RT @Shawwwwwn1: No ‚ù§trump......2020 No üíöNoüíú #TrumpCrimeFamily https://t.co/uLQ1kF1h8s', '@cnnbrk Yes.....This is awful', 'RT @Baligubadle1: @ProjectLincoln @pjlacasse22 Joe Biden should also have stoped the asteroid from wiping out the dinosaurs', 'RT @SenKamalaHarris: ‚ÄúMy most fervent wish is that I will not be replaced until a new president is installed.‚Äù ‚Äì Justice Ruth Bader Ginsbur‚Ä¶', 'RT @schland2014: @Rachet090604 @lonepalm99 @daveinla @Jim622 @JoeBiden The difference is how Trump handled the virus. He is a monster. #Tru‚Ä¶', 'RT @ThomasVanBarnes: All Trump Supporters believe Bidens truths as lies. But Believe Trumps lies as truths..How ironic. I mean most of the‚Ä¶', 'RT @JasonOverstreet: Sick! \\n\\nOne of the most disturbing things about Trump is how he has embraced and attempted to normalize so many distur‚Ä¶', 'RT @ThomasVanBarnes: So Trump supporters are saying \"Go see a therapist\" should we tell them to \"Go see a scientist\"??', '@ThomasVanBarnes Yes‚ù§']\n"
     ]
    }
   ],
   "source": [
    "print(iter_of_lists.iloc[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-266-46ed5e84de72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_of_lists\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "all_tokens(iter_of_lists['tweet_text'])[.head()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(preprocess_tweet(all_tokens(iter_of_lists)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency(iterable_of_lists):\n",
    "    \"\"\"\n",
    "    \n",
    "    Args:\n",
    "        iterable_of_lists: e.g. a dataframe or list of lists [of strings]\n",
    "    Return:\n",
    "        dict of {'word':'frequency'} sorted by frequency (high to low)\n",
    "    N.B.:\n",
    "        list(itertools.chain(*iterable_of_lists_of_strings))\n",
    "        # vs\n",
    "        list(*itertools.chain.from_iterable(iterable_of_lists_of_strings))\n",
    "    \"\"\"\n",
    "    \n",
    "    all_words = list(*itertools.chain.from_iterable(iterable_of_lists))\n",
    "    word_dict = dict()\n",
    "\n",
    "    for word in all_words:\n",
    "        if word in word_dict:\n",
    "            word_dict[word] += 1\n",
    "        else:\n",
    "            word_dict[word] = 1\n",
    "\n",
    "    # counts = collections.Counter(iterable_of_lists_of_strings)\n",
    "    \n",
    "    return sorted(word_dict.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokenize_iter() takes 1 positional argument but 209 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-5e1fa21a7dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenized_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenize_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0miter_of_lists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtokenized_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tokenize_iter() takes 1 positional argument but 209 were given"
     ]
    }
   ],
   "source": [
    "tokenized_df = tokenize_iter(iter_of_lists)\n",
    "tokenized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_dict = word_frequency(tokenized_df)\n",
    "freq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing\n",
    "\n",
    "Using sklearn's CountVectorizer to turn the corpus into a text-term matrix allows us to easily count tokens. CountVectorizer can count n-grams as well as tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram_freq_matrix(list_of_strings,\n",
    "                      stop_words=None,\n",
    "                      ngram_range=(1,2)):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "       list_of_strings: iterable of strings\n",
    "       stop_words: a list of stop words or the string 'english' to use a\n",
    "                   built-in English language stop word list.\n",
    "                   Default: no stop words\n",
    "       ngram_range: a single int, or a 2 tuple representing the range of ngrams to count.\n",
    "                    Default: (1,2); counts 1- and 2- grams.\n",
    "    Return:\n",
    "       dataframe of counts indexed by n-gram\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer(analyzer='word',\n",
    "                                 tokenizer=tweet_tokenizer,\n",
    "                                 stop_words=stop_words,\n",
    "                                 ngram_range=ngram_range\n",
    "                                )\n",
    "    \n",
    "    ngram_freq_matrix = count_vectorizer.fit_transform(list_of_strings)\n",
    "    ngrams = count_vectorizer.get_feature_names()\n",
    "\n",
    "    return ngram_freq_matrix, ngrams\n",
    "\n",
    "def count_freq_matrix(ngram_freq_matrix):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ngram_frequencies = term_freq_matrix.sum(axis=0).tolist()[0]\n",
    "    freq_dict = dict(zip(terms, term_frequencies))\n",
    "    \n",
    "    return (pd.DataFrame(freq_dict, \n",
    "                         index_column='ngram'\n",
    "                         columns=['ngram', 'count'])\n",
    "                        .sort_values(\"count\", ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = all_text(all_tokens(list_df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = preprocess_tweet(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = (TweetTokenizer(preserve_case=False, \n",
    "                            reduce_len=True, \n",
    "                            strip_handles=False)\n",
    "              .tokenize(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged = nltk.pos_tag(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = tokenize_df(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['america',\n",
       " 'and',\n",
       " 'the',\n",
       " 'way',\n",
       " 'its',\n",
       " 'government',\n",
       " 'treats',\n",
       " 'its',\n",
       " 'people',\n",
       " 'must',\n",
       " 'be',\n",
       " 'reformed',\n",
       " 'https://t.co/DupN3cE2dd',\n",
       " 'https://t.co/ee5KZJMm5R',\n",
       " 'portland',\n",
       " 'police',\n",
       " 'bureau',\n",
       " 'is',\n",
       " 'preparing',\n",
       " 'for',\n",
       " 'a',\n",
       " 'variety',\n",
       " 'of',\n",
       " 'mass',\n",
       " 'gathering',\n",
       " 'events',\n",
       " 'being',\n",
       " 'planned',\n",
       " 'for',\n",
       " 'saturday',\n",
       " 'september',\n",
       " '26',\n",
       " '2020',\n",
       " 'at',\n",
       " 'this',\n",
       " 'time',\n",
       " 'one',\n",
       " 'group',\n",
       " 'has',\n",
       " 'been',\n",
       " 'announced',\n",
       " 'they',\n",
       " 'will',\n",
       " 'hold',\n",
       " 'an',\n",
       " 'event',\n",
       " 'at',\n",
       " 'delta',\n",
       " 'park',\n",
       " 'at',\n",
       " 'noon',\n",
       " '#policelivesmatter',\n",
       " '#polizeigewalt',\n",
       " '#portland',\n",
       " '#portlandprotests',\n",
       " 'https://t.co/3JSoa0UcOL',\n",
       " 'why',\n",
       " 'lies',\n",
       " '...',\n",
       " 'why',\n",
       " 'hypocrisy',\n",
       " '...',\n",
       " 'why',\n",
       " 'security',\n",
       " 'forces',\n",
       " '...',\n",
       " 'why',\n",
       " 'racism',\n",
       " '...',\n",
       " 'why',\n",
       " 'cut',\n",
       " 'budgets',\n",
       " '...',\n",
       " 'to',\n",
       " 'deceive',\n",
       " 'people',\n",
       " 'no',\n",
       " 'trump',\n",
       " 'no',\n",
       " 'no',\n",
       " 'no',\n",
       " '#army',\n",
       " '#covid„Éº19',\n",
       " '#biden',\n",
       " '#trump',\n",
       " 'https://t.co/v1WYXyidzJ',\n",
       " 'difference',\n",
       " '#biden',\n",
       " 'https://t.co/Vl5lB7q2l6',\n",
       " 'he',\n",
       " 'has',\n",
       " 'destroyed',\n",
       " 'every',\n",
       " 'busines',\n",
       " '...',\n",
       " 'üêÇ',\n",
       " 'üêÉ',\n",
       " 'üêÉ',\n",
       " 'üêÉ',\n",
       " '#trumpmeltdown',\n",
       " 'https://t.co/tKrPEdujCZ',\n",
       " 'even',\n",
       " 'if',\n",
       " 'the',\n",
       " 'power',\n",
       " 'to',\n",
       " 'negotiate',\n",
       " 'deals',\n",
       " 'is',\n",
       " 'handed',\n",
       " 'over',\n",
       " 'to',\n",
       " 'the',\n",
       " 'presidency',\n",
       " 'congress',\n",
       " 'will',\n",
       " 'still',\n",
       " 'have',\n",
       " 'the',\n",
       " 'final',\n",
       " 'say',\n",
       " 'and',\n",
       " 'judging',\n",
       " 'by',\n",
       " 'the',\n",
       " 'current',\n",
       " 'political',\n",
       " 'climate',\n",
       " 'johnson',\n",
       " 'will',\n",
       " 'not',\n",
       " 'fire',\n",
       " 'him',\n",
       " 'this',\n",
       " 'time',\n",
       " '#trump',\n",
       " '#covid_19',\n",
       " '#democracyday',\n",
       " 'https://t.co/25ovVSWAFJ',\n",
       " 'trump',\n",
       " '...',\n",
       " 'trump',\n",
       " '..',\n",
       " 'trump',\n",
       " '#trump',\n",
       " 'https://t.co/vHAZyS0LeZ',\n",
       " '#blacklivesstillmatter',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/XQT3V5vGHZ',\n",
       " 'yes',\n",
       " 'biden',\n",
       " '...',\n",
       " 'not',\n",
       " 'trump',\n",
       " '#bidenharrislandslide2020',\n",
       " 'https://t.co/TPYT11Zb4U',\n",
       " '...',\n",
       " 'and',\n",
       " '...',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " '#thursdaythoughts',\n",
       " 'https://t.co/WHWxf5D44L',\n",
       " 'democratic',\n",
       " 'presidential',\n",
       " 'nominee',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'had',\n",
       " 'also',\n",
       " 'warned',\n",
       " 'johnson',\n",
       " 'that',\n",
       " 'either',\n",
       " 'he',\n",
       " 'will',\n",
       " 'respect',\n",
       " 'northern',\n",
       " 'ireland',\n",
       " '‚Äô',\n",
       " 's',\n",
       " 'peace',\n",
       " 'agreement',\n",
       " 'or',\n",
       " 'else',\n",
       " 'he',\n",
       " 'will',\n",
       " 'get',\n",
       " 'no',\n",
       " 'u',\n",
       " 's',\n",
       " 'trade',\n",
       " 'deal',\n",
       " '#happychenday',\n",
       " '#trump',\n",
       " '#covid19',\n",
       " 'why',\n",
       " 'should',\n",
       " 'racism',\n",
       " 'exist',\n",
       " 'in',\n",
       " 'america',\n",
       " 'for',\n",
       " 'example',\n",
       " 'we',\n",
       " 'are',\n",
       " 'the',\n",
       " 'first',\n",
       " 'country',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '#trump',\n",
       " 'https://t.co/spSLY2UY47',\n",
       " 'who',\n",
       " 'is',\n",
       " 'the',\n",
       " 'idiot',\n",
       " '...',\n",
       " 'the',\n",
       " 'one',\n",
       " 'who',\n",
       " 'extended',\n",
       " 'the',\n",
       " 'corona',\n",
       " '...',\n",
       " 'who',\n",
       " 'is',\n",
       " 'trump',\n",
       " 'according',\n",
       " 'to',\n",
       " 'pelosi',\n",
       " 'corona',\n",
       " 'herself',\n",
       " '#covid„Éº19',\n",
       " 'https://t.co/Y5TRDpoZ6M',\n",
       " 'https://t.co/SRByuzX5jC',\n",
       " 'https://t.co/JVX1MaOxQG',\n",
       " 'our',\n",
       " 'president',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '...',\n",
       " 'he',\n",
       " 'is',\n",
       " 'accused',\n",
       " 'of',\n",
       " 'raping',\n",
       " 'a',\n",
       " '13',\n",
       " 'year-old',\n",
       " 'girl',\n",
       " '...',\n",
       " '#trump',\n",
       " '#trumpisapedo',\n",
       " 'https://t.co/BD3FsyXITS',\n",
       " 'this',\n",
       " 'photo',\n",
       " 'of',\n",
       " 'racism',\n",
       " 'is',\n",
       " 'complete',\n",
       " '...',\n",
       " 'does',\n",
       " 'not',\n",
       " 'want',\n",
       " 'to',\n",
       " 'be',\n",
       " 'explained',\n",
       " '#racism',\n",
       " '#army',\n",
       " '#democrats',\n",
       " '#democracyday',\n",
       " 'https://t.co/77OHHpy9qe',\n",
       " 'are',\n",
       " 'democrats',\n",
       " 'angry',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'lying',\n",
       " 'about',\n",
       " 'vaccines',\n",
       " 'no',\n",
       " '...',\n",
       " 'no',\n",
       " '...',\n",
       " 'no',\n",
       " '#trump2020',\n",
       " '#covid__19',\n",
       " '#coronavirus',\n",
       " '#biden',\n",
       " 'the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'heaven',\n",
       " 'https://t.co/Q1YJF6DZAA',\n",
       " 'https://t.co/gUd7uePIca',\n",
       " '32',\n",
       " 'reduction',\n",
       " 'in',\n",
       " 'brazilian',\n",
       " 'exports',\n",
       " 'to',\n",
       " 'the',\n",
       " 'united',\n",
       " 'states',\n",
       " '...',\n",
       " 'although',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'is',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'its',\n",
       " 'relations',\n",
       " 'with',\n",
       " 'brazil',\n",
       " 'in',\n",
       " 'practice',\n",
       " 'it',\n",
       " 'is',\n",
       " 'something',\n",
       " 'else',\n",
       " '#trump',\n",
       " '#biden',\n",
       " '#trumpknew',\n",
       " '#trumpkillsamericans',\n",
       " 'https://t.co/mseaeJDB7O',\n",
       " 'in',\n",
       " 'america',\n",
       " 'the',\n",
       " 'law',\n",
       " 'goes',\n",
       " 'hand',\n",
       " 'in',\n",
       " 'hand',\n",
       " 'with',\n",
       " 'the',\n",
       " 'police',\n",
       " '#seattleprotests',\n",
       " 'https://t.co/n1FCwoCON8',\n",
       " '850',\n",
       " 'people',\n",
       " 'die',\n",
       " 'every',\n",
       " 'day',\n",
       " 'and',\n",
       " 'trump',\n",
       " 'tells',\n",
       " 'new',\n",
       " 'lies',\n",
       " 'every',\n",
       " 'day',\n",
       " '#coronavirus',\n",
       " '#covid__19',\n",
       " '#covid_19',\n",
       " 'https://t.co/5CT3Q5AzE8',\n",
       " 'health',\n",
       " 'wants',\n",
       " 'a',\n",
       " 'long-term',\n",
       " 'plan',\n",
       " '...',\n",
       " 'not',\n",
       " 'like',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'administration',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'ago',\n",
       " 'did',\n",
       " 'not',\n",
       " 'believe',\n",
       " 'in',\n",
       " 'masks',\n",
       " 'after',\n",
       " 'a',\n",
       " 'few',\n",
       " 'months',\n",
       " 'again',\n",
       " 'when',\n",
       " 'coronary',\n",
       " 'heart',\n",
       " 'disease',\n",
       " 'spread',\n",
       " '...',\n",
       " '#health',\n",
       " '#coronavirus',\n",
       " '#covid19',\n",
       " 'https://t.co/bU2vJxKs67',\n",
       " 'what',\n",
       " 'are',\n",
       " 'your',\n",
       " 'plans',\n",
       " 'for',\n",
       " 'choosing',\n",
       " 'trump',\n",
       " 'as',\n",
       " 'the',\n",
       " 'successor',\n",
       " 'to',\n",
       " 'the',\n",
       " 'late',\n",
       " 'lady',\n",
       " 'of',\n",
       " 'american',\n",
       " 'justice',\n",
       " '#trump',\n",
       " 'corona',\n",
       " 'is',\n",
       " 'for',\n",
       " 'all',\n",
       " 'ages',\n",
       " '...',\n",
       " 'mask',\n",
       " 'is',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'corona',\n",
       " '...',\n",
       " 'corona',\n",
       " 'does',\n",
       " 'not',\n",
       " 'have',\n",
       " 'any',\n",
       " 'medicine',\n",
       " 'at',\n",
       " 'the',\n",
       " 'moment',\n",
       " '#coronavirus',\n",
       " 'https://t.co/5YrHdx72vI',\n",
       " '#covid_19',\n",
       " '#democracyday',\n",
       " 'https://t.co/UZS4xmbHRs',\n",
       " 'biden',\n",
       " 'and',\n",
       " 'kissing',\n",
       " 'granddaughter',\n",
       " 'magically',\n",
       " '#biden',\n",
       " '#trump',\n",
       " '#trumplandslidevictory2020',\n",
       " '#bidenharris2020',\n",
       " 'https://t.co/QDtqEOJPLU',\n",
       " 'corona',\n",
       " '...',\n",
       " '#coronavirus',\n",
       " 'https://t.co/LcafZ6T7Fz',\n",
       " 'deadly',\n",
       " 'germs',\n",
       " 'alert',\n",
       " 'in',\n",
       " 'texas',\n",
       " 'drinking',\n",
       " 'water',\n",
       " '#covid„Éº19',\n",
       " 'https://t.co/kB9TVzkdgE',\n",
       " '#covid19',\n",
       " 'https://t.co/vcZAdxUnbx',\n",
       " 'https://t.co/Ke59HugLf5',\n",
       " 'look',\n",
       " '...',\n",
       " 'üëá',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " 'üò≠',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/CLpf9940mZ',\n",
       " 'trump',\n",
       " 'and',\n",
       " 'corona',\n",
       " 'are',\n",
       " 'destroying',\n",
       " 'america',\n",
       " 'together',\n",
       " '#trump',\n",
       " '#corona',\n",
       " '#trumppressconference',\n",
       " 'https://t.co/0E1GVkA1ir',\n",
       " 'https://t.co/36dmHri4pG',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/WaF778uKj1',\n",
       " 'https://t.co/5hlUTfhf3g',\n",
       " 'smile',\n",
       " 'https://t.co/nkfBCugmoJ',\n",
       " 'https://t.co/YcK6ypfmeQ',\n",
       " 'no',\n",
       " 'important',\n",
       " '‚ö†',\n",
       " 'more',\n",
       " 'than',\n",
       " '70',\n",
       " 'of',\n",
       " 'americans',\n",
       " 'say',\n",
       " 'the',\n",
       " 'debates',\n",
       " 'won',\n",
       " '‚Äô',\n",
       " 't',\n",
       " 'matter',\n",
       " 'much',\n",
       " 'to',\n",
       " 'them',\n",
       " 'a',\n",
       " 'recent',\n",
       " 'wall',\n",
       " 'street',\n",
       " 'journal',\n",
       " 'nbc',\n",
       " 'news',\n",
       " '#trumpisnotabillionaire',\n",
       " '#trumptaxes',\n",
       " '#biden',\n",
       " '#votehimout2020',\n",
       " 'https://t.co/y3dwMF3EnD',\n",
       " 'my',\n",
       " 'veto',\n",
       " 'protective',\n",
       " 'mask',\n",
       " '#covid19',\n",
       " 'https://t.co/LRxmlOrfN4',\n",
       " '‚ù§',\n",
       " 'üòÇ',\n",
       " '‚ù§',\n",
       " 'üòÇ',\n",
       " '‚ù§',\n",
       " 'https://t.co/piQwxECUhp',\n",
       " 'trump',\n",
       " '...\\n\\n.',\n",
       " 'where',\n",
       " 'is',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'liar',\n",
       " '#covid19',\n",
       " 'https://t.co/30NRZTXtNp',\n",
       " '#trump',\n",
       " 'https://t.co/YXBovhSAxr',\n",
       " 'ginsburg',\n",
       " 'justice',\n",
       " 'a',\n",
       " 'beautiful',\n",
       " 'dream',\n",
       " 'might',\n",
       " 'come',\n",
       " 'true',\n",
       " 'without',\n",
       " 'trump',\n",
       " 'yes',\n",
       " 'without',\n",
       " 'a',\n",
       " 'fool',\n",
       " '#biden',\n",
       " '#trump',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/j1dVIrkTer',\n",
       " 'https://t.co/22wjWV5D1d',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'a',\n",
       " 'tyrant',\n",
       " '...',\n",
       " 'the',\n",
       " 'return',\n",
       " 'of',\n",
       " 'tyranny',\n",
       " 'if',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'elected',\n",
       " 'in',\n",
       " '2020',\n",
       " '#trumpisnotabillionaire',\n",
       " '#trumpisbroke',\n",
       " '#trumptaxes',\n",
       " 'https://t.co/tgDv3OzWWj',\n",
       " 'wear',\n",
       " 'a',\n",
       " 'mask',\n",
       " 'the',\n",
       " 'situation',\n",
       " 'is',\n",
       " 'bad',\n",
       " 'do',\n",
       " 'not',\n",
       " 'listen',\n",
       " 'to',\n",
       " 'this',\n",
       " 'dumb',\n",
       " 'president',\n",
       " '#covid__19',\n",
       " '#coronavirus',\n",
       " 'https://t.co/pwFAWCMy78',\n",
       " 'think',\n",
       " '#democracyday',\n",
       " 'https://t.co/xwpL1RWvSx',\n",
       " 'from',\n",
       " 'reality',\n",
       " 'to',\n",
       " 'lies',\n",
       " 'from',\n",
       " 'earth',\n",
       " 'to',\n",
       " 'sky',\n",
       " '...',\n",
       " 'you',\n",
       " 'are',\n",
       " 'not',\n",
       " 'american',\n",
       " '#army',\n",
       " '#trump',\n",
       " '#covid„Éº19',\n",
       " '#coronawarnapp',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/xqFPsiBE7g',\n",
       " 'thanks',\n",
       " 'obama',\n",
       " '#democracyday',\n",
       " 'https://t.co/LrRdUgtWyv',\n",
       " 'https://t.co/XmlC8RJCKZ',\n",
       " 'https://t.co/JDbVJ8WGRD',\n",
       " 'destruction',\n",
       " 'https://t.co/oJFMnFDYO5',\n",
       " 'why',\n",
       " 'do',\n",
       " 'you',\n",
       " 'blame',\n",
       " 'your',\n",
       " 'shortcomings',\n",
       " 'and',\n",
       " 'your',\n",
       " 'government',\n",
       " 'on',\n",
       " 'the',\n",
       " 'states',\n",
       " 'and',\n",
       " 'condemn',\n",
       " 'them',\n",
       " 'trump',\n",
       " '...',\n",
       " 'enough',\n",
       " 'lies',\n",
       " '#trump',\n",
       " '#biden',\n",
       " 'https://t.co/14wzsyfLtw',\n",
       " 'it',\n",
       " 'just',\n",
       " 'goes',\n",
       " 'over',\n",
       " 'his',\n",
       " 'head',\n",
       " 'whether',\n",
       " 'he',\n",
       " 'has',\n",
       " 'the',\n",
       " 'right',\n",
       " 'to',\n",
       " 'do',\n",
       " 'so',\n",
       " 'or',\n",
       " 'not',\n",
       " '#democratsaredestroyingamerica',\n",
       " '#blacklivesmatter',\n",
       " '#seattle',\n",
       " '#seattleprotests',\n",
       " 'https://t.co/IxVmKrNPBK',\n",
       " 'why',\n",
       " 'are',\n",
       " 'you',\n",
       " 'lying',\n",
       " 'so',\n",
       " 'much',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'that',\n",
       " 'the',\n",
       " 'vaccine',\n",
       " 'was',\n",
       " 'not',\n",
       " 'produced',\n",
       " 'in',\n",
       " 'the',\n",
       " 'end',\n",
       " 'of',\n",
       " 'betraying',\n",
       " 'the',\n",
       " 'americans',\n",
       " '#trumptownhall',\n",
       " 'https://t.co/t1BeGBPtRa',\n",
       " 'https://t.co/RnIzFTK67y',\n",
       " 'a',\n",
       " 'world',\n",
       " 'proud',\n",
       " 'of',\n",
       " 'the',\n",
       " 'future',\n",
       " 'just',\n",
       " 'for',\n",
       " 'voting',\n",
       " 'correctly',\n",
       " '#covid19',\n",
       " '#trump',\n",
       " 'https://t.co/4lJC0a2uXJ',\n",
       " 'https://t.co/JwwkPrT92u',\n",
       " 'https://t.co/eHgMb7kfRP',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " 'the',\n",
       " 'miami',\n",
       " 'heat',\n",
       " 'team',\n",
       " 'reached',\n",
       " 'the',\n",
       " 'finals',\n",
       " 'the',\n",
       " '6',\n",
       " 'year',\n",
       " 'high',\n",
       " '...',\n",
       " 'was',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " '‚ù§',\n",
       " 'great',\n",
       " 'https://t.co/iunIsU9mAN',\n",
       " 'corona',\n",
       " '...',\n",
       " 'means',\n",
       " 'an',\n",
       " 'excuse',\n",
       " 'for',\n",
       " 'dismissal',\n",
       " 'please',\n",
       " 'see',\n",
       " 'the',\n",
       " 'problems',\n",
       " 'of',\n",
       " 'the',\n",
       " 'economy',\n",
       " '#covid„Éº19',\n",
       " '#coronawarnapp',\n",
       " 'https://t.co/Aj8VnDGslD',\n",
       " 'https://t.co/Qh74C0z9Ty',\n",
       " 'the',\n",
       " 'cdc',\n",
       " 'director',\n",
       " 'says',\n",
       " 'young',\n",
       " 'people',\n",
       " 'are',\n",
       " 'expanding',\n",
       " 'the',\n",
       " 'corona',\n",
       " '#coronavirus',\n",
       " '#covid_19',\n",
       " 'https://t.co/a8ikKsIVBs',\n",
       " 'racism',\n",
       " 'in',\n",
       " 'a',\n",
       " 'country',\n",
       " 'beyond',\n",
       " 'the',\n",
       " 'claims',\n",
       " 'of',\n",
       " 'humanity',\n",
       " '...',\n",
       " 'is',\n",
       " 'ridiculous',\n",
       " '#thursdaythoughts',\n",
       " '#blacklivesmatter',\n",
       " 'https://t.co/pTRUz1Xjxk',\n",
       " 'rt',\n",
       " '@annarmpeters',\n",
       " 'deutschland',\n",
       " 'ist',\n",
       " 'wenn',\n",
       " 'nur',\n",
       " '3',\n",
       " 'polizist',\n",
       " 'innen',\n",
       " 'nazis',\n",
       " 'davon',\n",
       " 'abhalten',\n",
       " 'den',\n",
       " 'bundestag',\n",
       " 'zu',\n",
       " 'st√ºrmen',\n",
       " 'aber',\n",
       " 'einheiten',\n",
       " 'mit',\n",
       " 'hunden',\n",
       " 'pfe',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " '@shawwwn1',\n",
       " 'no',\n",
       " '‚ù§',\n",
       " 'trump',\n",
       " '...',\n",
       " '2020',\n",
       " 'no',\n",
       " 'üíö',\n",
       " 'no',\n",
       " 'üíú',\n",
       " '#trumpcrimefamily',\n",
       " 'https://t.co/uLQ1kF1h8s',\n",
       " '@cnnbrk',\n",
       " 'yes',\n",
       " '...',\n",
       " 'this',\n",
       " 'is',\n",
       " 'awful',\n",
       " 'rt',\n",
       " '@baligubadle1',\n",
       " '@projectlincoln',\n",
       " '@pjlacasse22',\n",
       " 'joe',\n",
       " 'biden',\n",
       " 'should',\n",
       " 'also',\n",
       " 'have',\n",
       " 'stoped',\n",
       " 'the',\n",
       " 'asteroid',\n",
       " 'from',\n",
       " 'wiping',\n",
       " 'out',\n",
       " 'the',\n",
       " 'dinosaurs',\n",
       " 'rt',\n",
       " '@senkamalaharris',\n",
       " '‚Äú',\n",
       " 'my',\n",
       " 'most',\n",
       " 'fervent',\n",
       " 'wish',\n",
       " 'is',\n",
       " 'that',\n",
       " 'i',\n",
       " 'will',\n",
       " 'not',\n",
       " 'be',\n",
       " 'replaced',\n",
       " 'until',\n",
       " 'a',\n",
       " 'new',\n",
       " 'president',\n",
       " 'is',\n",
       " 'installed',\n",
       " '‚Äù',\n",
       " '‚Äì',\n",
       " 'justice',\n",
       " 'ruth',\n",
       " 'bader',\n",
       " 'ginsbur',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " '@schland2014',\n",
       " '@rachet090604',\n",
       " '@lonepalm99',\n",
       " '@daveinla',\n",
       " '@jim622',\n",
       " '@joebiden',\n",
       " 'the',\n",
       " 'difference',\n",
       " 'is',\n",
       " 'how',\n",
       " 'trump',\n",
       " 'handled',\n",
       " 'the',\n",
       " 'virus',\n",
       " 'he',\n",
       " 'is',\n",
       " 'a',\n",
       " 'monster',\n",
       " '#tru',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " '@thomasvanbarnes',\n",
       " 'all',\n",
       " 'trump',\n",
       " 'supporters',\n",
       " 'believe',\n",
       " 'bidens',\n",
       " 'truths',\n",
       " 'as',\n",
       " 'lies',\n",
       " 'but',\n",
       " 'believe',\n",
       " 'trumps',\n",
       " 'lies',\n",
       " 'as',\n",
       " 'truths',\n",
       " '..',\n",
       " 'how',\n",
       " 'ironic',\n",
       " 'i',\n",
       " 'mean',\n",
       " 'most',\n",
       " 'of',\n",
       " 'the',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " '@jasonoverstreet',\n",
       " 'sick',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'most',\n",
       " 'disturbing',\n",
       " 'things',\n",
       " 'about',\n",
       " 'trump',\n",
       " 'is',\n",
       " 'how',\n",
       " 'he',\n",
       " 'has',\n",
       " 'embraced',\n",
       " 'and',\n",
       " 'attempted',\n",
       " 'to',\n",
       " 'normalize',\n",
       " 'so',\n",
       " 'many',\n",
       " 'distur',\n",
       " '‚Ä¶',\n",
       " 'rt',\n",
       " '@thomasvanbarnes',\n",
       " 'so',\n",
       " 'trump',\n",
       " 'supporters',\n",
       " 'are',\n",
       " 'saying',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'therapist',\n",
       " 'should',\n",
       " 'we',\n",
       " 'tell',\n",
       " 'them',\n",
       " 'to',\n",
       " 'go',\n",
       " 'see',\n",
       " 'a',\n",
       " 'scientist',\n",
       " '@thomasvanbarnes',\n",
       " 'yes',\n",
       " '‚ù§',\n",
       " '@manotonews',\n",
       " 'ÿß⁄ØŸá',\n",
       " 'ÿß€åÿ±ÿßŸÜ',\n",
       " 'ÿ®Ÿá',\n",
       " '€åŸÖŸÜ',\n",
       " 'Ÿà',\n",
       " 'ŸÖŸÇÿßŸàŸÖÿ™',\n",
       " '⁄©ŸÖ⁄©',\n",
       " 'ŸÜ⁄©ŸÜŸá',\n",
       " 'ÿÆÿß⁄©',\n",
       " 'ÿ™Ÿà',\n",
       " 'ÿ≥ÿ±ÿ¥',\n",
       " 'ŸÑÿ∑ŸÅÿß',\n",
       " '⁄©ÿ≥ÿßŸÜ€å',\n",
       " '⁄©Ÿá',\n",
       " 'Ÿàÿßÿ≥Ÿá',\n",
       " 'ÿß€åÿ±ÿßŸÜ',\n",
       " 'Ÿà',\n",
       " 'ŸÖÿ±ÿØŸÖ',\n",
       " 'ÿ≥€åŸÑ',\n",
       " 'ÿ≤ÿØŸá',\n",
       " '⁄©ŸÖ⁄©',\n",
       " 'ŸÜ⁄©ÿ±ÿØŸÜÿØ',\n",
       " 'ŸÜÿ∏ÿ±',\n",
       " 'ŸÜÿØŸÜ',\n",
       " 'üîò',\n",
       " 'ŸæŸáÿ®ÿßÿØ',\n",
       " 'ÿ≥Ÿá',\n",
       " 'ÿ™ÿß',\n",
       " '€±€∞€∞€∞',\n",
       " '€åŸàÿ±Ÿà',\n",
       " 'üîò',\n",
       " 'ŸÖŸàÿ¥⁄©',\n",
       " 'ÿ≥Ÿàÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿ¨ÿØÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿ®ÿ®ÿ±',\n",
       " 'ÿØÿπÿß',\n",
       " '⁄©ŸÜ',\n",
       " 'ÿØŸàŸÜŸá',\n",
       " 'ÿß€å',\n",
       " '€±€∞€∞€∞',\n",
       " '€åŸàÿ±Ÿà',\n",
       " 'üîò',\n",
       " ...]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('america', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('its', 'PRP$'),\n",
       " ('government', 'NN'),\n",
       " ('treats', 'VBZ'),\n",
       " ('its', 'PRP$'),\n",
       " ('people', 'NNS'),\n",
       " ('must', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('reformed', 'VBN'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('poland', 'NN'),\n",
       " ('police', 'NN'),\n",
       " ('bureau', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('preparing', 'VBG'),\n",
       " ('for', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('variety', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('mass', 'NN'),\n",
       " ('gathering', 'NN'),\n",
       " ('events', 'NNS'),\n",
       " ('being', 'VBG'),\n",
       " ('planned', 'VBN'),\n",
       " ('for', 'IN'),\n",
       " ('saturday', 'JJ'),\n",
       " ('september', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('one', 'CD'),\n",
       " ('group', 'NN'),\n",
       " ('has', 'VBZ'),\n",
       " ('been', 'VBN'),\n",
       " ('announced', 'VBN'),\n",
       " ('they', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('hold', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('event', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('delta', 'NN'),\n",
       " ('park', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('noon', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('lies', 'VBZ'),\n",
       " ('why', 'WRB'),\n",
       " ('hypocrisy', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('security', 'NN'),\n",
       " ('forces', 'NNS'),\n",
       " ('why', 'WRB'),\n",
       " ('racism', 'NN'),\n",
       " ('why', 'WRB'),\n",
       " ('cut', 'NN'),\n",
       " ('budgets', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('deceive', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('no', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('no', 'RB'),\n",
       " ('no', 'DT'),\n",
       " ('no', 'DT'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('difference', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('destroyed', 'VBN'),\n",
       " ('every', 'DT'),\n",
       " ('busines', 'NNS'),\n",
       " ('üêÇ', 'VBP'),\n",
       " ('üêÉ', 'JJ'),\n",
       " ('üêÉ', 'NNP'),\n",
       " ('üêÉ', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('even', 'RB'),\n",
       " ('if', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('power', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('negotiate', 'JJ'),\n",
       " ('deals', 'NNS'),\n",
       " ('is', 'VBZ'),\n",
       " ('handed', 'VBN'),\n",
       " ('over', 'IN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('presidency', 'NN'),\n",
       " ('congress', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('still', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('final', 'JJ'),\n",
       " ('say', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('judging', 'NN'),\n",
       " ('by', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('current', 'JJ'),\n",
       " ('political', 'JJ'),\n",
       " ('climate', 'NN'),\n",
       " ('johnson', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('fire', 'VB'),\n",
       " ('him', 'PRP'),\n",
       " ('this', 'DT'),\n",
       " ('time', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('trump', 'NN'),\n",
       " ('trump', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('biden', 'IN'),\n",
       " ('not', 'RB'),\n",
       " ('trump', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NNP'),\n",
       " ('democratic', 'JJ'),\n",
       " ('presidential', 'JJ'),\n",
       " ('nominee', 'NN'),\n",
       " ('joe', 'NN'),\n",
       " ('biden', 'NN'),\n",
       " ('had', 'VBD'),\n",
       " ('also', 'RB'),\n",
       " ('warned', 'VBN'),\n",
       " ('johnson', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('either', 'CC'),\n",
       " ('he', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('respect', 'VB'),\n",
       " ('nohern', 'JJ'),\n",
       " ('ireland', 'NN'),\n",
       " ('‚Äô', 'NNP'),\n",
       " ('s', 'VBD'),\n",
       " ('peace', 'NN'),\n",
       " ('agreement', 'NN'),\n",
       " ('or', 'CC'),\n",
       " ('else', 'RB'),\n",
       " ('he', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('get', 'VB'),\n",
       " ('no', 'DT'),\n",
       " ('us', 'PRP'),\n",
       " ('trade', 'VB'),\n",
       " ('deal', 'VB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('should', 'MD'),\n",
       " ('racism', 'VB'),\n",
       " ('exist', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('america', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('example', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('first', 'JJ'),\n",
       " ('country', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('idiot', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('one', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('extended', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('corona', 'NN'),\n",
       " ('who', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('trump', 'JJ'),\n",
       " ('according', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('pelosi', 'VB'),\n",
       " ('corona', 'VB'),\n",
       " ('herself', 'PRP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('our', 'PRP$'),\n",
       " ('president', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('ridiculous', 'JJ'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('accused', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('raping', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('-', ':'),\n",
       " ('year-old', 'JJ'),\n",
       " ('girl', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('this', 'DT'),\n",
       " ('photo', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('racism', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('complete', 'JJ'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('want', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('explained', 'VBN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('democrats', 'VBN'),\n",
       " ('angry', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('lying', 'VBG'),\n",
       " ('about', 'IN'),\n",
       " ('vaccines', 'NNS'),\n",
       " ('nono', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('heaven', 'VB'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('reduction', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('brazilian', 'JJ'),\n",
       " ('expos', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('united', 'JJ'),\n",
       " ('states', 'NNS'),\n",
       " ('although', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('trump', 'JJ'),\n",
       " ('administration', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('proud', 'JJ'),\n",
       " ('of', 'IN'),\n",
       " ('its', 'PRP$'),\n",
       " ('relations', 'NNS'),\n",
       " ('with', 'IN'),\n",
       " ('brazil', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('practice', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('something', 'NN'),\n",
       " ('else', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('america', 'CC'),\n",
       " ('the', 'DT'),\n",
       " ('law', 'NN'),\n",
       " ('goes', 'VBZ'),\n",
       " ('hand', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('hand', 'NN'),\n",
       " ('with', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('police', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('die', 'VBP'),\n",
       " ('every', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('trump', 'NN'),\n",
       " ('tells', 'NNS'),\n",
       " ('new', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('every', 'DT'),\n",
       " ('day', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('health', 'NN'),\n",
       " ('wants', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('long-term', 'JJ'),\n",
       " ('plan', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('administration', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('ago', 'RB'),\n",
       " ('did', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('believe', 'VB'),\n",
       " ('in', 'IN'),\n",
       " ('masks', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('few', 'JJ'),\n",
       " ('months', 'NNS'),\n",
       " ('again', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('coronary', 'JJ'),\n",
       " ('hea', 'NN'),\n",
       " ('disease', 'NN'),\n",
       " ('spread', 'VBD'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('what', 'WP'),\n",
       " ('are', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('plans', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('choosing', 'VBG'),\n",
       " ('trump', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('successor', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('late', 'JJ'),\n",
       " ('lady', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('american', 'JJ'),\n",
       " ('justice', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('ages', 'NNS'),\n",
       " ('mask', 'VBP'),\n",
       " ('is', 'VBZ'),\n",
       " ('suitable', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('corona', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('does', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('any', 'DT'),\n",
       " ('medicine', 'NN'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('moment', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('biden', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('kissing', 'VBG'),\n",
       " ('granddaughter', 'NN'),\n",
       " ('magically', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('corona', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('deadly', 'RB'),\n",
       " ('germs', 'NNS'),\n",
       " ('ale', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('texas', 'NN'),\n",
       " ('drinking', 'NN'),\n",
       " ('water', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('look', 'NN'),\n",
       " ('üëá', 'NNP'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('üò≠', 'NNP'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('corona', 'NN'),\n",
       " ('are', 'VBP'),\n",
       " ('destroying', 'VBG'),\n",
       " ('america', 'IN'),\n",
       " ('together', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('smile', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('impoant', 'JJ'),\n",
       " ('‚ö†', 'VBZ'),\n",
       " ('more', 'JJR'),\n",
       " ('than', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('americans', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('debates', 'NNS'),\n",
       " ('won', 'VBD'),\n",
       " ('‚Äô', 'JJ'),\n",
       " ('t', 'JJ'),\n",
       " ('matter', 'NN'),\n",
       " ('much', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('them', 'PRP'),\n",
       " ('a', 'DT'),\n",
       " ('recent', 'JJ'),\n",
       " ('wall', 'NN'),\n",
       " ('street', 'NN'),\n",
       " ('journalnbc', 'JJ'),\n",
       " ('news', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('veto', 'NN'),\n",
       " ('protective', 'JJ'),\n",
       " ('mask', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('‚ù§', 'NN'),\n",
       " ('üòÇ', 'NNP'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('üòÇ', 'NNP'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('where', 'WRB'),\n",
       " ('is', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('vaccine', 'NN'),\n",
       " ('liar', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('ginsburg', 'NN'),\n",
       " ('justice', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('dream', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('come', 'VB'),\n",
       " ('true', 'JJ'),\n",
       " ('without', 'IN'),\n",
       " ('trump', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('without', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('fool', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('tyrant', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('return', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('tyranny', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('elected', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('wear', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('mask', 'NN'),\n",
       " ('the', 'DT'),\n",
       " ('situation', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('bad', 'JJ'),\n",
       " ('do', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('listen', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('this', 'DT'),\n",
       " ('dumb', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('think', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('reality', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('lies', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('eah', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('sky', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('not', 'RB'),\n",
       " ('american', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('thanks', 'NNS'),\n",
       " ('obama', 'IN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('destruction', 'NN'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('do', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('blame', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('shocomings', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('your', 'PRP$'),\n",
       " ('government', 'NN'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('states', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('condemn', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('trump', 'VB'),\n",
       " ('enough', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('it', 'PRP'),\n",
       " ('just', 'RB'),\n",
       " ('goes', 'VBZ'),\n",
       " ('over', 'RP'),\n",
       " ('his', 'PRP$'),\n",
       " ('head', 'NN'),\n",
       " ('whether', 'IN'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('right', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('do', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('or', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('why', 'WRB'),\n",
       " ('are', 'VBP'),\n",
       " ('you', 'PRP'),\n",
       " ('lying', 'VBG'),\n",
       " ('so', 'RB'),\n",
       " ('much', 'JJ'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('that', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('vaccine', 'NN'),\n",
       " ('was', 'VBD'),\n",
       " ('not', 'RB'),\n",
       " ('produced', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('end', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('betraying', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('americans', 'NNS'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'NN'),\n",
       " ('a', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('proud', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('future', 'NN'),\n",
       " ('just', 'RB'),\n",
       " ('for', 'IN'),\n",
       " ('voting', 'VBG'),\n",
       " ('correctly', 'RB'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('‚ù§', 'NN'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('‚ù§', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('miami', 'NN'),\n",
       " ('heat', 'NN'),\n",
       " ('team', 'NN'),\n",
       " ('reached', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('finals', 'NNS'),\n",
       " ('the', 'DT'),\n",
       " ('-', ':'),\n",
       " ('year', 'NN'),\n",
       " ('high', 'JJ'),\n",
       " ('was', 'VBD'),\n",
       " ('‚ù§', 'JJ'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('great', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('corona', 'NN'),\n",
       " ('means', 'VBZ'),\n",
       " ('an', 'DT'),\n",
       " ('excuse', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('dismissal', 'NN'),\n",
       " ('please', 'NN'),\n",
       " ('see', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('problems', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('economy', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('cdc', 'NNS'),\n",
       " ('director', 'NN'),\n",
       " ('says', 'VBZ'),\n",
       " ('young', 'JJ'),\n",
       " ('people', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('expanding', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('corona', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('racism', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('country', 'NN'),\n",
       " ('beyond', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('claims', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('humanity', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('ridiculous', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('deutschland', 'NN'),\n",
       " ('ist', 'NN'),\n",
       " ('wenn', 'NN'),\n",
       " ('nur', 'JJ'),\n",
       " ('polizistinnen', 'NN'),\n",
       " ('nazis', 'NN'),\n",
       " ('davon', 'VBD'),\n",
       " ('abhalten', 'JJ'),\n",
       " ('den', 'JJ'),\n",
       " ('bundestag', 'NN'),\n",
       " ('zu', 'NN'),\n",
       " ('st√ºrmen', 'NNS'),\n",
       " ('aber', 'VBP'),\n",
       " ('einheiten', 'JJ'),\n",
       " ('mit', 'NN'),\n",
       " ('hunden', 'NN'),\n",
       " ('pfe', 'NN'),\n",
       " ('‚Ä¶', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('‚ù§', 'NNP'),\n",
       " ('trump', 'VBZ'),\n",
       " ('no', 'DT'),\n",
       " ('üíö', 'JJ'),\n",
       " ('no', 'DT'),\n",
       " ('üíú', 'JJ'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('<-url->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('yesthis', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('awful', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('joe', 'NN'),\n",
       " ('biden', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('also', 'RB'),\n",
       " ('have', 'VB'),\n",
       " ('stoped', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('asteroid', 'NN'),\n",
       " ('from', 'IN'),\n",
       " ('wiping', 'VBG'),\n",
       " ('out', 'RP'),\n",
       " ('the', 'DT'),\n",
       " ('dinosaurs', 'NNS'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('‚Äú', 'NNP'),\n",
       " ('my', 'PRP$'),\n",
       " ('most', 'JJS'),\n",
       " ('fervent', 'JJ'),\n",
       " ('wish', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('that', 'IN'),\n",
       " ('i', 'NN'),\n",
       " ('will', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('replaced', 'VBN'),\n",
       " ('until', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('president', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('installed', 'VBN'),\n",
       " ('‚Äù', 'JJ'),\n",
       " ('‚Äì', 'NNP'),\n",
       " ('justice', 'NN'),\n",
       " ('ruth', 'NN'),\n",
       " ('bader', 'NN'),\n",
       " ('ginsbur', 'NN'),\n",
       " ('‚Ä¶', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('the', 'DT'),\n",
       " ('difference', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('trump', 'JJ'),\n",
       " ('handled', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('virus', 'NN'),\n",
       " ('he', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('monster', 'NN'),\n",
       " ('<-#->', 'JJ'),\n",
       " ('‚Ä¶', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('all', 'DT'),\n",
       " ('trump', 'NN'),\n",
       " ('suppoers', 'NNS'),\n",
       " ('believe', 'VBP'),\n",
       " ('bidens', 'VBZ'),\n",
       " ('truths', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('lies', 'NNS'),\n",
       " ('but', 'CC'),\n",
       " ('believe', 'VBP'),\n",
       " ('trumps', 'JJ'),\n",
       " ('lies', 'NNS'),\n",
       " ('as', 'IN'),\n",
       " ('truthshow', 'NN'),\n",
       " ('ironic', 'JJ'),\n",
       " ('i', 'NN'),\n",
       " ('mean', 'VBP'),\n",
       " ('most', 'JJS'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('‚Ä¶', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('sick', 'JJ'),\n",
       " ('one', 'CD'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('most', 'RBS'),\n",
       " ('disturbing', 'JJ'),\n",
       " ('things', 'NNS'),\n",
       " ('about', 'IN'),\n",
       " ('trump', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('how', 'WRB'),\n",
       " ('he', 'PRP'),\n",
       " ('has', 'VBZ'),\n",
       " ('embraced', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('attempted', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('normalize', 'VB'),\n",
       " ('so', 'RB'),\n",
       " ('many', 'JJ'),\n",
       " ('distur', 'JJ'),\n",
       " ('‚Ä¶', 'JJ'),\n",
       " ('<-@->', 'NNS'),\n",
       " ('so', 'RB'),\n",
       " ('trump', 'JJ'),\n",
       " ('suppoers', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('saying', 'VBG'),\n",
       " ('go', 'VB'),\n",
       " ('see', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('therapist', 'NN'),\n",
       " ('should', 'MD'),\n",
       " ('we', 'PRP'),\n",
       " ('tell', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('to', 'TO'),\n",
       " ('go', 'VB'),\n",
       " ('see', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('scientist', 'JJ'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('yes', 'NNS'),\n",
       " ('‚ù§', 'POS'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('ÿß⁄ØŸá', 'NN'),\n",
       " ('ÿß€åÿ±ÿßŸÜ', 'NNP'),\n",
       " ('ÿ®Ÿá', 'NNP'),\n",
       " ('€åŸÖŸÜ', 'NNP'),\n",
       " ('Ÿà', 'NNP'),\n",
       " ('ŸÖŸÇÿßŸàŸÖÿ™', 'NNP'),\n",
       " ('⁄©ŸÖ⁄©', 'NNP'),\n",
       " ('ŸÜ⁄©ŸÜŸá', 'NNP'),\n",
       " ('ÿÆÿß⁄©', 'NNP'),\n",
       " ('ÿ™Ÿà', 'NNP'),\n",
       " ('ÿ≥ÿ±ÿ¥', 'NNP'),\n",
       " ('ŸÑÿ∑ŸÅÿß', 'NNP'),\n",
       " ('⁄©ÿ≥ÿßŸÜ€å', 'NNP'),\n",
       " ('⁄©Ÿá', 'NNP'),\n",
       " ('Ÿàÿßÿ≥Ÿá', 'NNP'),\n",
       " ('ÿß€åÿ±ÿßŸÜ', 'NNP'),\n",
       " ('Ÿà', 'NNP'),\n",
       " ('ŸÖÿ±ÿØŸÖ', 'NNP'),\n",
       " ('ÿ≥€åŸÑ', 'NNP'),\n",
       " ('ÿ≤ÿØŸá', 'NNP'),\n",
       " ('⁄©ŸÖ⁄©', 'NNP'),\n",
       " ('ŸÜ⁄©ÿ±ÿØŸÜÿØ', 'NNP'),\n",
       " ('ŸÜÿ∏ÿ±', 'NNP'),\n",
       " ('ŸÜÿØŸÜ', 'NNP'),\n",
       " ('üîò', 'NNP'),\n",
       " ('ŸæŸáÿ®ÿßÿØ', 'NNP'),\n",
       " ('ÿ≥Ÿá', 'NNP'),\n",
       " ('ÿ™ÿß', 'NNP'),\n",
       " ('€±€∞€∞€∞', 'CD'),\n",
       " ('€åŸàÿ±Ÿà', 'NNP'),\n",
       " ('üîò', 'NNP'),\n",
       " ('ŸÖŸàÿ¥⁄©', 'NNP'),\n",
       " ('ÿ≥Ÿàÿß', 'NNP'),\n",
       " ('⁄©ŸÜ', 'NNP'),\n",
       " ('ÿ¨ÿØÿß', 'NNP'),\n",
       " ('⁄©ŸÜ', 'NNP'),\n",
       " ('ÿ®ÿ®ÿ±', 'NNP'),\n",
       " ('ÿØÿπÿß', 'NNP'),\n",
       " ('⁄©ŸÜ', 'NNP'),\n",
       " ('ÿØŸàŸÜŸá', 'NNP'),\n",
       " ('ÿß€å', 'NNP'),\n",
       " ('€±€∞€∞€∞', 'CD'),\n",
       " ('€åŸàÿ±Ÿà', 'NNP'),\n",
       " ('üîò', 'NNP'),\n",
       " ('ŸÜÿßŸà', 'NNP'),\n",
       " ('ÿ∫ŸÜ€åŸÖÿ™€å', 'NNP'),\n",
       " ('ÿ®ÿß', 'NNP'),\n",
       " ('ÿÆÿØŸÖŸá', 'NNP'),\n",
       " ('ÿ¢ŸÖÿ±€å⁄©ÿß€å€å', 'NNP'),\n",
       " ('ÿ±ÿß€å⁄ØÿßŸÜ', 'NNP'),\n",
       " ('üîò', 'NNP'),\n",
       " ('ŸÜÿßŸà', 'NNP'),\n",
       " ('ÿ®ÿØŸàŸÜ', 'NNP'),\n",
       " ('ÿÆÿØŸÖŸá', 'NNP'),\n",
       " ('ŸÇÿ≥ÿ∑€å', 'NNP'),\n",
       " ('ŸÖÿßŸá€å', 'NNP'),\n",
       " ('€±€∞€∞€∞', 'CD'),\n",
       " ('€åŸàÿ±Ÿà', 'NNP'),\n",
       " ('ÿ®ÿØŸà', 'NNP'),\n",
       " ('ÿß€åŸÜŸàÿ±', 'NNP'),\n",
       " ('ÿ®ÿßÿ≤ÿßÿ±', 'NNP'),\n",
       " ('<-@->', 'JJ'),\n",
       " ('ÿ®ÿπÿ∂€å', 'NNP'),\n",
       " ('⁄©Ÿá', 'NNP'),\n",
       " ('ŸÖ€åÿ±ŸÜ', 'NNP'),\n",
       " ('ÿÆÿßÿ±ÿ¨', 'NNP'),\n",
       " ('⁄©Ÿá', 'NNP'),\n",
       " ('ŸÖÿ´ŸÑÿß', 'NNP'),\n",
       " ('ÿ¢ÿ≤ÿßÿØ', 'NNP'),\n",
       " ('ÿ®ÿßÿ¥ŸÜ', 'NNP'),\n",
       " ('ÿå', 'NNP'),\n",
       " ('⁄ÜŸÜÿßŸÜ', 'NNP'),\n",
       " ('ÿØÿ±⁄Ø€åÿ±', 'NNP'),\n",
       " ('ŸÇŸàÿßŸÜ€åŸÜ', 'NNP'),\n",
       " ('ÿßÿ¨ÿ®ÿßÿ±€å', 'NNP'),\n",
       " ('Ÿà', 'NNP'),\n",
       " ('ÿÆÿ¥⁄©', 'NNP'),\n",
       " ('ÿØÿ±', 'NNP'),\n",
       " ('ÿ∫ÿ±ÿ®ÿ™', 'NNP'),\n",
       " ('ŸÖ€åÿ¥ŸÜ', 'NNP'),\n",
       " ('⁄©Ÿá', 'NNP'),\n",
       " ('ÿ¢ÿ≤ÿßÿØ€å€å', 'NNP'),\n",
       " ('⁄©Ÿá', 'NNP'),\n",
       " ('ÿ™Ÿà', 'NNP'),\n",
       " ('ÿß€åÿ±ÿßŸÜ', 'NNP'),\n",
       " ('ÿØÿßÿ¥ÿ™ŸÜ', 'NNP'),\n",
       " ('ÿ®ÿ±ÿßÿ¥ŸàŸÜ', 'NNP'),\n",
       " ('ÿ≠ÿ≥ÿ±ÿ™', 'NNP'),\n",
       " ('Ÿà', 'NNP'),\n",
       " ('ÿ±Ÿà€åÿß', 'NNP'),\n",
       " ('ŸÖ€åÿ¥Ÿá', 'NNP'),\n",
       " ('ÿß€åŸÜÿ¨ÿß', 'NNP'),\n",
       " ('ŸÇÿßŸÜŸàŸÜ', 'NNP'),\n",
       " ('ÿØÿßÿ±Ÿá', 'NNP'),\n",
       " ('Ÿà', 'NNP'),\n",
       " ('Ÿáÿ±⁄ÜŸÜÿØ', 'NNP'),\n",
       " ('ÿßÿ¥ÿ™ÿ®ÿßŸá', 'NNP'),\n",
       " ('ÿå', 'NNP'),\n",
       " ('ÿ®ÿß€åÿØ', 'NNP'),\n",
       " ('ÿ±ÿπÿß€åÿ™', 'NNP'),\n",
       " ('⁄©ÿ±ÿØ', 'NNP'),\n",
       " ...]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_speech = dict(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-208-29e3ab001cac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         ).astype({'count':'int64',\n\u001b[1;32m     12\u001b[0m                                   'part_of_speech':'category'})\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_of_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-208-29e3ab001cac>\u001b[0m in \u001b[0;36mpart_of_speech\u001b[0;34m(iterable_of_lists)\u001b[0m\n\u001b[1;32m     10\u001b[0m                         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'part_of_speech'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                         ).astype({'count':'int64',\n\u001b[0;32m---> 12\u001b[0;31m                                   'part_of_speech':'category'})\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpart_of_speech\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5682\u001b[0m                     results.append(\n\u001b[0;32m-> 5683\u001b[0;31m                         \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5684\u001b[0m                     )\n\u001b[1;32m   5685\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5696\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5697\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5698\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5699\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, filter, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "def part_of_speech(iterable_of_lists):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    all_words = tokenize_list(iterable_of_lists)\n",
    "    tokens = remove_stopwords(all_words)\n",
    "    tagged = nltk.pos_tag(tokens)\n",
    "    part_of_speech = dict(tagged)\n",
    "    \n",
    "    return pd.DataFrame(part_of_speech, \n",
    "                        index=part_of_speech.keys(),\n",
    "                        columns=['count','part_of_speech']\n",
    "                        ).astype({'count':'int64',\n",
    "                                  'part_of_speech':'category'})\n",
    "pos = part_of_speech(list_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(words,\n",
    "              limit=100,\n",
    "              color=(150,50,50)):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    cloud = WordCloud(background_color=\"white\",\n",
    "                  prefer_horizontal=0.9,\n",
    "                  max_font_size=40,\n",
    "                  relative_scaling=.5,\n",
    "                  color_func=lambda *args,**kwargs:color)\n",
    "    cloud.generate_from_frequencies(dict(word_freq[:limit]))\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(cloud)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "    \"\"\"Convert a list of tokens to a matrix of token counts.\"\"\"\n",
    "    \n",
    "    vectorizer = CountVectorizer()\n",
    "    frequency_matrix = vectorizer.fit_transform(df)\n",
    "    \n",
    "    # Sum all the frequencies for each word\n",
    "    total_count = np.sum(frequency_matrix, axis=0)\n",
    "    \n",
    "    # Squeeze to remove single-dimensional entries\n",
    "    frequency = np.squeeze(np.asarray(sum_frequencies))\n",
    "    \n",
    "    # Make a dataframe of the words and their frequencies\n",
    "    frequency_df = pd.DataFrame([frequency], columns=vectorizer.get_feature_names()).transpose()\n",
    "    return frequency_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(word_frequency):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    labels = word_frequency[0][1:51].index\n",
    "    title = 'Word Frequency'\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.bar(np.arange(50), word_frequency[0][1:51], width = 0.8, color = sns.color_palette(\"bwr\"), alpha=0.5, \n",
    "            edgecolor = \"black\", capsize=8, linewidth=1);\n",
    "    plt.xticks(np.arange(50), labels, rotation=90, size=14);\n",
    "    plt.xlabel(\"Word\");\n",
    "    plt.ylabel(\"Frequency\", size=14);\n",
    "    plt.title(title, size=18)\n",
    "    plt.grid(False);\n",
    "    plt.gca().spines[\"top\"].set_visible(False);\n",
    "    plt.gca().spines[\"right\"].set_visible(False);\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 560571 entries, 1271764746983952390 to 948848104362663936\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   userid                    560571 non-null  string        \n",
      " 1   user_display_name         560571 non-null  string        \n",
      " 2   user_screen_name          560571 non-null  string        \n",
      " 3   user_reported_location    417523 non-null  string        \n",
      " 4   user_profile_description  530518 non-null  string        \n",
      " 5   user_profile_url          338535 non-null  string        \n",
      " 6   follower_count            560571 non-null  int64         \n",
      " 7   following_count           560571 non-null  int64         \n",
      " 8   account_creation_date     560571 non-null  datetime64[ns]\n",
      " 9   account_language          560571 non-null  string        \n",
      " 10  tweet_language            444758 non-null  string        \n",
      " 11  tweet_text                560571 non-null  string        \n",
      " 12  tweet_time                560571 non-null  datetime64[ns]\n",
      " 13  tweet_client_name         560571 non-null  category      \n",
      " 14  in_reply_to_userid        95096 non-null   string        \n",
      " 15  in_reply_to_tweetid       89139 non-null   float64       \n",
      " 16  quoted_tweet_tweetid      18513 non-null   float64       \n",
      " 17  is_retweet                560571 non-null  bool          \n",
      " 18  retweet_userid            17981 non-null   string        \n",
      " 19  retweet_tweetid           100446 non-null  float64       \n",
      " 20  latitude                  560571 non-null  category      \n",
      " 21  longitude                 560571 non-null  category      \n",
      " 22  quote_count               560571 non-null  int64         \n",
      " 23  reply_count               560571 non-null  int64         \n",
      " 24  like_count                560571 non-null  int64         \n",
      " 25  retweet_count             560571 non-null  int64         \n",
      " 26  hashtags                  444588 non-null  string        \n",
      " 27  urls                      465724 non-null  string        \n",
      " 28  user_mentions             560571 non-null  string        \n",
      " 29  file                      560571 non-null  string        \n",
      " 30  campaign                  560571 non-null  string        \n",
      " 31  release                   560571 non-null  object        \n",
      " 32  government                560571 non-null  string        \n",
      " 33  type                      560571 non-null  object        \n",
      " 34  has_quote                 560571 non-null  bool          \n",
      "dtypes: bool(2), category(3), datetime64[ns](2), float64(3), int64(6), object(2), string(17)\n",
      "memory usage: 155.3+ MB\n"
     ]
    }
   ],
   "source": [
    "iran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = (iran\n",
    "            .loc[:][['tweetid','userid','tweet_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.tweet, table.sentiment, test_size=0.2, shuffle=True)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data, features):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    tokenization = TfidfVectorizer(max_features=features)\n",
    "    tokenization.fit(dataset)\n",
    "    return tokenization.transform(data).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
