{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "John R. Ladd, Jessica Otis, Christopher N. Warren, and Scott Weingart, \"Exploring and Analyzing Network Data with Python,\" The Programming Historian 6 (2017), https://doi.org/10.46430/phen0064.\n",
    "\n",
    "https://programminghistorian.org/en/lessons/exploring-and-analyzing-network-data-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import functools\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import *\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build User Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid\n",
       "1271764746983952390            []\n",
       "907991739713118208             []\n",
       "1277789135470768129            []\n",
       "137282411095539712             []\n",
       "1314271851988873251            []\n",
       "                          ...    \n",
       "962844249149538304     [10228272]\n",
       "492029494153052161             []\n",
       "544193600033013760             []\n",
       "243819549844193280             []\n",
       "948848104362663936     [10228272]\n",
       "Name: user_mentions, Length: 560571, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iran['user_mentions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connections(tweets):\n",
    "    \"\"\"Generate three sets of connections ((user1, user2), tweetid):\n",
    "        1. Retweeted: ((['userid'], ['retweet_userid'])['tweetid'])\n",
    "        2. Replied: ((['userid'], ['in_reply_to_userid']), ['tweetid'])\n",
    "        3. Mentioned: ((['userid'], ['mentioned_userid']), ['tweetid'])\n",
    "    \"\"\"\n",
    "    rt = tweets[['userid', 'retweet_userid']].dropna().reset_index()\n",
    "    re = tweets[['userid', 'in_reply_to_userid']].dropna().reset_index()\n",
    "    \n",
    "    mentions = (iran['user_mentions']\n",
    "                # expand usernames into columns\n",
    "                .explode()\n",
    "                # melt wide table into duplicated tweets\n",
    "                .reset_index()\n",
    "                .melt(id_vars=['tweetid'],\n",
    "                      value_name='mentioned_userid')\n",
    "                # clean up\n",
    "                .astype({'mentioned_userid':'string'})\n",
    "                .drop(columns=['variable'])\n",
    "                .join(iran['userid'], on='tweetid')\n",
    "                .dropna()\n",
    "               )\n",
    "    \n",
    "    rt_graph = nx.from_pandas_edgelist(rt, \n",
    "                                       source='userid', \n",
    "                                       target='retweet_userid', \n",
    "                                       edge_attr='tweetid',\n",
    "                                       create_using=nx.DiGraph(),\n",
    "                                      )\n",
    "    re_graph = nx.from_pandas_edgelist(re, \n",
    "                                       source='userid', \n",
    "                                       target='in_reply_to_userid', \n",
    "                                       edge_attr='tweetid',\n",
    "                                       create_using=nx.DiGraph(),\n",
    "                                      )\n",
    "    mention_graph = nx.from_pandas_edgelist(mentions, \n",
    "                                           source='userid', \n",
    "                                           target='mentioned_userid', \n",
    "                                           edge_attr='tweetid',\n",
    "                                           create_using=nx.DiGraph(),\n",
    "                                           )\n",
    "    return rt_graph, re_graph, mention_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_node_attributes(G):\n",
    "    \"\"\"Compute various graph metrics and add to node attributes.\n",
    "    \"\"\"\n",
    "    # degree\n",
    "    nx.set_node_attributes(G,\n",
    "                           dict(G.out_degree(G.nodes())), \n",
    "                           'out_degree')\n",
    "    nx.set_node_attributes(G,\n",
    "                           dict(G.in_degree(G.nodes())), \n",
    "                           'in_degree')\n",
    "    \n",
    "    # eigenvector centrality\n",
    "    nx.set_node_attributes(G, \n",
    "                           nx.eigenvector_centrality(G),\n",
    "                           'eigenvector')\n",
    "    \n",
    "    # betweenness centrality\n",
    "    nx.set_node_attributes(G,\n",
    "                           nx.betweenness_centrality(G), \n",
    "                           'betweenness')\n",
    "    \n",
    "    # degree centrality\n",
    "    nx.set_node_attributes(G,\n",
    "                           nx.degree_centrality(re),\n",
    "                           'degree_centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def top_nodes(data_dict, limit=20, show=False):\n",
    "    \"\"\"Return and optionally print the top n nodes in an attribute\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    nodes = sorted(data_dict.items(), \n",
    "                   key=itemgetter(1), \n",
    "                   reverse=True)[:limit]\n",
    "    if show:\n",
    "        print(\"Top {} nodes:\".format(limit))\n",
    "        for d in nodes:\n",
    "            print(d)\n",
    "        \n",
    "    return nodes\n",
    "        \n",
    "def highest_value(attribute_dict):     \n",
    "    \"\"\"Find the node with largest value in an attribute dictionary.\n",
    "    \n",
    "    Return: \n",
    "        tuple(node, value)\n",
    "        \n",
    "    \"\"\"     \n",
    "    # Ordered tuple  \n",
    "    attr_items = [(b,a) for (a,b) in attribute_dict.iteritems()]    \n",
    "    # Sort in descending order     \n",
    "    attr_items.sort()     \n",
    "    attr_items.reverse()     \n",
    "    return tuple(reversed(attr_items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_directed_attributes(G):\n",
    "    # ratio of number of graph edges to number of edges if fully connected\n",
    "    G.graph['density'] = nx.density(G)\n",
    "    \n",
    "    # diameter = maximum distance between any pair of nodes\n",
    "    G.graph['diameter'] = nx.diameter(G)\n",
    "\n",
    "    \n",
    "def add_undirected_attributes(G):\n",
    "    graph = graph.to_undirected()\n",
    "    \n",
    "    G.graph['connected_components'] = nx.number_connected_components(graph)\n",
    "    #G.graph['largest_subgraph'] = max(nx.connected_component_subgraphs(graph), key=len)\n",
    "    \n",
    "    clustering_coeffs = nx.clustering(graph)\n",
    "    G.graph['avg_clust'] = (sum(clustering_coeffs.values()) \n",
    "                             / len(clustering_coeffs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df(G):\n",
    "    \"\"\"Export graph to Pandas dataframe with attributes as columns.\"\"\"\n",
    "\n",
    "    return pd.DataFrame(dict(G.nodes(data=True))).T\n",
    "    \n",
    "def to_file(G, file):\n",
    "    \"\"\"Export graph to .gexf file.\"\"\"\n",
    "    nx.write_gexf(G, file)\n",
    "    \n",
    "def to_txt(G, file):\n",
    "    \"\"\"Export node attributes to .txt file.\"\"\"\n",
    "    results = [(k, bet_cen[k], clo_cen[k], eig_cen[k]) for k in range(len(nodes))]\n",
    "    \n",
    "    f = open(file,'w')\n",
    "    for item in results:     \n",
    "        f.write(','.join(map(str,item)))     \n",
    "        f.write('\\n')\n",
    "    f.close()\n",
    "\n",
    "def get_matrix(G):\n",
    "    return nx.to_numpy_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(G, format_dict=None):\n",
    "    if format_dict == None:\n",
    "        format_dict = {'font_size':16,\n",
    "                       'width':3,\n",
    "                       'edge_color':'grey',\n",
    "                       'node_color':'purple',\n",
    "                       'with_labels':False,\n",
    "                      }\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    pos = nx.spring_layout(G, k=2)\n",
    "\n",
    "    nx.draw_networkx(G, \n",
    "                     pos,\n",
    "                     ax=ax,\n",
    "                     kwargs=format_dict,\n",
    "                    )\n",
    "    # Offset labels\n",
    "    for key, value in pos.items():\n",
    "        x, y = value[0]+.135, value[1]+.045\n",
    "        ax.text(x, y,\n",
    "                s=key,\n",
    "                bbox=dict(facecolor='red', alpha=0.25),\n",
    "                horizontalalignment='center', fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Iran 12/2020 Campaign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = UsersData('data/users')\n",
    "tweets = TweetsData('data/tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = tweets.df.loc[:][:]\n",
    "users_df = users.df.loc[:][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iran = tweets_df[tweets_df['campaign'] == 'iran202012']\n",
    "iran_users = users_df[users_df['campaign'] == 'iran202012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 560571 entries, 1271764746983952390 to 948848104362663936\n",
      "Data columns (total 36 columns):\n",
      " #   Column                    Non-Null Count   Dtype         \n",
      "---  ------                    --------------   -----         \n",
      " 0   userid                    560571 non-null  string        \n",
      " 1   user_display_name         560571 non-null  string        \n",
      " 2   user_screen_name          560571 non-null  string        \n",
      " 3   user_reported_location    417523 non-null  string        \n",
      " 4   user_profile_description  530518 non-null  string        \n",
      " 5   user_profile_url          338535 non-null  string        \n",
      " 6   follower_count            560571 non-null  int64         \n",
      " 7   following_count           560571 non-null  int64         \n",
      " 8   account_creation_date     560571 non-null  datetime64[ns]\n",
      " 9   account_language          560571 non-null  string        \n",
      " 10  tweet_language            444758 non-null  string        \n",
      " 11  tweet_text                560571 non-null  string        \n",
      " 12  tweet_time                560571 non-null  datetime64[ns]\n",
      " 13  tweet_client_name         560571 non-null  category      \n",
      " 14  in_reply_to_userid        95096 non-null   string        \n",
      " 15  in_reply_to_tweetid       89139 non-null   object        \n",
      " 16  quoted_tweet_tweetid      18513 non-null   object        \n",
      " 17  is_retweet                560571 non-null  bool          \n",
      " 18  retweet_userid            17981 non-null   string        \n",
      " 19  retweet_tweetid           100446 non-null  object        \n",
      " 20  latitude                  560571 non-null  category      \n",
      " 21  longitude                 560571 non-null  category      \n",
      " 22  quote_count               560571 non-null  int64         \n",
      " 23  reply_count               560571 non-null  int64         \n",
      " 24  like_count                560571 non-null  int64         \n",
      " 25  retweet_count             560571 non-null  int64         \n",
      " 26  hashtags                  444588 non-null  object        \n",
      " 27  urls                      465724 non-null  object        \n",
      " 28  user_mentions             560571 non-null  object        \n",
      " 29  file                      560571 non-null  string        \n",
      " 30  campaign                  560571 non-null  string        \n",
      " 31  release                   560571 non-null  object        \n",
      " 32  government                560571 non-null  string        \n",
      " 33  type                      560571 non-null  object        \n",
      " 34  is_reply                  560571 non-null  bool          \n",
      " 35  has_quote                 560571 non-null  bool          \n",
      "dtypes: bool(3), category(3), datetime64[ns](2), int64(6), object(8), string(14)\n",
      "memory usage: 135.8+ MB\n"
     ]
    }
   ],
   "source": [
    "iran.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt, re, mentions = get_connections(iran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes: 92\n",
      "Edges: 319\n",
      "Maximum degree: 26\n",
      "Minimum degree: 1\n",
      "Average degree: 6.9\n",
      "Mode: 2\n"
     ]
    }
   ],
   "source": [
    "def print_graph_properties(graph):\n",
    "    out = \"Nodes: {}\".format(graph.number_of_nodes())\n",
    "    print(out)\n",
    "    out = \"Edges: {}\".format(graph.number_of_edges())\n",
    "    print(out)\n",
    "\n",
    "    degrees = [val for (node, val) in graph.degree()]\n",
    "\n",
    "    out = \"Maximum degree: {}\".format(np.max(degrees))\n",
    "    print(out)\n",
    "    out = \"Minimum degree: {}\".format(np.min(degrees))\n",
    "    print(out)\n",
    "    out = \"Average degree: {:.1f}\".format(np.mean(degrees))\n",
    "    print(out)\n",
    "    out = \"Mode: {}\".format(stats.mode(degrees)[0][0])\n",
    "    print(out)\n",
    "    \n",
    "print_graph_properties(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_node_attributes(rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_nodes(data_dict, limit=20, show=False):\n",
    "    \"\"\"Return and optionally print the top n nodes in an attribute\n",
    "    dictionary.\n",
    "    \"\"\"\n",
    "    nodes = sorted(data_dict.items(), \n",
    "                   key=itemgetter(1), \n",
    "                   reverse=True)[:limit]\n",
    "    if show:\n",
    "        print(\"Top {} nodes:\".format(limit))\n",
    "        for d in nodes:\n",
    "            print(d)\n",
    "        \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total retweets: 100446\n"
     ]
    }
   ],
   "source": [
    "print('Total retweets: {}'.format(len(iran[iran['is_retweet'] == True])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retweets with userid: 17981\n"
     ]
    }
   ],
   "source": [
    "print('Retweets with userid: {}'. format(len(iran[iran['retweet_userid'].notna()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userid\n",
       "+JkWMulEtCyTrcFDRO2XLv9EOdGHDl0GB9cdZUWgtA=        78\n",
       "+fwTi4Wv1fs5sua3wZXqtBWBMMAy5IKNd5euWlP8Kuk=       95\n",
       "0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=      456\n",
       "0hVjtURHlBEHZhn22rNDf98r+8VUXV3gi1bxvAhrZo=      1566\n",
       "0zCl5U0pYu0gEmK3JtjO5fbnxEj6pO9GUgH52Q6yg0E=    13304\n",
       "                                                ...  \n",
       "y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=       526\n",
       "z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=      7878\n",
       "zFlH+vHUhiZD2qvvCLYyiU76qOha9+iYxCn1NVmzw=         41\n",
       "zTUtu8WZ3RwxnwgMsYXnTU107UXsn4MQU5wrg8IDOU=         5\n",
       "zk4khaX7A3XhXVndteeiXLe4ma8xR7bYMBCOhCt68j8=        1\n",
       "Name: is_retweet, Length: 209, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iran.groupby([['is_retweet','userid']]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=', 15),\n",
       " ('z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=', 14),\n",
       " ('BYaaZkKxjVQjhsnn9REZ0UcFoEHl+tKnzJ+0Hv+Pg=', 13),\n",
       " ('v6groR3jb3Pkm5X9ccSwgoPnmlZzKEkx5bsc1XQHb0=', 13),\n",
       " ('6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=', 12),\n",
       " ('rrkP3RNDiwWqLySjcoqdFlz7DrFX7RCwwDSxyDqaU=', 11),\n",
       " ('y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=', 10),\n",
       " ('KDPuEWEH9vUzPJJYOWrnRKwAkD475uTOwGgDadl13M=', 10),\n",
       " ('qb7oI6mpyssEK1+AulE9g7rOChgVTfVOIDhXM8tA=', 10),\n",
       " ('hkHAOHxXGt95jKyclLf70qjOMCdw3E7RyP1EYC0pYJU=', 10),\n",
       " ('Bl9IUxp6GStTkiNGbhfBJM9xu85e3Y9BQdNd97GFAI=', 9),\n",
       " ('Hz3n1y2y3sLOknEGxPWczYyCSeZrz15JLPTcJAd6oAo=', 9),\n",
       " ('QXyUcPxvoQ+uzkqCj6O+AT9nUf3Avh0JTvwTG9GncQk=', 9),\n",
       " ('ihPCMQ32xEzpD35Et9IH4HO21XKiWdSJreVg+pHT5o=', 9),\n",
       " ('A2ufeZxtC32uuqgSKfm1EiJPs4uMP3aM7AfHUMsTM=', 8),\n",
       " ('etDaWEjMPleueDrpkatPUSCApc6yU8W95+yZYWzVxSY=', 8),\n",
       " ('LubegkQHPmV20BdQonItq03iWY5unAkvlI2M7PNKvjI=', 8),\n",
       " ('1099221870530961408', 8),\n",
       " ('1067814896706994176', 7),\n",
       " ('mpY+AZI80Nu61VS3o4Zm+UXTjaxrkE08xU0nO3JQ=', 7)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_retweets = top_nodes(nx.get_node_attributes(rt, 'out_degree'),limit=20)\n",
    "most_retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bl9IUxp6GStTkiNGbhfBJM9xu85e3Y9BQdNd97GFAI=', 16),\n",
       " ('etDaWEjMPleueDrpkatPUSCApc6yU8W95+yZYWzVxSY=', 16),\n",
       " ('1067814896706994176', 15),\n",
       " ('BYaaZkKxjVQjhsnn9REZ0UcFoEHl+tKnzJ+0Hv+Pg=', 13),\n",
       " ('rrkP3RNDiwWqLySjcoqdFlz7DrFX7RCwwDSxyDqaU=', 13),\n",
       " ('v6groR3jb3Pkm5X9ccSwgoPnmlZzKEkx5bsc1XQHb0=', 12),\n",
       " ('79Tf6XH3DwjdUWGO4aQWghSj5G2esetBnePoOBB3wYM=', 11),\n",
       " ('M4AN5Ed68gBwmVS3DcPbwuXv7cJRYDwsCvmJ84BYSB0=', 11),\n",
       " ('0gTQ2cDCHFpYXKO+G367F1HBrPLupiuPjXuvmp9UL+w=', 11),\n",
       " ('1099221870530961408', 11),\n",
       " ('mpY+AZI80Nu61VS3o4Zm+UXTjaxrkE08xU0nO3JQ=', 10),\n",
       " ('6qhrzJLryTiE7VlJkmY+cKE5VsITiaFwMA7s3Dr5I=', 10),\n",
       " ('y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=', 10),\n",
       " ('XCVp3AesS42sNbyxhBsKM62AylqUJyipi3laS53gY=', 10),\n",
       " ('EOkiPW6kT+GE5A2wU5mqPe7hiK8s7Cr0tfCybFsz2Sg=', 8),\n",
       " ('z3nCVBEHiIbcBhhxU2mOz5iWK4a7sUdGmRSPFM16G0=', 7),\n",
       " ('ihPCMQ32xEzpD35Et9IH4HO21XKiWdSJreVg+pHT5o=', 7),\n",
       " ('HcrkAj2Z5laESkAd3aQjE1dgoP6r9xDN6LLzEIHzX4=', 7),\n",
       " ('qb7oI6mpyssEK1+AulE9g7rOChgVTfVOIDhXM8tA=', 7),\n",
       " ('Llwo+0XebgvqnGE1UiwiaJqfQWQF6NJX+gnV77DBRpk=', 7)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_retweeted = top_nodes(nx.get_node_attributes(rt, 'in_degree'),limit=20)\n",
    "most_retweeted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('BYaaZkKxjVQjhsnn9REZ0UcFoEHl+tKnzJ+0Hv+Pg=', 13), ('y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=', 10)]\n"
     ]
    }
   ],
   "source": [
    "print([userid for userid in most_retweeted if userid in most_retweets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering and transitivity\n",
    "\n",
    "Measuring the tendency for nodes to cluster together or for edges to form triangles: this corresponds to measures of the extent to which the users interacting with one particular user tend to interact with each other as well. Transitivity weights nodes with a large degree higher.\n",
    "\n",
    "The clustering coefficient is calculated as the number of triangles connected to node $i$ divided by the number of sets of two edges connected to node $i$ (node triples). \n",
    "\n",
    "The transitivity coefficient is calculated as 3 times the number of triangles in the network, divided by the number of connected triples of nodes in the network.\n",
    "\n",
    "- insight into how users tend to create groups characterized by dense connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average clustering coefficient: 0.3277545397909848\n",
      "Transitivity: 0.676875\n"
     ]
    }
   ],
   "source": [
    "out = \"Average clustering coefficient: {}\".format(nx.average_clustering(graph))\n",
    "print(out)\n",
    "out = \"Transitivity: {}\".format(nx.transitivity(graph))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centrality\n",
    "\n",
    "Capture the importance of a node's position in the network considering: \n",
    "- degree, on the assumption that an important node will have many connections,\n",
    "- closeness, on the assumption that important nodes are close to other nodes, and\n",
    "- betweenness, on the assumption that important nodes are well situated and connect other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max degree centrality: 0.21, for node v6groR3jb3Pkm5X9ccSwgoPnmlZzKEkx5bsc1XQHb0=\n",
      "Max closeness centrality: 0.22, for node y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=\n",
      "Max betweenness centrality: 0.16, for node y3KkURpZFjT+WeW9e6BcxBYRg311F8fz1eJ647ahQc=\n"
     ]
    }
   ],
   "source": [
    "graph_centrality = nx.degree_centrality(graph)\n",
    "max_de = max(graph_centrality.items(), key=itemgetter(1))\n",
    "graph_closeness = nx.closeness_centrality(graph)\n",
    "max_clo = max(graph_closeness.items(), key=itemgetter(1))\n",
    "graph_betweenness = nx.betweenness_centrality(graph, normalized=True, endpoints=False)\n",
    "max_bet = max(graph_betweenness.items(), key=itemgetter(1))\n",
    "\n",
    "out = \"Max degree centrality: {:.2f}, for node {}\".format(max_de[1], max_de[0])\n",
    "print(out)\n",
    "out = \"Max closeness centrality: {:.2f}, for node {}\".format(max_clo[1], max_clo[0])\n",
    "print(out)\n",
    "out = \"Max betweenness centrality: {:.2f}, for node {}\".format(max_bet[1], max_bet[0])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
